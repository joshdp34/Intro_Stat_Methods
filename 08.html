<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Sampling Distributions ‚Äì STA 2381 Introductory Statistical Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-2ea2d3e7f2364fcda3d434693d3458e0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
div.callout-example.callout {
  border-left-color: #008000;
}
div.callout-example.callout-style-default > .callout-header {
  background-color: rgba(0, 128, 0, 0.13);
}
div.callout-example .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-example.callout-style-default .callout-icon::before, div.callout-example.callout-titled .callout-icon::before {
  content: 'üìà';
  background-image: none;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href=".center-panel.quarto-layout-panel {
  justify-content: center;
  column-gap: 1rem;
}">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./08.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Distributions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Collecting Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Describing Data with Tables and Graphs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Describing Data with Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability Concepts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Distributions</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-08_01" id="toc-sec-08_01" class="nav-link active" data-scroll-target="#sec-08_01"><span class="header-section-number">8.1</span> Data, Probability and Sampling Distributions</a>
  <ul class="collapse">
  <li><a href="#three-distributions-you-will-encounter" id="toc-three-distributions-you-will-encounter" class="nav-link" data-scroll-target="#three-distributions-you-will-encounter">Three distributions you will encounter</a></li>
  <li><a href="#statistics-versus-parameters" id="toc-statistics-versus-parameters" class="nav-link" data-scroll-target="#statistics-versus-parameters">Statistics versus parameters</a></li>
  <li><a href="#working-in-jmp" id="toc-working-in-jmp" class="nav-link" data-scroll-target="#working-in-jmp">Working in JMP</a></li>
  <li><a href="#recap" id="toc-recap" class="nav-link" data-scroll-target="#recap">Recap</a></li>
  <li><a href="#check-your-understanding" id="toc-check-your-understanding" class="nav-link" data-scroll-target="#check-your-understanding">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-08_02" id="toc-sec-08_02" class="nav-link" data-scroll-target="#sec-08_02"><span class="header-section-number">8.2</span> Sampling Distribution of the Sample Proportion</a>
  <ul class="collapse">
  <li><a href="#the-sample-proportion" id="toc-the-sample-proportion" class="nav-link" data-scroll-target="#the-sample-proportion">The sample proportion</a></li>
  <li><a href="#the-sampling-distribution-of-hatp" id="toc-the-sampling-distribution-of-hatp" class="nav-link" data-scroll-target="#the-sampling-distribution-of-hatp">The sampling distribution of <span class="math inline">\(\hat{p}\)</span></a></li>
  <li><a href="#properties-of-the-sampling-distribution" id="toc-properties-of-the-sampling-distribution" class="nav-link" data-scroll-target="#properties-of-the-sampling-distribution">Properties of the sampling distribution</a></li>
  <li><a href="#conditions-for-the-normal-approximation" id="toc-conditions-for-the-normal-approximation" class="nav-link" data-scroll-target="#conditions-for-the-normal-approximation">Conditions for the normal approximation</a></li>
  <li><a href="#working-in-jmp-1" id="toc-working-in-jmp-1" class="nav-link" data-scroll-target="#working-in-jmp-1">Working in JMP</a></li>
  <li><a href="#recap-1" id="toc-recap-1" class="nav-link" data-scroll-target="#recap-1">Recap</a></li>
  <li><a href="#check-your-understanding-1" id="toc-check-your-understanding-1" class="nav-link" data-scroll-target="#check-your-understanding-1">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-08_03" id="toc-sec-08_03" class="nav-link" data-scroll-target="#sec-08_03"><span class="header-section-number">8.3</span> Sampling Distribution of the Sample Mean</a>
  <ul class="collapse">
  <li><a href="#properties-of-the-sampling-distribution-1" id="toc-properties-of-the-sampling-distribution-1" class="nav-link" data-scroll-target="#properties-of-the-sampling-distribution-1">Properties of the sampling distribution</a></li>
  <li><a href="#the-central-limit-theorem" id="toc-the-central-limit-theorem" class="nav-link" data-scroll-target="#the-central-limit-theorem">The Central Limit Theorem</a></li>
  <li><a href="#practical-considerations" id="toc-practical-considerations" class="nav-link" data-scroll-target="#practical-considerations">Practical considerations</a></li>
  <li><a href="#working-in-jmp-2" id="toc-working-in-jmp-2" class="nav-link" data-scroll-target="#working-in-jmp-2">Working in JMP</a></li>
  <li><a href="#recap-2" id="toc-recap-2" class="nav-link" data-scroll-target="#recap-2">Recap</a></li>
  <li><a href="#check-your-understanding-2" id="toc-check-your-understanding-2" class="nav-link" data-scroll-target="#check-your-understanding-2">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-08_04" id="toc-sec-08_04" class="nav-link" data-scroll-target="#sec-08_04"><span class="header-section-number">8.4</span> Bootstrap Sampling Distribution</a>
  <ul class="collapse">
  <li><a href="#how-bootstrapping-works" id="toc-how-bootstrapping-works" class="nav-link" data-scroll-target="#how-bootstrapping-works">How bootstrapping works</a></li>
  <li><a href="#why-bootstrapping-is-useful" id="toc-why-bootstrapping-is-useful" class="nav-link" data-scroll-target="#why-bootstrapping-is-useful">Why bootstrapping is useful</a></li>
  <li><a href="#when-to-be-cautious" id="toc-when-to-be-cautious" class="nav-link" data-scroll-target="#when-to-be-cautious">When to be cautious</a></li>
  <li><a href="#the-big-picture" id="toc-the-big-picture" class="nav-link" data-scroll-target="#the-big-picture">The big picture</a></li>
  <li><a href="#working-in-jmp-3" id="toc-working-in-jmp-3" class="nav-link" data-scroll-target="#working-in-jmp-3">Working in JMP</a></li>
  <li><a href="#recap-3" id="toc-recap-3" class="nav-link" data-scroll-target="#recap-3">Recap</a></li>
  <li><a href="#check-your-understanding-3" id="toc-check-your-understanding-3" class="nav-link" data-scroll-target="#check-your-understanding-3">Check your understanding</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Distributions</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="sec-08_01" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="sec-08_01"><span class="header-section-number">8.1</span> Data, Probability and Sampling Distributions</h2>
<blockquote class="blockquote">
<p>‚ÄúWhile nothing is more uncertain than a single life, nothing is more certain than the average duration of a thousand lives.‚Äù ‚Äì Elizur Wright</p>
</blockquote>
<p>The leap from simply <em>describing data</em> to making <em>decisions about unknown populations</em> depends on understanding <strong>sampling distributions</strong>. Up to this point, we have focused on two main tasks:</p>
<ul>
<li>describing what we observe in a single dataset, and</li>
<li>modeling randomness using probability distributions.</li>
</ul>
<p>Statistical inference‚Äîconfidence intervals, hypothesis tests, and many modeling tools‚Äîrequires one more layer of thinking. Instead of asking only <em>‚ÄúWhat does this sample look like?‚Äù</em>, we must ask:</p>
<blockquote class="blockquote">
<p><em>How would this statistic behave if we repeated the sampling process over and over?</em></p>
</blockquote>
<p>That question leads us directly to the idea of a <strong>sampling distribution</strong>.</p>
<p>Before developing that concept, it is essential to clearly distinguish three different kinds of distributions that appear throughout statistics. Although they are related, they answer very different questions.</p>
<section id="three-distributions-you-will-encounter" class="level3">
<h3 class="anchored" data-anchor-id="three-distributions-you-will-encounter">Three distributions you will encounter</h3>
<section id="the-data-distribution" class="level4">
<h4 class="anchored" data-anchor-id="the-data-distribution">The data distribution</h4>
<p>The <strong>data distribution</strong> is the distribution of the raw observations in a single sample. It is what you actually see when you collect data.</p>
<ul>
<li>It is <em>empirical</em> (based on observed values).</li>
<li>It changes from sample to sample.</li>
<li>It is typically displayed with a histogram, dotplot, or boxplot.</li>
</ul>
<p><strong>Example.</strong> If you measure the blood pressures of 50 patients and plot a histogram of those 50 values, you are looking at the <em>data distribution</em>.</p>
<p>This distribution answers the descriptive question:</p>
<blockquote class="blockquote">
<p><em>What does this particular sample look like?</em></p>
</blockquote>
</section>
<section id="the-probability-distribution" class="level4">
<h4 class="anchored" data-anchor-id="the-probability-distribution">The probability distribution</h4>
<p>A <strong>probability distribution</strong> is a theoretical model for how individual values behave in the population.</p>
<ul>
<li>It describes the long-run behavior of a random variable.</li>
<li>It is defined mathematically (for example, normal, binomial, or uniform).</li>
<li>It represents our assumptions about the population.</li>
</ul>
<p>You can think of it as the <em>data-generating mechanism</em> for individual observations.</p>
<p><strong>Example.</strong> We might assume adult systolic blood pressure in a population follows approximately a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p>This distribution answers the modeling question:</p>
<blockquote class="blockquote">
<p><em>How do individual observations vary in the population?</em></p>
</blockquote>
</section>
<section id="the-sampling-distribution" class="level4">
<h4 class="anchored" data-anchor-id="the-sampling-distribution">The sampling distribution</h4>
<p>The <strong>sampling distribution</strong> is the distribution of a <em>statistic</em> (such as a sample mean, sample median, or sample proportion) computed from <em>all possible samples of a fixed size <span class="math inline">\(n\)</span></em>.</p>
<p>Key features:</p>
<ul>
<li>It is also theoretical.</li>
<li>It concerns <em>statistics</em>, not raw data.</li>
<li>It describes the variability caused by the sampling process itself.</li>
</ul>
<p>Formally: The sampling distribution of a statistic is the probability distribution of all possible values of that statistic when all possible samples of size <span class="math inline">\(n\)</span> are drawn from the population.</p>
<p>This distribution answers the inferential question:</p>
<blockquote class="blockquote">
<p><em>How much would our statistic vary if we repeated the study many times?</em></p>
</blockquote>
<p>This is the critical bridge to statistical inference.</p>
</section>
<section id="why-the-distinction-matters" class="level4">
<h4 class="anchored" data-anchor-id="why-the-distinction-matters">Why the distinction matters</h4>
<p>These three distributions live at <em>different levels</em>:</p>
<ul>
<li><strong>Data distribution</strong> ‚Üí variability among individual observations in one sample</li>
<li><strong>Probability distribution</strong> ‚Üí theoretical model for individual observations</li>
<li><strong>Sampling distribution</strong> ‚Üí variability of a statistic across repeated samples</li>
</ul>
<p>Students often confuse the last two. A helpful rule of thumb is:</p>
<p><strong>Probability distributions describe</strong> <strong><em>individuals</em></strong>.<br>
<strong>Sampling distributions describe</strong> <strong><em>statistics</em></strong>.</p>
<div class="callout callout-style-simple callout-example callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 8.1: Salamander lengths
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Imagine an ecologist studying the lengths of salamanders in a particular swamp.</p>
<p><em>Population (conceptual starting point).</em> Suppose the true salamander lengths in the swamp follow a right-skewed probability distribution: most animals are small, but a few grow unusually long. This underlying model is the <strong>probability distribution</strong> of salamander length.</p>
<p><em>Single field study.</em> The ecologist randomly captures, measures, and releases 20 salamanders. The histogram of those 20 measured lengths is the <strong>data distribution</strong>. If she repeated the fieldwork tomorrow, she would likely get a slightly different histogram.</p>
<p><em>Repeated sampling thought experiment.</em> Now imagine she repeats the same 20-salamander study hundreds or thousands of times, each time computing the <em>sample mean length</em>. If we plotted a histogram of all those sample means, that histogram would be the <strong>sampling distribution of the sample mean</strong>.</p>
<p>Notice the shift in focus:</p>
<ul>
<li>The data distribution describes <strong>individual salamanders</strong>.</li>
<li>The sampling distribution describes <strong>the sample mean across studies</strong>.</li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="statistics-versus-parameters" class="level3">
<h3 class="anchored" data-anchor-id="statistics-versus-parameters">Statistics versus parameters</h3>
<p>A clear understanding of the difference between <strong>parameters</strong> and <strong>statistics</strong> is essential for statistical inference. Much of what we do in statistics revolves around using information from a sample to learn about a larger population we cannot fully observe.</p>
<p>A <strong>parameter</strong> is a numerical summary that describes an entire population. It is a fixed but usually unknown quantity. Common population parameters include:</p>
<ul>
<li>the population mean, denoted <span class="math inline">\(\mu\)</span>,</li>
<li>the population proportion, denoted <span class="math inline">\(p\)</span>,</li>
<li>the population standard deviation, denoted <span class="math inline">\(\sigma\)</span>.</li>
</ul>
<p>Because populations are often very large‚Äîor even conceptual‚Äîit is usually impractical or impossible to measure every individual. As a result, the true parameter value typically remains unknown.</p>
<p>In contrast, a <strong>statistic</strong> is a numerical summary computed from a sample. Statistics are observable and calculable from data we actually collect. Common examples include:</p>
<ul>
<li>the sample mean, denoted <span class="math inline">\(\bar{x}\)</span>,</li>
<li>the sample standard deviation, denoted <span class="math inline">\(s\)</span>.</li>
</ul>
<p>Unlike parameters, statistics <em>vary from sample to sample</em> because different random samples produce different values.</p>
<p>The central goal of statistical inference is to use <em>statistics to estimate parameters</em>. We hope that a well-chosen statistic will be close to the corresponding population parameter, but because of sampling variability, it will not match exactly every time.</p>
<p>This is where the <strong>sampling distribution</strong> plays a crucial role. The sampling distribution describes how a statistic behaves across repeated random samples of the same size. By studying this distribution, we can answer important questions such as:</p>
<ul>
<li>How much does the statistic typically vary?</li>
<li>Is the statistic usually close to the parameter?</li>
<li>How uncertain is our estimate?</li>
</ul>
<p>For example, suppose the true mean blood pressure of all adults in Waco is <span class="math inline">\(\mu\)</span>. We cannot measure everyone, so we take a random sample of 50 adults and compute the sample mean <span class="math inline">\(\bar{x}\)</span>. If we repeatedly took new samples of 50 adults and recomputed <span class="math inline">\(\bar{x}\)</span> each time, the resulting values would form the <em>sampling distribution of the sample mean</em>.</p>
<p>The spread of this sampling distribution tells us how precisely <span class="math inline">\(\bar{x}\)</span> estimates <span class="math inline">\(\mu\)</span>. A narrow sampling distribution indicates that the statistic tends to be close to the parameter (high precision), while a wide sampling distribution indicates more sampling variability (lower precision).</p>
<p>A useful way to think about the relationship is:</p>
<ul>
<li>The <em>parameter</em> is the fixed target.</li>
<li>The <em>statistic</em> is our estimate from one sample.</li>
<li>The <em>sampling distribution</em> describes how the estimate would fluctuate if we repeated the sampling process many times.</li>
</ul>
<div class="callout callout-style-simple callout-example callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 8.2: Sampling distribution from a small population
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Suppose we had a small population of 20 US adults. Furthermore, suppose we want to estimate the proportion of this population that are left eye dominate. Below are the values for this population<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 4%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;">L</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Our goal is to estimate the proportion of this population who are left eye dominate. Clearly, we could easily determine this proportion by looking at this small population. By doing so, we see that the proportion that are left eye dominate is <span class="math display">\[
\begin{align*}
p &amp;= \frac{9}{20}\\
&amp;=0.45
\end{align*}
\]</span> Suppose we don‚Äôt know this proportion and the only thing we can do is randomly sample of size of 5 from this population. Below is one such sample.</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<tbody>
<tr class="odd">
<td style="text-align: left;">L</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">R</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>From this sample, we estimate the proportion to be <span class="math display">\[
\begin{align*}
\hat{p} &amp;= \frac{2}{5}\\
&amp;= 0.4
\end{align*}
\]</span></p>
<p>This is just one such sample. There are many more random samples of size 5 from this population of 20 that I could have gotten. In fact, there are <span class="math display">\[
\binom{20}{5} = 15{,}504
\]</span> possible samples of size 5 from this population. Suppose we did all of these samples and each time calculated <span class="math inline">\(\hat{p}\)</span>. Below is a histogram of all of these <span class="math inline">\(\hat{p}\)</span>‚Äôs.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="08_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>The histogram above shows the sampling distribution of <span class="math inline">\(\hat{p}\)</span> for a sample of size 5 from a population of size 20. For most practical applications, the population is much bigger than 20. It is not uncommon to have population sizes in the tens of thousands or even millions. Even if we kept the population size relatively low, such as 1000, the number of possible samples of size 5 become massive. <span class="math display">\[
\begin{align*}
\binom{1000}{5} = 8{,}250{,}291{,}250{,}200
\end{align*}
\]</span></p>
<p>Even if we wanted to examine all of the possible samples (if the population was known) of size 5, it would be unfeasible even with a computer.</p>
<p>Fortunately, we have some results to help us determine what these distributions look like without having to examine all of the possible samples.</p>
</div>
</div>
</div>
</section>
<section id="working-in-jmp" class="level3">
<h3 class="anchored" data-anchor-id="working-in-jmp">Working in JMP</h3>
<p>JMP can simulate sampling distributions without requiring you to know R. To explore the sampling distribution of a mean:</p>
<ul>
<li>Use <strong>Help ‚Üí Sample Data Library</strong> to load a dataset (for example, ‚ÄúBody Measurements‚Äù). Then choose <strong>Analyze ‚Üí Distribution</strong> and assign your variable to Y to visualize the data distribution.</li>
<li>To simulate a sampling distribution, go to <strong>Graph Builder</strong> and use <strong>Bootstrap</strong> from the red triangle menu. Specify your statistic (mean, median or proportion) and the number of bootstrap samples. JMP will draw many samples with replacement from your data and display the distribution of the chosen statistic. This bootstrap distribution approximates the sampling distribution we would get by taking many independent samples from the population.</li>
</ul>
</section>
<section id="recap" class="level3">
<h3 class="anchored" data-anchor-id="recap">Recap</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 82%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Data distribution</strong></td>
<td>The distribution of the observed values in a single sample.</td>
</tr>
<tr class="even">
<td><strong>Probability distribution</strong></td>
<td>A theoretical model describing how a variable behaves in the population.</td>
</tr>
<tr class="odd">
<td><strong>Sampling distribution</strong></td>
<td>The probability distribution of a statistic computed from all possible samples of a fixed size.</td>
</tr>
<tr class="even">
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding">Check your understanding</h3>
<div class="callout callout-style-default callout-note callout-titled" title="Problems">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problems
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Explain, in your own words, the difference between a data distribution and a sampling distribution. Why is the latter crucial for inference?</li>
<li>What is the meaning of the phrase ‚Äúthe sampling distribution is a theoretical idea‚Äîwe do not actually build it‚Äù?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Data vs.&nbsp;sampling distribution.</strong> A data distribution reflects the raw measurements from one sample. A sampling distribution reflects how a summary statistic (such as a mean or proportion) would vary if we repeatedly took new samples of the same size. The sampling distribution is crucial because it tells us how much our statistic is expected to fluctuate around the true parameter, and thus forms the basis for standard errors and confidence intervals.</p></li>
<li><p><strong>Why theoretical?</strong> The number of possible samples of size <span class="math inline">\(n\)</span> from a population is enormous, so we cannot literally take all of them. The sampling distribution therefore exists as a theoretical construct.</p></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-08_02" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="sec-08_02"><span class="header-section-number">8.2</span> Sampling Distribution of the Sample Proportion</h2>
<blockquote class="blockquote">
<p>‚ÄúMath is the logic of certainty; statistics is the logic of uncertainty.‚Äù - Joe Blizstein</p>
</blockquote>
<p>Many real-world studies involve <em>categorical outcomes</em> rather than numerical measurements. For example, in business, we could have</p>
<ul>
<li>Whether a customer makes a purchase (yes/no),</li>
<li>Whether a loan applicant defaults (default/no default),</li>
<li>Whether a marketing email is opened (opened/not opened),</li>
<li>Whether a customer renews a subscription (renew/does not renew).</li>
</ul>
<p>In each of these settings, the outcome for an individual unit falls into one of two categories. Such variables are often called <strong>binary</strong> variables.</p>
<section id="the-sample-proportion" class="level3">
<h3 class="anchored" data-anchor-id="the-sample-proportion">The sample proportion</h3>
<p>When outcomes are binary, a natural summary statistic is the <strong>sample proportion</strong>, denoted <span class="math inline">\(\hat{p}\)</span>.</p>
<p>Suppose a company sends a promotional email to <span class="math inline">\(n\)</span> customers and records how many open it. If <span class="math inline">\(X\)</span> customers open the email, the sample proportion is</p>
<p><span class="math display">\[
\hat{p} = \frac{X}{n}.
\]</span></p>
<p>This quantity estimates the <em>population proportion</em> <span class="math inline">\(p\)</span>, which represents the true (but unknown) probability that a randomly selected customer would open the email.</p>
<p>Because <span class="math inline">\(\hat{p}\)</span> is computed from a sample, it will vary from sample to sample. If the company ran the same email campaign many times with different randomly selected customers, the observed open rate would not be identical each time.</p>
</section>
<section id="the-sampling-distribution-of-hatp" class="level3">
<h3 class="anchored" data-anchor-id="the-sampling-distribution-of-hatp">The sampling distribution of <span class="math inline">\(\hat{p}\)</span></h3>
<p>The <strong>sampling distribution of <span class="math inline">\(\hat{p}\)</span></strong> describes how the sample proportion behaves across repeated random samples of the same size <span class="math inline">\(n\)</span>.</p>
<p>Before collecting data, <span class="math inline">\(\hat{p}\)</span> is a random variable. Its value depends on which customers happen to be included in the sample. Some samples may yield a high open rate; others may yield a lower one.</p>
<p>If we repeatedly:</p>
<ol type="1">
<li>Select a random sample of <span class="math inline">\(n\)</span> customers,</li>
<li>Compute <span class="math inline">\(\hat{p}\)</span> for each sample,</li>
<li>Plot all those values,</li>
</ol>
<p>the resulting distribution would be the <strong>sampling distribution of the sample proportion</strong>.</p>
</section>
<section id="properties-of-the-sampling-distribution" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-the-sampling-distribution">Properties of the sampling distribution</h3>
<p>When the outcomes in the population are independent and the population proportion is <span class="math inline">\(p\)</span>, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> has three key properties:</p>
<ul>
<li><p><strong>Center</strong>. The mean (or expected value) of <span class="math inline">\(\hat{p}\)</span> is the true population proportion. In other words, <span class="math inline">\(E(\hat{p}) = p\)</span>.<br>
</p></li>
<li><p><strong>Spread</strong>. The standard deviation of <span class="math inline">\(\hat{p}\)</span> is <span class="math display">\[
\sigma_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}
\]</span></p>
<p>This formula arises because the variance of a binomial random variable with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span> is <span class="math inline">\(np(1-p)\)</span>, and dividing by <span class="math inline">\(n^2\)</span> converts the count to a proportion. The standard deviation shrinks as the sample size increases, meaning larger samples give more precise estimates.</p></li>
<li><p><strong>Shape</strong>. Under mild conditions (in particular, when the expected numbers of successes and failures both exceed about 15), the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is approximately normal. Thus, for large enough <span class="math inline">\(n\)</span> we can use a Normal model to approximate probabilities involving <span class="math inline">\(\hat{p}\)</span>.</p></li>
</ul>
<div class="callout callout-style-simple callout-example callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 8.3: Prevalence of blood type O
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Consider a large population of blood donors in which the true proportion with type O blood is 45%. Suppose we randomly sample <span class="math inline">\(n=50\)</span> donors and record whether each has type O blood. The sample proportion of type O donors is <span class="math inline">\(\hat{p} = x/n\)</span>, where <span class="math inline">\(x\)</span> is the number of type O donors. Because <span class="math inline">\(x\)</span> follows a binomial distribution with parameters <span class="math inline">\((n,p) = (50,0.45)\)</span>, we know that <span class="math display">\[
E(\hat{p}) = 0.45
\]</span> and <span class="math display">\[
\sigma_{\hat{p}} = \sqrt{\frac{0.45\times 0.55}{50}} \approx 0.070
\]</span></p>
<p>To see the sampling distribution in action, we can simulate many samples and plot their proportions. Below is a histogram of <span class="math inline">\(\hat{p}\)</span> for 10,000 samples.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="08_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>The histogram of the simulated proportions (blue bars) lines up closely with the red Normal curve predicted by the theory. Most sample proportions fall within roughly two standard errors (about ¬±0.14) of the true proportion 0.45.</p>
</div>
</div>
</div>
</section>
<section id="conditions-for-the-normal-approximation" class="level3">
<h3 class="anchored" data-anchor-id="conditions-for-the-normal-approximation">Conditions for the normal approximation</h3>
<p>The <em>Normal approximation</em> to the sampling distribution of the sample proportion <span class="math inline">\(\hat{p}\)</span> is extremely useful, but it does not always work well. A common rule of thumb is that both</p>
<p><span class="math display">\[
np \ge 15 \quad \text{and} \quad n(1-p) \ge 15.
\]</span></p>
<p>Here:</p>
<ul>
<li><span class="math inline">\(np\)</span> is the expected number of <strong>successes</strong> in the sample,</li>
<li><span class="math inline">\(n(1-p)\)</span> is the expected number of <strong>failures</strong>.</li>
</ul>
<p>The sampling distribution of <span class="math inline">\(\hat{p}\)</span> is based on the binomial model. When the sample size is small or when the true proportion <span class="math inline">\(p\)</span> is very close to 0 or 1, the binomial distribution is <em>skewed</em>, not symmetric. In such cases, the bell-shaped Normal curve is a poor approximation.</p>
<p>The conditions <span class="math inline">\(np \ge 15\)</span> and <span class="math inline">\(n(1-p) \ge 15\)</span> ensure that:</p>
<ul>
<li>the distribution of the number of successes is reasonably symmetric,</li>
<li>and there are enough observations in both categories,</li>
</ul>
<p>When these conditions hold, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is well-approximated by a Normal distribution.</p>
<p>If either expected count is too small, several problems arise:</p>
<ul>
<li>The sampling distribution becomes <strong>skewed</strong>, often strongly.</li>
<li>The Normal approximation may give <strong>inaccurate probabilities</strong>.</li>
</ul>
<p>For example, if a company studies a rare event (say <span class="math inline">\(p=0.01\)</span>) with only <span class="math inline">\(n=50\)</span> customers, then</p>
<p><span class="math display">\[
np = 0.5,
\]</span></p>
<p>which is far below 15. The distribution of <span class="math inline">\(\hat{p}\)</span> in this case is highly right-skewed, and the Normal model performs poorly.</p>
<section id="what-to-do-when-the-condition-is-not-met" class="level4">
<h4 class="anchored" data-anchor-id="what-to-do-when-the-condition-is-not-met">What to do when the condition is not met</h4>
<p>When either <span class="math inline">\(np &lt; 15\)</span> or <span class="math inline">\(n(1-p) &lt; 15\)</span>, it is safer to use methods that do not rely on the Normal approximation, such as:</p>
<ul>
<li><strong>Exact binomial calculations</strong>, which use the true discrete distribution, or</li>
<li><strong>Bootstrap methods</strong> (Section 8.4), which approximate the sampling distribution through resampling.</li>
</ul>
<p>These approaches better capture skewness and discreteness when sample sizes are small or when proportions are extreme.</p>
<p>The Normal approximation for <span class="math inline">\(\hat{p}\)</span> works well only when there are <em>enough expected successes and failures</em>. Always check the conditions before applying Normal-based inference. When in doubt, especially with small samples or rare events, prefer exact or bootstrap methods to avoid misleading conclusions.</p>
</section>
</section>
<section id="working-in-jmp-1" class="level3">
<h3 class="anchored" data-anchor-id="working-in-jmp-1">Working in JMP</h3>
<p>To explore sampling distributions for proportions in JMP:</p>
<ul>
<li>Use <strong>Analyze ‚Üí Distribution</strong> on a binary variable (coded 1 for success and 0 for failure) to see the data distribution.</li>
<li>Use <strong>Graph Builder</strong> with the <strong>Bootstrap</strong> option to resample your data with replacement. Specify the statistic as <em>proportion of successes</em> and the number of bootstrap samples. JMP will display the bootstrap distribution, which closely approximates the theoretical sampling distribution when the sample is random and unbiased.</li>
</ul>
</section>
<section id="recap-1" class="level3">
<h3 class="anchored" data-anchor-id="recap-1">Recap</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 76%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Population proportion <span class="math inline">\(p\)</span></strong></td>
<td>The true fraction of individuals in the population with a certain characteristic.</td>
</tr>
<tr class="even">
<td><strong>Sample proportion <span class="math inline">\(\hat{p}\)</span></strong></td>
<td>The fraction of sampled individuals with the characteristic; an estimator of <span class="math inline">\(p\)</span>.</td>
</tr>
<tr class="odd">
<td><strong>Expected value of <span class="math inline">\(\hat{p}\)</span></strong></td>
<td>The expected value of the sampling distribution of <span class="math inline">\(\hat{p}\)</span>, equal to <span class="math inline">\(p\)</span>.</td>
</tr>
<tr class="even">
<td><strong>Standard deviation of <span class="math inline">\(\hat{p}\)</span></strong></td>
<td>The standard deviation of the sampling distribution of <span class="math inline">\(\hat{p}\)</span>, equal to <span class="math inline">\(\sqrt{p(1-p)/n}\)</span>.</td>
</tr>
<tr class="odd">
<td><strong>Normal approximation</strong></td>
<td>For large <span class="math inline">\(n\)</span> with <span class="math inline">\(np\ge15\)</span> and <span class="math inline">\(n(1-p)\ge15\)</span>, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is approximately normal.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-1" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-1">Check your understanding</h3>
<div class="callout callout-style-default callout-note callout-titled" title="Problems">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problems
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Explain why the sampling distribution of <span class="math inline">\(\hat{p}\)</span> has mean equal to the population proportion. What would it mean if the mean of <span class="math inline">\(\hat{p}\)</span> were systematically above or below <span class="math inline">\(p\)</span>?</li>
<li>Suppose the true prevalence of a rare mutation is 1%. If you sample <span class="math inline">\(n=100\)</span> individuals, will the sampling distribution of <span class="math inline">\(\hat{p}\)</span> be well approximated by a Normal distribution? Why or why not? How might you proceed instead?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Unbiasedness.</strong> If we took infinitely many random samples and averaged the sample proportions, we would recover the true population proportion. That is precisely what the expected value of <span class="math inline">\(\hat{p}\)</span> tells us: <span class="math inline">\(E(\hat{p})=p\)</span>. If the mean of <span class="math inline">\(\hat{p}\)</span> were consistently above <span class="math inline">\(p\)</span>, our estimator would be biased, systematically overestimating the true proportion.</p></li>
<li><p><strong>Rare mutation.</strong> When <span class="math inline">\(p\)</span> is very small (0.01) and <span class="math inline">\(n=100\)</span>, the expected number of successes is <span class="math inline">\(np=1\)</span> and the expected number of failures is 99. Because <span class="math inline">\(np&lt;15\)</span>, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is highly skewed and the normal approximation is poor. A better approach is to use the exact binomial distribution to compute probabilities or to use a bootstrap to approximate the sampling distribution (see Section 8.4).</p></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-08_03" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="sec-08_03"><span class="header-section-number">8.3</span> Sampling Distribution of the Sample Mean</h2>
<blockquote class="blockquote">
<p>‚ÄúThe Scientist must set in order. Science is built up with facts, as a house is with stones. But a collection of facts is no more a science than a heap of stones is a house.‚Äù - Henri Poincare</p>
</blockquote>
<p>The sample mean <span class="math inline">\(\bar{x}\)</span> is the workhorse of quantitative inference. Whenever we measure a quantitative trait‚Äîsuch as revenue per customer, delivery time, exam score, or daily sales‚Äîwe often reduce the data to a single summary: the average. This simple statistic captures the central tendency of the sample and serves as our primary estimate of the unknown population mean <span class="math inline">\(\mu\)</span>.</p>
<p>But for inference, computing <span class="math inline">\(\bar{x}\)</span> once is not enough. To draw conclusions about the population, we must understand how <span class="math inline">\(\bar{x}\)</span> behaves across repeated samples. In other words, we must study the <strong>sampling distribution of the sample mean</strong>.</p>
<p>Because samples are random, the value of <span class="math inline">\(\bar{x}\)</span> will vary from sample to sample. If we repeatedly:</p>
<ol type="1">
<li>Draw a random sample of size <span class="math inline">\(n\)</span>,</li>
<li>Compute the sample mean each time,</li>
<li>Plot all those means,</li>
</ol>
<p>the resulting distribution is the <em>sampling distribution of <span class="math inline">\(\bar{x}\)</span></em>.</p>
<p>This distribution tells us:</p>
<ul>
<li>how close <span class="math inline">\(\bar{x}\)</span> tends to be to <span class="math inline">\(\mu\)</span>,</li>
<li>how much sampling variability to expect,</li>
<li>and how precise our estimate is likely to be.</li>
</ul>
<p>These ideas are the foundation of <em>confidence intervals</em>, <em>hypothesis tests</em>, and many statistical models.</p>
<section id="properties-of-the-sampling-distribution-1" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-the-sampling-distribution-1">Properties of the sampling distribution</h3>
<p>Under mild and widely satisfied conditions, the sampling distribution of <span class="math inline">\(\bar{x}\)</span> has three powerful properties. The first two concern the mean and standard deviation of <span class="math inline">\(\bar{x}\)</span>.</p>
<section id="the-mean-of-barx-equals-the-population-mean" class="level4">
<h4 class="anchored" data-anchor-id="the-mean-of-barx-equals-the-population-mean">1. The mean of <span class="math inline">\(\bar{x}\)</span> equals the population mean</h4>
<p>If the population has mean <span class="math inline">\(\mu\)</span>, then</p>
<p><span class="math display">\[
E(\bar{x}) = \mu.
\]</span></p>
</section>
<section id="the-variability-of-barx-shrinks-with-sample-size" class="level4">
<h4 class="anchored" data-anchor-id="the-variability-of-barx-shrinks-with-sample-size">2. The variability of <span class="math inline">\(\bar{x}\)</span> shrinks with sample size</h4>
<p>The standard deviation of the sampling distribution of <span class="math inline">\(\bar{x}\)</span> is</p>
<p><span class="math display">\[
\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}},
\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the population standard deviation.</p>
<p>This quantity is called the <strong>standard error of the mean</strong>. It shows a crucial fact:</p>
<blockquote class="blockquote">
<p>Larger samples produce more precise estimates.</p>
</blockquote>
<p>Because of the <span class="math inline">\(\sqrt{n}\)</span> in the denominator, the variability of <span class="math inline">\(\bar{x}\)</span> decreases as sample size increases‚Äîbut with <em>diminishing returns</em>. Doubling the sample size does not cut the error in half; it reduces it by a factor of <span class="math inline">\(\sqrt{2}\)</span>.</p>
</section>
</section>
<section id="the-central-limit-theorem" class="level3">
<h3 class="anchored" data-anchor-id="the-central-limit-theorem">The Central Limit Theorem</h3>
<p>The third property involves the shape of the sampling distribution of <span class="math inline">\(\bar{x}\)</span>. The <strong>Central Limit Theorem</strong> (CLT) is one of the pillars of statistics. It states that when we randomly sample from any population with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, the sampling distribution of <span class="math inline">\(\bar{x}\)</span> becomes approximately normal as the sample size <span class="math inline">\(n\)</span> grows. In symbols, <span class="math display">\[
\bar{X} \overset{\cdot}{\sim} N\bigl(\mu,\, \sigma/\sqrt{n}\bigr)
\]</span> for sufficiently large <span class="math inline">\(n\)</span>. Note that the dot (<span class="math inline">\(\cdot\)</span>) above <span class="math inline">\(\sim\)</span> means ‚Äúapproximately distributed as‚Äù.</p>
<p>The beauty of the CLT is that it does not require the underlying population to be normal; even strongly skewed or irregular distributions yield approximately normal sample means when <span class="math inline">\(n\)</span> is large enough.</p>
<div class="callout callout-style-simple callout-example callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 8.4: Simulated Enzyme Activities
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Enzyme activity measurements often follow a skewed distribution because they cannot be negative but can have long right tails. Suppose the true activity in a population of cells follows an exponential distribution. We take repeated random samples of different sizes and compute the sample mean for each. The following plot shows 10,000 simulated sample means for <span class="math inline">\(n=5\)</span>, <span class="math inline">\(n=20\)</span> and <span class="math inline">\(n=50\)</span> to illustrate how the distribution of <span class="math inline">\(\bar{x}\)</span> evolves:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="08_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>The three panels show that for very small samples (<span class="math inline">\(n=5\)</span>) the sampling distribution of <span class="math inline">\(\bar{x}\)</span> still retains some skewness. For moderate samples (<span class="math inline">\(n=20\)</span>) the distribution looks more bell‚Äëshaped, and by <span class="math inline">\(n=50\)</span> it is nearly indistinguishable from the Normal curve (red line). This behavior is exactly what the CLT predicts.</p>
</div>
</div>
</div>
</section>
<section id="practical-considerations" class="level3">
<h3 class="anchored" data-anchor-id="practical-considerations">Practical considerations</h3>
<p>The CLT justifies using normal‚Äëbased methods for many statistics, but it is not a panacea. Large samples are not always attainable. Sometimes cost, difficulty or the preciousness of biological material limits the sample size. In such cases the sampling distribution of <span class="math inline">\(\bar{x}\)</span> may be far from normal, especially for very skewed or heavy‚Äëtailed populations. Diagnostic plots and simulation can help you gauge whether normal approximations are reasonable.</p>
<p>If the data is not available, then the rule-of-thumb of <span class="math inline">\(n\ge 30\)</span> is adequate in most situations to determine if the sample size is large enough.</p>
</section>
<section id="working-in-jmp-2" class="level3">
<h3 class="anchored" data-anchor-id="working-in-jmp-2">Working in JMP</h3>
<p>To explore the sampling distribution of the mean in JMP:</p>
<ul>
<li>Use <strong>Analyze ‚Üí Distribution</strong> to visualise your quantitative data and estimate the population standard deviation.</li>
<li>Choose <strong>Analyze ‚Üí Resampling</strong> and select <strong>Bootstrap</strong>. Specify the statistic as the <em>mean</em> and set the number of resamples. JMP will generate a bootstrap sampling distribution of <span class="math inline">\(\bar{x}\)</span>, plot it and report the standard error. You can compare the bootstrap distribution to a Normal distribution with mean equal to the observed <span class="math inline">\(\bar{x}\)</span> and standard deviation equal to the bootstrap standard error.</li>
</ul>
</section>
<section id="recap-2" class="level3">
<h3 class="anchored" data-anchor-id="recap-2">Recap</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 81%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Standard deviation of <span class="math inline">\(\bar{x}\)</span></strong></td>
<td>The standard deviation of the sampling distribution of <span class="math inline">\(\bar{x}\)</span>, equal to <span class="math inline">\(\sigma/\sqrt{n}\)</span>.</td>
</tr>
<tr class="even">
<td><strong>Central Limit Theorem (CLT)</strong></td>
<td>States that for large <span class="math inline">\(n\)</span>, the sampling distribution of the sample mean is approximately normal with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma/\sqrt{n}\)</span>.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-2" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-2">Check your understanding</h3>
<div class="callout callout-style-default callout-note callout-titled" title="Problems">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problems
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>A laboratory measures the enzyme activity of 10 randomly selected yeast cultures. The population distribution is known to be highly skewed with mean 50 units and standard deviation 20 units. Without doing any calculations, would you expect the sample mean to follow a Normal distribution? Explain your reasoning.</li>
<li>A nutritionist samples 64 adults and measures their daily vitamin D intake. The population mean intake is 600 IU with standard deviation 200 IU. What is the mean and standard deviation of the sampling distribution of <span class="math inline">\(\bar{x}\)</span>? If the intake distribution is skewed, is the Normal approximation still reasonable? Why or why not?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Small, skewed samples.</strong> With a sample size of 10 and a highly skewed population, the sampling distribution of <span class="math inline">\(\bar{x}\)</span> will retain noticeable skewness. The Central Limit Theorem requires larger <span class="math inline">\(n\)</span> before the distribution of the sample mean becomes approximately normal, so caution is warranted when applying Normal approximations.</p></li>
<li><p><strong>Vitamin D intake.</strong> The sampling distribution has mean <span class="math inline">\(\mu = 600\)</span> and standard deviation <span class="math inline">\(200/\sqrt{64} = 25\)</span>. Because <span class="math inline">\(n=64\)</span> is reasonably large, the CLT suggests that the sample mean will be approximately normal even if the individual intakes are skewed. Therefore the Normal approximation should be adequate.</p></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-08_04" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="sec-08_04"><span class="header-section-number">8.4</span> Bootstrap Sampling Distribution</h2>
<blockquote class="blockquote">
<p>‚ÄúIt is the mark of a truly intelligent person to be moved by statistics.‚Äù -George Bernard Shaw</p>
</blockquote>
<p>Sometimes we cannot rely on tidy formulas or the Central Limit Theorem (CLT) to determine the sampling distribution of a statistic. The CLT works beautifully for sample means under broad conditions, but many practical situations fall outside its comfort zone. For example:</p>
<ul>
<li>The statistic of interest may have a <strong>complicated distribution</strong> (such as the median, a trimmed mean, a percentile, or a regression coefficient).</li>
<li>The sample size may be <strong>too small</strong> for Normal approximations to be reliable.</li>
<li>The population distribution may be <strong>strongly skewed</strong> or heavy-tailed.</li>
<li>The standard error formula may be <strong>unknown or difficult to derive</strong>.</li>
</ul>
<p>In these settings, classical theoretical methods either become inaccurate or require mathematics that is impractical to work out by hand. <strong>Bootstrapping</strong> provides a powerful, data-driven alternative.</p>
<p>Bootstrapping is a resampling method that approximates the sampling distribution of a statistic by using the data we already have. Instead of imagining all possible samples from the population (which we cannot see), we treat the observed sample as a <strong>stand-in for the population</strong> and repeatedly resample from it.</p>
<p>The name comes from the phrase <em>‚Äúpulling yourself up by your bootstraps‚Äù</em>‚Äîwe use the sample to learn about its own variability.</p>
<p>The key insight is:</p>
<blockquote class="blockquote">
<p>If the sample is representative of the population, then resampling from the sample mimics sampling from the population.</p>
</blockquote>
<section id="how-bootstrapping-works" class="level3">
<h3 class="anchored" data-anchor-id="how-bootstrapping-works">How bootstrapping works</h3>
<p>Suppose we have a sample of size <span class="math inline">\(n\)</span> and a statistic of interest (say the median).</p>
<p>A bootstrap procedure typically follows these steps:</p>
<ol type="1">
<li><strong>Start with the original sample</strong> of size <span class="math inline">\(n\)</span>.</li>
<li><strong>Resample with replacement</strong> from the sample to create a bootstrap sample of size <span class="math inline">\(n\)</span>.</li>
<li><strong>Compute the statistic</strong> (e.g., the median) for this bootstrap sample.</li>
<li><strong>Repeat</strong> steps 2‚Äì3 many times (often thousands).</li>
<li><strong>Examine the distribution</strong> of the bootstrap statistics.</li>
</ol>
<p>The resulting distribution is called the <strong>bootstrap distribution</strong>, and it serves as an approximation to the true sampling distribution of the statistic.</p>
<div class="callout callout-style-simple callout-example callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 8.5: Median Tumor Size
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Imagine a study measuring the diameters (in millimeters) of 25 tumors detected in a mammogram screening. The sample is small and the data are skewed; we want to estimate the sampling distribution of the median tumor size. A bootstrap approach provides the following:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="08_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>The histogram shows the bootstrap distribution of the median tumor size. From this distribution we can compute a bootstrap standard deviation (the standard deviation of the bootstrap medians) and make inferences.</p>
</div>
</div>
</div>
</section>
<section id="why-bootstrapping-is-useful" class="level3">
<h3 class="anchored" data-anchor-id="why-bootstrapping-is-useful">Why bootstrapping is useful</h3>
<p>Bootstrapping is especially valuable when:</p>
<ul>
<li>the sampling distribution is mathematically intractable,</li>
<li>the statistic is not well handled by the CLT,</li>
<li>the sample size is modest,</li>
<li>or we want a flexible, computer-based solution.</li>
</ul>
<p>From the bootstrap distribution we can estimate:</p>
<ul>
<li>the <strong>standard error</strong> of the statistic,</li>
<li><strong>confidence intervals</strong>,</li>
<li><strong>bias</strong> in the estimator,</li>
<li>and the overall <strong>shape</strong> of the sampling distribution.</li>
</ul>
<p>In modern statistics, bootstrapping is widely used because it replaces difficult mathematics with computation.</p>
</section>
<section id="when-to-be-cautious" class="level3">
<h3 class="anchored" data-anchor-id="when-to-be-cautious">When to be cautious</h3>
<p>Bootstrapping is powerful but not magic. It works best when:</p>
<ul>
<li>the original sample is <strong>representative</strong> of the population,</li>
<li>observations are <strong>independent</strong>,</li>
<li>and the sample size is not extremely small.</li>
</ul>
<p>If the sample is biased or too tiny to reflect the population‚Äôs structure, the bootstrap will faithfully reproduce those problems.</p>
</section>
<section id="the-big-picture" class="level3">
<h3 class="anchored" data-anchor-id="the-big-picture">The big picture</h3>
<p>Classical inference relies on theoretical sampling distributions derived from probability models. Bootstrapping takes a different approach:</p>
<ul>
<li><strong>Theory-based inference:</strong> derive the sampling distribution mathematically.</li>
<li><strong>Bootstrap inference:</strong> approximate the sampling distribution computationally.</li>
</ul>
<p>When formulas are unavailable or unreliable, bootstrapping provides a practical and remarkably effective way to understand the variability of complex statistics directly from the data.</p>
</section>
<section id="working-in-jmp-3" class="level3">
<h3 class="anchored" data-anchor-id="working-in-jmp-3">Working in JMP</h3>
<p>JMP has built‚Äëin bootstrap tools that make resampling easy:</p>
<ul>
<li>After running an analysis (for example <strong>Analyze ‚Üí Fit Y by X</strong> for comparing two groups), click the red triangle menu (‚ñ∏) and select <strong>Bootstrap</strong>. Choose the statistic you wish to bootstrap and the number of resamples. JMP will create a bootstrap distribution, display it and report standard errors and confidence intervals.</li>
<li>For custom statistics, use <strong>Tables ‚Üí Bootstrap Data</strong> to generate bootstrap samples from your dataset. You can then analyse each bootstrap sample using your preferred platform and collect the statistic of interest.</li>
</ul>
</section>
<section id="recap-3" class="level3">
<h3 class="anchored" data-anchor-id="recap-3">Recap</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 78%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Bootstrapping</strong></td>
<td>A resampling method that uses the observed data to approximate a sampling distribution by repeatedly sampling with replacement.</td>
</tr>
<tr class="even">
<td><strong>Bootstrap sample</strong></td>
<td>A sample of size <span class="math inline">\(n\)</span> drawn with replacement from the original sample.</td>
</tr>
<tr class="odd">
<td><strong>Bootstrap statistic</strong></td>
<td>The value of the statistic computed on a bootstrap sample.</td>
</tr>
<tr class="even">
<td><strong>Bootstrap distribution</strong></td>
<td>The distribution of many bootstrap statistics; an empirical approximation to the sampling distribution.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-3" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-3">Check your understanding</h3>
<div class="callout callout-style-default callout-note callout-titled" title="Problems">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problems
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Why do we sample <em>with replacement</em> when constructing a bootstrap sample? What would go wrong if we sampled without replacement?</li>
<li>Compare and contrast the bootstrap distribution with the theoretical sampling distribution. Under what circumstances do they coincide, and when might they differ?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Replacement is essential.</strong> Sampling with replacement allows each observation to appear multiple times‚Äîor not at all‚Äîin a bootstrap sample. This mimics the variability of drawing new samples from the population. Sampling without replacement would simply rearrange the data and fail to capture the variability inherent in new samples.</p></li>
<li><p><strong>Bootstrap vs.&nbsp;theoretical.</strong> The bootstrap distribution approximates the theoretical sampling distribution when the sample is random and representative, and when the number of bootstrap resamples is large. For statistics with simple known sampling distributions (like means and proportions), the bootstrap will agree closely with theory. For statistics whose sampling distributions are complicated or unknown, the bootstrap provides a practical alternative but may differ from the true sampling distribution, especially when the sample size is very small or the sample is biased.</p></li>
</ol>
</div>
</div>
</div>


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Data was obtained from Introductory Statistical Methods classes. Here, we are treating these values as a population.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>