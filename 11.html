<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STA 2381 Introductory Statistical Methods - 11&nbsp; Hypothesis Testing with Categorical Response</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style type="text/css">
.sidebar .chapter-number {
color: #FFB81c;
}
freeblank {
  color: transparent;
  cursor: pointer;
}
freeblank.clicked {
  color: red;
}
blank {
  display: inline-block; 
  position: relative;
  padding: 0 10px;
  color: transparent;
  cursor: pointer;
}
blank::before {
  content: ''; /* Creates a custom underline */
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  height: 1px; /* Thickness of the underline */
  background-color: black; /* Color of the underline */
}
blank.clicked {
  color: red;
}
</style>
<script>
document.addEventListener('click', (event) => {
  if (event.target.tagName === 'BLANK') {
    event.target.classList.add('clicked');
  }
});
document.addEventListener('click', (event) => {
  if (event.target.tagName === 'FREEBLANK') {
    event.target.classList.add('clicked');
  }
});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./11.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Hypothesis Testing with Categorical Response</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Collecting Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Describing Data with Tables and Graphs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Describing Data with Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability Concepts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Estimation and Confidence Intervals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Hypothesis Testing: The Basics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Hypothesis Testing with Categorical Response</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Methods for Quantitative Response Variables – One and Two Groups</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Analysis of Variance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Correlation and Simple Linear Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-response-explanatory" id="toc-sec-response-explanatory" class="nav-link active" data-scroll-target="#sec-response-explanatory"><span class="header-section-number">11.1</span> Response and Explanatory Variables</a>
  <ul class="collapse">
  <li><a href="#response-variable" id="toc-response-variable" class="nav-link" data-scroll-target="#response-variable">Response Variable</a></li>
  <li><a href="#explanatory-variable" id="toc-explanatory-variable" class="nav-link" data-scroll-target="#explanatory-variable">Explanatory Variable</a></li>
  <li><a href="#relationship-between-the-two" id="toc-relationship-between-the-two" class="nav-link" data-scroll-target="#relationship-between-the-two">Relationship Between the Two</a></li>
  <li><a href="#recap" id="toc-recap" class="nav-link" data-scroll-target="#recap">Recap</a></li>
  <li><a href="#check-your-understanding" id="toc-check-your-understanding" class="nav-link" data-scroll-target="#check-your-understanding">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-11_01" id="toc-sec-11_01" class="nav-link" data-scroll-target="#sec-11_01"><span class="header-section-number">11.2</span> One Sample Test for a Proportion</a>
  <ul class="collapse">
  <li><a href="#hypotheses-and-assumptions" id="toc-hypotheses-and-assumptions" class="nav-link" data-scroll-target="#hypotheses-and-assumptions">Hypotheses and assumptions</a></li>
  <li><a href="#test-statistic-and-pvalue" id="toc-test-statistic-and-pvalue" class="nav-link" data-scroll-target="#test-statistic-and-pvalue">Test statistic and p‑value</a></li>
  <li><a href="#posthoc-confidence-interval" id="toc-posthoc-confidence-interval" class="nav-link" data-scroll-target="#posthoc-confidence-interval">Post‑hoc confidence interval</a></li>
  <li><a href="#example-side-effects-of-a-vaccine" id="toc-example-side-effects-of-a-vaccine" class="nav-link" data-scroll-target="#example-side-effects-of-a-vaccine">Example – Side effects of a vaccine</a></li>
  <li><a href="#example-color-morph-frequency" id="toc-example-color-morph-frequency" class="nav-link" data-scroll-target="#example-color-morph-frequency">Example – Color morph frequency</a></li>
  <li><a href="#check-your-understanding-1" id="toc-check-your-understanding-1" class="nav-link" data-scroll-target="#check-your-understanding-1">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-11_02" id="toc-sec-11_02" class="nav-link" data-scroll-target="#sec-11_02"><span class="header-section-number">11.3</span> Test for Difference in Proportions</a>
  <ul class="collapse">
  <li><a href="#hypotheses-and-assumptions-1" id="toc-hypotheses-and-assumptions-1" class="nav-link" data-scroll-target="#hypotheses-and-assumptions-1">Hypotheses and assumptions</a></li>
  <li><a href="#test-statistic" id="toc-test-statistic" class="nav-link" data-scroll-target="#test-statistic">Test statistic</a></li>
  <li><a href="#posthoc-confidence-interval-and-multiple-comparisons" id="toc-posthoc-confidence-interval-and-multiple-comparisons" class="nav-link" data-scroll-target="#posthoc-confidence-interval-and-multiple-comparisons">Post‑hoc confidence interval and multiple comparisons</a></li>
  <li><a href="#example-treatment-success-rates" id="toc-example-treatment-success-rates" class="nav-link" data-scroll-target="#example-treatment-success-rates">Example– Treatment success rates</a></li>
  <li><a href="#example-genotype-frequencies" id="toc-example-genotype-frequencies" class="nav-link" data-scroll-target="#example-genotype-frequencies">Example – Genotype frequencies</a></li>
  <li><a href="#example-ab-testing" id="toc-example-ab-testing" class="nav-link" data-scroll-target="#example-ab-testing">Example – A/B testing</a></li>
  <li><a href="#check-your-understanding-2" id="toc-check-your-understanding-2" class="nav-link" data-scroll-target="#check-your-understanding-2">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-11_03" id="toc-sec-11_03" class="nav-link" data-scroll-target="#sec-11_03"><span class="header-section-number">11.4</span> Chi‑Square Goodness of Fit</a>
  <ul class="collapse">
  <li><a href="#hypotheses-and-assumptions-2" id="toc-hypotheses-and-assumptions-2" class="nav-link" data-scroll-target="#hypotheses-and-assumptions-2">Hypotheses and assumptions</a></li>
  <li><a href="#test-statistic-1" id="toc-test-statistic-1" class="nav-link" data-scroll-target="#test-statistic-1">Test statistic</a></li>
  <li><a href="#posthoc-analysisbonferroni-confidence-intervals" id="toc-posthoc-analysisbonferroni-confidence-intervals" class="nav-link" data-scroll-target="#posthoc-analysisbonferroni-confidence-intervals">Post‑hoc analysis:Bonferroni confidence intervals</a></li>
  <li><a href="#example-mendelian-inheritance" id="toc-example-mendelian-inheritance" class="nav-link" data-scroll-target="#example-mendelian-inheritance">Example – Mendelian inheritance</a></li>
  <li><a href="#check-your-understanding-3" id="toc-check-your-understanding-3" class="nav-link" data-scroll-target="#check-your-understanding-3">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-11_04" id="toc-sec-11_04" class="nav-link" data-scroll-target="#sec-11_04"><span class="header-section-number">11.5</span> Chi‑Square Test for Association</a>
  <ul class="collapse">
  <li><a href="#hypotheses-and-assumptions-3" id="toc-hypotheses-and-assumptions-3" class="nav-link" data-scroll-target="#hypotheses-and-assumptions-3">Hypotheses and assumptions</a></li>
  <li><a href="#test-statistic-2" id="toc-test-statistic-2" class="nav-link" data-scroll-target="#test-statistic-2">Test statistic</a></li>
  <li><a href="#posthoc-analysis" id="toc-posthoc-analysis" class="nav-link" data-scroll-target="#posthoc-analysis">Post‑hoc analysis</a></li>
  <li><a href="#example-11.10-smoking-status-and-lung-disease-medicine" id="toc-example-11.10-smoking-status-and-lung-disease-medicine" class="nav-link" data-scroll-target="#example-11.10-smoking-status-and-lung-disease-medicine">Example 11.10 – Smoking status and lung disease (medicine)</a></li>
  <li><a href="#check-your-understanding-4" id="toc-check-your-understanding-4" class="nav-link" data-scroll-target="#check-your-understanding-4">Check your understanding</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Hypothesis Testing with Categorical Response</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="sec-response-explanatory" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="sec-response-explanatory"><span class="header-section-number">11.1</span> Response and Explanatory Variables</h2>
<blockquote class="blockquote">
<p>“Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.” - H.G. Wells</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>How do we distinguish between the variable we are trying to understand and the variable(s) that might explain it?</em></p>
</blockquote>
<p>Every statistical study involves variables that play different roles. Two of the most important are the <em>response variable</em> and the <em>explanatory variable</em>.</p>
<section id="response-variable" class="level3">
<h3 class="anchored" data-anchor-id="response-variable">Response Variable</h3>
<p>The <blank>response variable</blank> (sometimes called the <em>dependent variable</em> or <em>outcome variable</em>) measures the result or outcome we want to understand, predict, or explain.</p>
<p>Examples include:</p>
<ul>
<li>In a medical study, the response variable might be <em>whether a patient recovers</em> (yes/no) or the <em>reduction in blood pressure</em> (in mmHg).</li>
<li>In a business context, it could be <em>sales revenue</em>, <em>customer satisfaction score</em>, or <em>whether a customer makes a repeat purchase</em>.</li>
<li>In biology, it could be <em>plant height</em>, <em>growth rate</em>, or <em>presence of a mutation</em>.</li>
</ul>
<p>The response variable answers the question: <em>“What outcome are we interested in?”</em></p>
</section>
<section id="explanatory-variable" class="level3">
<h3 class="anchored" data-anchor-id="explanatory-variable">Explanatory Variable</h3>
<p>The <blank>explanatory variable</blank> (also called the <em>independent variable</em>, <em>predictor</em>, or <em>factor</em>) is the variable that we think might help explain or predict changes in the response.</p>
<p>Examples include:</p>
<ul>
<li>In a clinical trial, the explanatory variable could be <em>treatment type</em> (new drug vs.&nbsp;placebo).</li>
<li>In a marketing experiment, it might be <em>advertising strategy</em> or <em>price level</em>.</li>
<li>In an ecological study, it could be <em>amount of sunlight</em> or <em>soil type</em> affecting plant growth.</li>
</ul>
<p>Sometimes there are <blank>multiple</blank> explanatory variables. For instance, a researcher studying cholesterol levels might consider both <em>diet</em> and <em>exercise level</em>.</p>
</section>
<section id="relationship-between-the-two" class="level3">
<h3 class="anchored" data-anchor-id="relationship-between-the-two">Relationship Between the Two</h3>
<ul>
<li>We use explanatory variables to describe or predict changes in the response variable.</li>
<li>The direction of explanation goes from <em>explanatory → response</em>, not the other way around.</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 18%">
<col style="width: 43%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Type of Study</strong></th>
<th><strong>Response Variable</strong></th>
<th><strong>Explanatory Variable(s)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Medical Trial</td>
<td>Whether patient’s blood pressure decreases</td>
<td>Drug type (placebo vs.&nbsp;new drug)</td>
</tr>
<tr class="even">
<td>Business Survey</td>
<td>Customer satisfaction (1–10 scale)</td>
<td>Wait time, price, or service quality</td>
</tr>
<tr class="odd">
<td>Biology Experiment</td>
<td>Growth of seedlings (cm)</td>
<td>Amount of fertilizer or sunlight</td>
</tr>
</tbody>
</table>
<p>In <em>experiments</em>, researchers manipulate the explanatory variable to study its effect on the response. In <em>observational studies</em>, the explanatory variable is merely recorded, not controlled—so we must be cautious about claiming causation.</p>
</section>
<section id="recap" class="level3">
<h3 class="anchored" data-anchor-id="recap">Recap</h3>
<table class="table">
<colgroup>
<col style="width: 24%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Response variable</strong></td>
<td>The outcome or result measured in a study; the variable of primary interest.</td>
</tr>
<tr class="even">
<td><strong>Explanatory variable</strong></td>
<td>The variable thought to explain or predict changes in the response.</td>
</tr>
<tr class="odd">
<td><strong>Dependent vs.&nbsp;independent</strong></td>
<td>“Dependent” refers to the response variable; “independent” refers to the explanatory variable.</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="check-your-understanding" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding">Check your understanding</h3>
<ol type="1">
<li><p>Identify the response and explanatory variables in each scenario:</p>
<ul>
<li><ol type="a">
<li>A company studies whether providing flexible work hours increases employee productivity.</li>
</ol></li>
<li><ol start="2" type="a">
<li>A biologist examines whether soil pH affects seed germination rate.</li>
</ol></li>
<li><ol start="3" type="a">
<li>An economist studies whether interest rates influence consumer spending.</li>
</ol></li>
</ul></li>
<li><p>In which of the above examples would it be appropriate to claim a cause-and-effect relationship? Why?</p></li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li></li>
</ol>
<ul>
<li><ol type="a">
<li><strong>Response:</strong> employee productivity; <strong>Explanatory:</strong> work-schedule type (flexible vs.&nbsp;fixed).</li>
</ol></li>
<li><ol start="2" type="a">
<li><strong>Response:</strong> germination rate; <strong>Explanatory:</strong> soil pH.</li>
</ol></li>
<li><ol start="3" type="a">
<li><strong>Response:</strong> consumer spending; <strong>Explanatory:</strong> interest rate.</li>
</ol></li>
</ul>
<ol start="2" type="1">
<li>Cause-and-effect can be claimed <strong>only</strong> in a true experiment—typically case (a) or (b) if the explanatory variable is <em>controlled</em> by the researcher. In (c), interest rates are not manipulated by the researcher but merely observed, so the study is observational and cannot establish causation.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-11_01" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="sec-11_01"><span class="header-section-number">11.2</span> One Sample Test for a Proportion</h2>
<blockquote class="blockquote">
<p>“60% of the time, it works every time.” - Brian Fantana</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>How do we test whether a single proportion equals a hypothesized value?</em></p>
</blockquote>
<p>To decide on a statistical method, we should first start with asking what type of response variable we have (or will have). There are two main types: <blank>quantitative</blank> and <blank>categorical</blank>.</p>
<p>After we determine the type of the response variable, we should then determine the explanatory variables (if any). We can think of this in terms of a flowchart:</p>
<p><img src="images/02.png" class="img-fluid"></p>
<p>For the rest of this chapter, we will focus on a categorical response variable (the blue side on the flowchart). We will then cover different methods depending on the type and number of explanatory variables.</p>
<section id="hypotheses-and-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="hypotheses-and-assumptions">Hypotheses and assumptions</h3>
<p>Our first method is the scenario where the response is categorical but there are no explanatory variables. In particular, the response variable is binary and we are interested in making an inference of the proportion of the population for one of those categories.</p>
<p><img src="images/04.png" class="img-fluid"></p>
<p>Let <span class="math inline">\(p\)</span> denote the true proportion of interest and let <span class="math inline">\(p_0\)</span> be the hypothesized value.</p>
<p>The <em>null hypothesis</em> states that the population proportion equals the hypothesized value. The <em>alternative hypothesis</em> may be two‑sided if we simply want to detect any difference, or one‑sided if we are interested in increases or decreases.</p>
<p><span class="math display">\[
\begin{align*}
H_0&amp;: p = p_0\\
H_a&amp;: p \ne p_0\quad\text{ or }\quad p&gt;p_0\quad\text{ or }\quad p&lt;p_o
\end{align*}
\]</span></p>
<p>Like all inference procedures, this test requires certain conditions. We assume a <blank>simple random sample</blank> from a population of independent Bernoulli trials. Each trial has two categories (success/failure) and a constant probability of success. We must also have at least 15 successes and 15 failures (<span class="math inline">\(np\geq15\)</span> and <span class="math inline">\(n(1-p)\geq15\)</span>) so that the normal approximation is reasonable. These “success–failure” conditions ensure the sampling distribution of the sample proportion is approximately normal.</p>
</section>
<section id="test-statistic-and-pvalue" class="level3">
<h3 class="anchored" data-anchor-id="test-statistic-and-pvalue">Test statistic and p‑value</h3>
<p>Given a sample of size <span class="math inline">\(n\)</span> with <span class="math inline">\(x\)</span> successes, the <em>sample proportion</em> is <span class="math inline">\(\hat{p}=x/n\)</span>. Under <span class="math inline">\(H_0\)</span> the test statistic</p>
<p><span class="math display">\[
z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}
\]</span></p>
<p>measures how many standard errors the sample proportion deviates from the hypothesized proportion. For a two‑sided alternative the p‑value is <span class="math inline">\(2P(Z &gt; |z|)\)</span>; for a one‑sided alternative we compute <span class="math inline">\(P(Z &gt; z)\)</span> or <span class="math inline">\(P(Z &lt; z)\)</span> depending on the direction. If the p‑value is less than the significance level <span class="math inline">\(\alpha\)</span>, we reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_a\)</span>.</p>
</section>
<section id="posthoc-confidence-interval" class="level3">
<h3 class="anchored" data-anchor-id="posthoc-confidence-interval">Post‑hoc confidence interval</h3>
<p>When the test is significant, a <em>confidence interval</em> for <span class="math inline">\(p\)</span> provides context. A <span class="math inline">\((1-\alpha)\times100\%\)</span> interval is</p>
<p><span class="math display">\[
\hat{p} \pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}},
\]</span></p>
<p>where <span class="math inline">\(z_{\alpha/2}\)</span> is the critical value from the standard normal distribution. This interval uses the sample proportion in place of the hypothesized value in the standard error. It gives a range of plausible values for <span class="math inline">\(p\)</span> and helps assess practical importance.</p>
</section>
<section id="example-side-effects-of-a-vaccine" class="level3">
<h3 class="anchored" data-anchor-id="example-side-effects-of-a-vaccine">Example – Side effects of a vaccine</h3>
<p>Suppose a pharmaceutical company wishes to evaluate whether fewer than a quarter of patients experience a mild rash after receiving a vaccine. In a random sample of <span class="math inline">\(n=200\)</span> vaccinated patients, <span class="math inline">\(x=38\)</span> report a rash. We test</p>
<p><span class="math display">\[
H_0: p = 0.25 \quad\text{versus}\quad H_a: p &lt; 0.25
\]</span></p>
<p>using <span class="math inline">\(\alpha=0.05\)</span>. The sample proportion is <span class="math inline">\(\hat{p} = 38/200 = 0.19\)</span>. Plugging into the test statistic formula gives</p>
<p><span class="math display">\[
z = \frac{0.19 - 0.25}{\sqrt{\frac{0.25\times 0.75}{200}}} \approx -2.06.
\]</span></p>
<p>For a one‑sided test the p‑value is <span class="math inline">\(P(Z &lt; -2.06) \approx 0.0198\)</span>, which is below 0.05. We reject <span class="math inline">\(H_0\)</span> and conclude that the rash rate is lower than 25%.</p>
<p>A 95 % confidence interval for <span class="math inline">\(p\)</span> is 5 <span class="math display">\[
0.19 \pm 1.96\sqrt{\frac{0.19\times0.81}{200}} = (0.13, 0.244).
\]</span></p>
<p>This interval suggests the true proportion lies somewhere between 13.5% and 24.4%, consistent with our conclusion.</p>
<section id="performing-the-onesample-proportion-test-in-jmp-pro-18" class="level4">
<h4 class="anchored" data-anchor-id="performing-the-onesample-proportion-test-in-jmp-pro-18">Performing the one‑sample proportion test in JMP Pro 18</h4>
<ol type="1">
<li><strong>Enter or import the data.</strong> Create a column for the binary response (e.g., “Rash”) coded with two categories (Yes/No). If you have counts rather than individual observations, include a <strong>Freq</strong> column containing the counts.</li>
<li><strong>Launch the Distribution platform.</strong> Choose <code>Analyze → Distribution</code>, assign the response to Y and the Freq column (if present) to <strong>Freq</strong>, and click OK. JMP will display counts, proportions and a bar chart.</li>
<li><strong>Test the proportion.</strong> Click the red triangle next to the variable’s name and choose <strong>Test Probabilities</strong>. Enter the hypothesized proportion <span class="math inline">\(p_0\)</span>; JMP reports the <strong>Pearson <span class="math inline">\(\chi^2\)</span></strong> statistic and associated p‑value. The Pearson statistic is <span class="math inline">\(z^2\)</span> for a two‑sided test, so you can recover <span class="math inline">\(z\)</span> by taking its square root and assigning the sign based on <span class="math inline">\(\hat{p}-p_0\)</span>.</li>
<li><strong>Confidence interval.</strong> Under the same menu choose <strong>Confidence Interval</strong>. Specify the confidence level (e.g., 0.95). JMP calculates the interval using the standard normal approximation as above.</li>
</ol>
</section>
</section>
<section id="example-color-morph-frequency" class="level3">
<h3 class="anchored" data-anchor-id="example-color-morph-frequency">Example – Color morph frequency</h3>
<p>A biologist studying a species of lizard notes that 40 out of 150 captured individuals have a rare blue color morph. Is there evidence that the morph frequency differs from 20%? We set up</p>
<p><span class="math display">\[
H_0: p = 0.20 \quad\text{vs.}\quad H_a: p \neq 0.20.
\]</span></p>
<p>We could perform this test by manually doing the calculations like the last example. Instead, we will use the Calculators available in JMP 18 Student Edition.</p>
<p><img src="images/zptest1.png" class="img-fluid"></p>
<p>The p‑value is <span class="math inline">\(P(Z &gt; 2.0412) =0.0412\)</span>. At <span class="math inline">\(\alpha=0.05\)</span> we <em>reject</em> <span class="math inline">\(H_0\)</span>; the data provides enough evidence to conclude that the blue morph frequency differs from 20%.</p>
<p><img src="images/zptest2.png" class="img-fluid"></p>
<p>A 95% confidence interval for <span class="math inline">\(p\)</span> is <span class="math inline">\((0.1959, 0.3374)\)</span>. Note that the confidence interval just passes 0.20 on the lower limit. This is due to the confidence interval uses <span class="math inline">\(\hat p\)</span> in the standard error where as the test statistic uses the hypothesized value <span class="math inline">\(p_0\)</span>. A larger study might yield a more definitive conclusion.</p>
<section id="example-customer-satisfaction" class="level4">
<h4 class="anchored" data-anchor-id="example-customer-satisfaction">Example – Customer satisfaction</h4>
<p>A retailer advertises that 85% of its customers are satisfied with the online shopping experience. An independent survey of 250 recent customers finds that 192 report being satisfied. We test</p>
<p><span class="math display">\[
H_0: p = 0.85 \quad\text{vs.}\quad H_a: p &lt; 0.85.
\]</span></p>
<p>Here <span class="math inline">\(\hat{p} = 192/250 = 0.768\)</span>. The z‑statistic is <span class="math inline">\((0.768-0.85)/\sqrt{0.85\times 0.15/250} \approx -3.34\)</span> with p‑value <span class="math inline">\(&lt;0.001\)</span>. The data provide strong evidence that the true satisfaction rate is below the advertised 85%. A 9 % confidence interval for <span class="math inline">\(p\)</span> is <span class="math inline">\((0.72, 0.81)\)</span>, well below 0.85. Companies often report high satisfaction percentages in advertisements, but independent surveys can reveal gaps between perception and reality.</p>
</section>
<section id="recap-1" class="level4">
<h4 class="anchored" data-anchor-id="recap-1">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition/Formula</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Null hypothesis</strong> <span class="math inline">\(H_0: p=p_0\)</span></td>
<td>Assumes the population proportion equals the hypothesized value <span class="math inline">\(p_0\)</span>.</td>
</tr>
<tr class="even">
<td><strong>Alternative hypothesis</strong></td>
<td>Specifies whether <span class="math inline">\(p\)</span> differs from <span class="math inline">\(p_0\)</span> (two‑sided) or is greater/less than <span class="math inline">\(p_0\)</span> (one‑sided).</td>
</tr>
<tr class="odd">
<td><strong>Z‑statistic</strong></td>
<td><span class="math inline">\(z = (\hat{p}-p_0)/\sqrt{p_0(1-p_0)/n}\)</span>.</td>
</tr>
<tr class="even">
<td><strong>Confidence interval for <span class="math inline">\(p\)</span></strong></td>
<td><span class="math inline">\(\hat{p}\pm z_{\alpha/2}\sqrt{\hat{p}(1-\hat{p})/n}\)</span>.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-1" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-1">Check your understanding</h3>
<ol type="1">
<li>A survey asks whether citizens of a town support building a new park. Out of 400 respondents, 112 say yes. Test at the 0.05 level whether the support rate differs from 25%. Find and interpret a 95% confidence interval.</li>
<li>A biologist believes that 30% of a wildflower species carry a recessive allele. In a sample of 120 plants, 46 carry the allele. Set up and perform a one‑sided test at <span class="math inline">\(\alpha=0.10\)</span> to determine whether the allele frequency is greater than 30%.</li>
<li>Explain why the z‑statistic uses the hypothesized proportion <span class="math inline">\(p_0\)</span> in the denominator when calculating the test statistic, but the confidence interval uses <span class="math inline">\(\hat{p}\)</span>.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>The sample proportion is <span class="math inline">\(\hat{p}=112/400=0.28\)</span>. Test <span class="math inline">\(H_0:p=0.25\)</span> vs.&nbsp;<span class="math inline">\(H_a:p\neq0.25\)</span> at <span class="math inline">\(\alpha=0.05\)</span>. The z‑statistic is <span class="math inline">\((0.28-0.25)/\sqrt{0.25\times0.75/400}\approx1.39\)</span> with two‑sided p‑value 0.164. We fail to reject <span class="math inline">\(H_0\)</span>; the support rate is not significantly different from 25 %. A 95 % confidence interval is <span class="math inline">\(0.28\pm1.96\sqrt{0.28\times0.72/400}= (0.23,0.33)\)</span>, which includes 0.25.</p></li>
<li><p>Here <span class="math inline">\(\hat{p}=46/120=0.383\)</span>. We test <span class="math inline">\(H_0:p=0.30\)</span> vs.&nbsp;<span class="math inline">\(H_a:p&gt;0.30\)</span> at <span class="math inline">\(\alpha=0.10\)</span>. The z‑statistic is <span class="math inline">\((0.383-0.30)/\sqrt{0.30\times0.70/120}\approx2.07\)</span> with one‑sided p‑value 0.019. Since 0.019 &lt; 0.10, we reject <span class="math inline">\(H_0\)</span> and conclude the allele frequency exceeds 30 %. A 90 % one‑sided confidence bound would start at <span class="math inline">\(\hat{p}-1.28\sqrt{\hat{p}(1-\hat{p})/n}=0.383-1.28\times0.042=0.33\)</span>; we are 90 % confident that the allele frequency is at least 33 %.</p></li>
<li><p>Under the null hypothesis the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is centered at <span class="math inline">\(p_0\)</span> with variance <span class="math inline">\(p_0(1-p_0)/n\)</span>, so the z‑statistic uses <span class="math inline">\(p_0\)</span> to measure how far the sample proportion deviates from what we expect when <span class="math inline">\(H_0\)</span> is true. For a confidence interval we treat <span class="math inline">\(\hat{p}\)</span> as our best estimate of <span class="math inline">\(p\)</span> and use its estimated standard error <span class="math inline">\(\sqrt{\hat{p}(1-\hat{p})/n}\)</span> to account for sampling variability.</p></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-11_02" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="sec-11_02"><span class="header-section-number">11.3</span> Test for Difference in Proportions</h2>
<blockquote class="blockquote">
<p>“The essence of mathematics is not to make simple things complicated, but to make complicated things simple.” - S. Gudder</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>When comparing two independent groups with a binary outcome, how can we test whether their proportions differ?</em></p>
</blockquote>
<p>In clinical trials, marketing experiments and ecological studies we often compare two treatments or populations. Each unit yields a binary response (success/failure), and the explanatory variable indicates group membership. To decide whether a difference observed in the sample reflects a true difference in the populations we use a two‑sample proportion test.</p>
<p><img src="images/05.png" class="img-fluid"></p>
<section id="hypotheses-and-assumptions-1" class="level3">
<h3 class="anchored" data-anchor-id="hypotheses-and-assumptions-1">Hypotheses and assumptions</h3>
<p>Let <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> denote the proportions in groups 1 and 2, and let <span class="math inline">\(\hat{p}_1\)</span> and <span class="math inline">\(\hat{p}_2\)</span> be the sample proportions from independent random samples of sizes <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>. The null hypothesis is <span class="math inline">\(H_0: p_1 = p_2\)</span>, implying no group effect. The alternative can be two‑sided (<span class="math inline">\(H_a: p_1 \neq p_2\)</span>) or one‑sided (e.g., <span class="math inline">\(H_a: p_1 &gt; p_2\)</span>).</p>
<p>The success–failure conditions must hold for each group separately: <span class="math inline">\(n_1\hat{p}_1\geq 15\)</span>, <span class="math inline">\(n_1(1-\hat{p}_1)\geq 15\)</span>, <span class="math inline">\(n_2\hat{p}_2\geq 15\)</span> and <span class="math inline">\(n_2(1-\hat{p}_2)\geq 15\)</span>. We also require that the samples are independent of each other and that observations within each sample are independent. Meeting these conditions allows us to approximate the sampling distribution of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> by a normal distribution.</p>
</section>
<section id="test-statistic" class="level3">
<h3 class="anchored" data-anchor-id="test-statistic">Test statistic</h3>
<p>Under <span class="math inline">\(H_0\)</span> we assume the common population proportion is <span class="math inline">\(p\)</span> and estimate it by the <em>pooled proportion</em></p>
<p><span class="math display">\[
p = \frac{x_1 + x_2}{n_1 + n_2},
\]</span></p>
<p>where <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are the numbers of successes in groups 1 and 2. The test statistic is</p>
<p><span class="math display">\[
z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{p(1-p)\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}},
\]</span></p>
<p>For a two‑sided alternative the p‑value is <span class="math inline">\(2P(Z &gt; |z|)\)</span>; for one‑sided tests we compute <span class="math inline">\(P(Z &gt; z)\)</span> or <span class="math inline">\(P(Z &lt; z)\)</span> depending on the direction. A small p‑value indicates evidence against <span class="math inline">\(H_0\)</span>.</p>
</section>
<section id="posthoc-confidence-interval-and-multiple-comparisons" class="level3">
<h3 class="anchored" data-anchor-id="posthoc-confidence-interval-and-multiple-comparisons">Post‑hoc confidence interval and multiple comparisons</h3>
<p>When we reject <span class="math inline">\(H_0\)</span> (or even if we do not), it is informative to estimate the difference in proportions with a <em>confidence interval</em>. Using the sample proportions (not pooled), the standard error is</p>
<p><span class="math display">\[
SE = \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}},
\]</span></p>
<p>and a <span class="math inline">\((1-\alpha)\times100\%\)</span> confidence interval for <span class="math inline">\(p_1 - p_2\)</span> is</p>
<p><span class="math display">\[
(\hat{p}_1 - \hat{p}_2) \pm z_{\alpha/2} SE.
\]</span></p>
<p>Unlike the test statistic, the confidence interval does not use the pooled proportion because it aims to estimate the true difference rather than test a null hypothesis.</p>
</section>
<section id="example-treatment-success-rates" class="level3">
<h3 class="anchored" data-anchor-id="example-treatment-success-rates">Example– Treatment success rates</h3>
<p>A clinical study compares recovery rates between two therapies for treating a viral infection. Therapy A is given to 150 patients, 105 of whom recover within a week; therapy B is given to 130 patients, with 72 recoveries. We test</p>
<p><span class="math display">\[
H_0: p_A = p_B \quad\text{vs.}\quad H_a: p_A &gt; p_B
\]</span></p>
<p>at <span class="math inline">\(\alpha=0.05\)</span>. The sample proportions are <span class="math inline">\(\hat{p}_A = 105/150 = 0.70\)</span> and <span class="math inline">\(\hat{p}_B = 72/130 \approx 0.554\)</span>. The pooled proportion is</p>
<p><span class="math display">\[
p = \frac{105 + 72}{150 + 130} = \frac{177}{280} = 0.632.
\]</span></p>
<p>The test statistic is</p>
<p><span class="math display">\[
z = \frac{0.70 - 0.554}{\sqrt{0.632\times(1-0.632)\left(\frac{1}{150} + \frac{1}{130}\right)}} \approx 2.68.
\]</span></p>
<p>The one‑sided p‑value is <span class="math inline">\(P(Z &gt; 2.68) \approx 0.0037\)</span>. Since 0.0037 &lt; 0.05, we reject <span class="math inline">\(H_0\)</span> and conclude therapy A has a higher recovery rate. A 95% confidence interval for <span class="math inline">\(p_A - p_B\)</span> uses the standard error with unpooled proportions:</p>
<p><span class="math display">\[
SE = \sqrt{\frac{0.70\times0.30}{150} + \frac{0.554\times0.446}{130}} \approx 0.062,
\]</span></p>
<p>so the interval is <span class="math inline">\((0.70-0.554) \pm 1.96 \times 0.062 = (0.031, 0.238)\)</span>. We are 95% confident that therapy A’s recovery rate exceeds therapy B’s by between 3.1% and 23.8%.</p>
</section>
<section id="example-genotype-frequencies" class="level3">
<h3 class="anchored" data-anchor-id="example-genotype-frequencies">Example – Genotype frequencies</h3>
<p>Researchers investigate whether the frequency of a deleterious allele differs between male and female mice. Among 80 males, 24 carry the allele; among 90 females, 12 do. Testing <span class="math inline">\(H_0:p_M = p_F\)</span> vs.&nbsp;<span class="math inline">\(H_a:p_M \neq p_F\)</span>, we have <span class="math inline">\(\hat{p}_M=0.30\)</span> and <span class="math inline">\(\hat{p}_F=0.133\)</span>. The pooled proportion is <span class="math inline">\((24+12)/(80+90)=36/170=0.212\)</span>. The z‑statistic is</p>
<p><span class="math display">\[
z=\frac{0.30 - 0.133}{\sqrt{0.212\times0.788\left(\frac{1}{80}+\frac{1}{90}\right)}} \approx 3.24,
\]</span></p>
<p>yielding a two‑sided p‑value of about 0.0012. We reject <span class="math inline">\(H_0\)</span>. At a 5% significance level, there is enough evidence to conclude the frequency of a deleterious allele differs between male and female mice. A 95% confidence interval is <span class="math inline">\((0.30-0.133) \pm 1.96\sqrt{0.30\times0.70/80 + 0.133\times0.867/90} = (0.064, 0.262)\)</span>.</p>
</section>
<section id="example-ab-testing" class="level3">
<h3 class="anchored" data-anchor-id="example-ab-testing">Example – A/B testing</h3>
<p>An online retailer runs an A/B experiment to compare two website layouts. Group A (old layout) has 1,800 visitors with 144 purchases; Group B (new layout) has 1,900 visitors with 190 purchases. We test</p>
<p><span class="math display">\[H_0:p_A = p_B \quad\text{vs.}\quad H_a:p_A \neq p_B.\]</span></p>
<p>Let’s do the test with JMP 18 Student Edition.</p>
<p><img src="images/zp2test1.png" class="img-fluid"></p>
<p>The two‑sided p‑value is about 0.0339, indicating a significant difference. At the 5% significance level, there is enough evidence to conclude the the proportion of visitors to the old layout who made a purchase differs from the proportion who made a purchase to the new layout.</p>
<p><img src="images/zp2test2.png" class="img-fluid"></p>
<p>A 95% confidence interval for <span class="math inline">\(p_A - p_B\)</span> is <span class="math inline">\((-0.0384, -0.00016)\)</span>, so the new layout increases purchase rates by roughly 0.02% to 3.8%.</p>
<section id="performing-the-twosample-proportion-test-in-jmp-pro-18" class="level4">
<h4 class="anchored" data-anchor-id="performing-the-twosample-proportion-test-in-jmp-pro-18">Performing the two‑sample proportion test in JMP Pro 18</h4>
<ol type="1">
<li><strong>Prepare your data.</strong> Each row should correspond to an individual with a column for the binary response (e.g., “Purchased”) and a column for group membership (“Layout”). If you have aggregated counts, include a Freq column with the counts.</li>
<li><strong>Use the Contingency platform.</strong> Choose <code>Analyze → Fit Y by X</code>, assign the response variable to <strong>Y</strong>, the group to <strong>X</strong>, and (if present) the counts column to <strong>Freq</strong>. Click OK to produce a contingency table.</li>
<li><strong>Run the two‑sample test.</strong> Click the red triangle next to “Contingency Analysis” and choose <strong>Two Sample Test for Proportions</strong>. JMP reports the difference in sample proportions, the test statistic and p‑value, and a confidence interval for the difference. Use the “Cell Chi Square” option to view contributions to the chi‑square statistic.</li>
<li><strong>Multiple comparisons.</strong> For pairwise comparisons, rerun the two‑sample test on each pair and adjust <span class="math inline">\(\alpha\)</span> using the Bonferroni correction to maintain the overall error rate.</li>
</ol>
</section>
<section id="recap-2" class="level4">
<h4 class="anchored" data-anchor-id="recap-2">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition/Formula</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Two‑sample test for proportions</strong></td>
<td>Tests <span class="math inline">\(H_0: p_1 = p_2\)</span> using a pooled estimate of the common proportion and a z‑statistic.</td>
</tr>
<tr class="even">
<td><strong>Pooled proportion</strong> <span class="math inline">\(p\)</span></td>
<td><span class="math inline">\((x_1+x_2)/(n_1+n_2)\)</span>, used in the denominator of the test statistic under <span class="math inline">\(H_0\)</span>.</td>
</tr>
<tr class="odd">
<td><strong>Standard error for CI</strong></td>
<td><span class="math inline">\(\sqrt{\hat{p}_1(1-\hat{p}_1)/n_1 + \hat{p}_2(1-\hat{p}_2)/n_2}\)</span>.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-2" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-2">Check your understanding</h3>
<ol type="1">
<li>A vaccine trial compares adverse event rates between men and women. Out of 250 men, 38 report an adverse event; out of 300 women, 22 do. At <span class="math inline">\(\alpha=0.05\)</span>, test whether the rates differ and construct a 95% confidence interval for the difference.</li>
<li>Why is the pooled proportion used in the test statistic but not in the confidence interval for <span class="math inline">\(p_1 - p_2\)</span>?</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><span class="math inline">\(\hat{p}_{\text{men}}=38/250=0.152\)</span> and <span class="math inline">\(\hat{p}_{\text{women}}=22/300=0.073\)</span>. The pooled proportion is <span class="math inline">\((38+22)/(250+300)=0.1067\)</span>. The z‑statistic is <span class="math inline">\((0.152-0.073)/\sqrt{0.1067\times0.8933\,(1/250+1/300)}\approx2.98\)</span> with two‑sided p‑value 0.003. We reject <span class="math inline">\(H_0\)</span>; men experience adverse events more often. A 95 % CI uses the unpooled SE <span class="math inline">\(\sqrt{0.152\times0.848/250+0.073\times0.927/300}\approx0.025\)</span>; the interval is <span class="math inline">\((0.079\pm1.96\times0.025)=(0.029,0.129)\)</span>, so the difference ranges from 2.9 % to 12.9 %.</p></li>
<li><p>Under the null hypothesis <span class="math inline">\(p_1 = p_2\)</span>, the sampling distribution of <span class="math inline">\(\hat{p}_1-\hat{p}_2\)</span> is centered at zero with variance <span class="math inline">\(p(1-p)(1/n_1+1/n_2)\)</span>, where <span class="math inline">\(p\)</span> is the common value. The pooled proportion estimates this common value. For confidence intervals we no longer assume <span class="math inline">\(p_1=p_2\)</span>; instead we estimate each population proportion separately to capture the true difference.</p></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-11_03" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="sec-11_03"><span class="header-section-number">11.4</span> Chi‑Square Goodness of Fit</h2>
<blockquote class="blockquote">
<p>“As far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.” - Albert Einstein</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>How can we test whether observed category frequencies match a theoretical distribution?</em></p>
</blockquote>
<p>The chi‑square goodness‑of‑fit test assesses whether a single categorical variable follows a specified distribution. Examples include testing whether the distribution of blood types in a sample matches known population proportions, whether Mendelian inheritance ratios (9 : 3 : 3 : 1) hold in a genetics experiment, or whether market shares of product categories agree with company projections.</p>
<p><img src="images/06.png" class="img-fluid"></p>
<section id="hypotheses-and-assumptions-2" class="level3">
<h3 class="anchored" data-anchor-id="hypotheses-and-assumptions-2">Hypotheses and assumptions</h3>
<p>Suppose there are <span class="math inline">\(k\)</span> categories with expected proportions <span class="math inline">\(p_{1,0},\dots,p_{k,0}\)</span> under the null hypothesis. We observe counts <span class="math inline">\(O_i\)</span> for category <span class="math inline">\(i\)</span> in a random sample of size <span class="math inline">\(n\)</span>. The null hypothesis asserts that the population follows the specified distribution: <span class="math inline">\(H_0: p_i = p_{i,0}\)</span> for all <span class="math inline">\(i\)</span>. The alternative hypothesis is that at least one category proportion differs.</p>
<p>For the chi‑square goodness‑of‑fit test to be valid the data must be counts of a categorical variable, collected from a simple random sample, and that expected counts <span class="math inline">\(E_i = n\,p_{i,0}\)</span> should be at least 5 in each category. These conditions ensure the chi‑square approximation is accurate.</p>
</section>
<section id="test-statistic-1" class="level3">
<h3 class="anchored" data-anchor-id="test-statistic-1">Test statistic</h3>
<p>For each category compute the <strong>expected count</strong> <span class="math inline">\(E_i = n p_{i,0}\)</span>. The chi‑square statistic</p>
<p><span class="math display">\[
\chi^2 = \sum_{i=1}^k \frac{(O_i - E_i)^2}{E_i}
\]</span></p>
<p>measures the discrepancy between the observed and expected frequencies. Under <span class="math inline">\(H_0\)</span> the statistic has a chi‑square distribution with <span class="math inline">\(k-1\)</span> degrees of freedom. Because large deviations in either direction contribute to the sum of squared standardized differences, the test is always one‑sided: large <span class="math inline">\(\chi^2\)</span> values yield small p‑values. If the p‑value is less than <span class="math inline">\(\alpha\)</span>, we reject <span class="math inline">\(H_0\)</span> and conclude the observed distribution does not fit the specified proportions.</p>
</section>
<section id="posthoc-analysisbonferroni-confidence-intervals" class="level3">
<h3 class="anchored" data-anchor-id="posthoc-analysisbonferroni-confidence-intervals">Post‑hoc analysis:Bonferroni confidence intervals</h3>
<p>A significant chi‑square statistic tells us that the observed distribution differs from the expected one, but it does not identify which categories contribute most. To diagnose the differences, construct separate confidence intervals for each category proportion: <span class="math display">\[
\hat{p}_i \pm z_{\alpha^*/2}\sqrt{\hat{p}_i(1-\hat{p}_i)/n}
\]</span></p>
<p>Comparing these intervals to the hypothesized proportions reveals which categories differ from expectation.</p>
<section id="the-bonferroni-confidence-intervals" class="level4">
<h4 class="anchored" data-anchor-id="the-bonferroni-confidence-intervals">The Bonferroni Confidence Intervals</h4>
<p>When we construct confidence intervals for <em>multiple categories</em> at once, each interval has its own chance of error. If we build <span class="math inline">\(k\)</span> intervals each at the same confidence level (<span class="math inline">\(1-\alpha\)</span>), the probability that <em>at least one</em> of them fails to capture the true parameter can exceed <span class="math inline">\(\alpha\)</span>. This inflation of the overall (family-wise) error rate is known as the <em>multiple comparisons problem.</em></p>
<p>The <blank>Bonferroni</blank> correction provides a simple and conservative way to control this overall error rate. Instead of using the full significance level <span class="math inline">\(\alpha\)</span> for each interval, we divide it equally among the <span class="math inline">\(k\)</span> intervals. That is, we use a per-comparison error rate of</p>
<p><span class="math display">\[
\alpha^* = \frac{\alpha}{k}
\]</span></p>
<p>and construct each interval with confidence level</p>
<p><span class="math display">\[
1 - \alpha^* = 1 - \frac{\alpha}{k}.
\]</span></p>
<p>For example, if we want an overall 95% family confidence level across five categories (<span class="math inline">\(k=5\)</span>), we set <span class="math inline">\(\alpha^* = 0.05/5 = 0.01\)</span>. Each individual interval then has confidence level <span class="math inline">\(1 - 0.01 = 0.99\)</span>. The resulting family of intervals jointly maintains an overall confidence of about 95%.</p>
</section>
<section id="why-it-works" class="level4">
<h4 class="anchored" data-anchor-id="why-it-works">Why It Works</h4>
<p>The justification comes from a basic probability inequality known as <em>Bonferroni’s inequality</em>, which states that for any collection of events <span class="math inline">\(A_1, A_2, \ldots, A_k\)</span>,</p>
<p><span class="math display">\[
P(A_1 \cup A_2 \cup \ldots \cup A_k) \leq P(A_1) + P(A_2) + \ldots + P(A_k).
\]</span></p>
<p>If we interpret each <span class="math inline">\(A_i\)</span> as the event that the <span class="math inline">\(i\)</span>th confidence interval fails to contain its true proportion, then</p>
<p><span class="math display">\[
P(\text{at least one interval fails}) \leq k \times \alpha^* = \alpha.
\]</span></p>
<p>Thus, the probability that <em>all</em> intervals simultaneously contain their true values is at least <span class="math inline">\(1 - \alpha\)</span>. In other words, the Bonferroni method guarantees that the <em>family-wise confidence level</em> is no smaller than the desired value.</p>
<p>Bonferroni intervals are <em>conservative</em>—they make it slightly harder to declare significance—but they ensure that the overall Type I error rate does not exceed the nominal level. This conservatism is often desirable in confirmatory analyses, such as identifying which categories deviate from a hypothesized distribution after a significant chi-square test.</p>
</section>
</section>
<section id="example-mendelian-inheritance" class="level3">
<h3 class="anchored" data-anchor-id="example-mendelian-inheritance">Example – Mendelian inheritance</h3>
<p>In a classic genetics experiment, pea plants are self‑fertilized to examine the distribution of phenotypes produced by a dihybrid cross. Mendel’s theory predicts a 9 : 3 : 3 : 1 ratio of phenotypes. Suppose a biologist observes the following counts in 1,600 offspring: 900 have phenotype A, 320 have phenotype B, 300 have phenotype C and 80 have phenotype D. We test</p>
<p><span class="math display">\[
\begin{align*}
&amp;H_0:p_1 = 0.5625, p_2=0.1875, p_3 = 0.1875, p_4 = 0.0625\\
&amp;H_a:\text{at least one differs}
\end{align*}
\]</span></p>
<p>The expected counts based on the 9 : 3 : 3 : 1 proportions are <span class="math display">\[
(0.5625, 0.1875, 0.1875, 0.0625)\times1600 = (900, 300, 300, 100)
\]</span></p>
<p>The chi‑square statistic is</p>
<p><span class="math display">\[
\begin{align*}
\chi^2 &amp;= \frac{(900-900)^2}{900} + \frac{(320-300)^2}{300} + \frac{(300-300)^2}{300} + \frac{(80-100)^2}{100}\\
&amp;\approx 5.33
\end{align*}
\]</span></p>
<p>With 3 degrees of freedom the p‑value is about 0.1490, above 0.05. We fail to reject <span class="math inline">\(H_0\)</span> and cannot conclude the observed distribution differs from the predicted Mendelian ratio.</p>
<p>We can perform the analysis in JMP to get the</p>
<p><img src="images/chisq1.png" class="img-fluid"></p>
<p>We can find the Bonferroni confidence intervals by first calculating <span class="math display">\[
\begin{align*}
1 - \alpha^* &amp;= 1 - \frac{\alpha}{k}\\
&amp; = 1-\frac{0.05}{4}\\
&amp; = 1-0.0125\\
&amp; = 0.9875
\end{align*}
\]</span> Thus, we are finding 98.75% confidence intervals:</p>
<p><img src="images/chisq2.png" class="img-fluid"></p>
<section id="performing-the-goodnessoffit-test-in-jmp-pro-18" class="level4">
<h4 class="anchored" data-anchor-id="performing-the-goodnessoffit-test-in-jmp-pro-18">Performing the goodness‑of‑fit test in JMP Pro 18</h4>
<ol type="1">
<li><strong>Enter the counts.</strong> Create a column for the categorical variable and another for the observed counts (if the data are aggregated). Alternatively, enter one row per observation.</li>
<li><strong>Analyze the distribution.</strong> Choose <code>Analyze → Distribution</code>, assign the categorical variable to Y and, if using aggregated counts, the counts column to <strong>Freq</strong>. Click OK to see the observed counts and bar chart.</li>
<li><strong>Specify expected proportions.</strong> Click the red triangle next to the variable name and choose <strong>Test Probabilities</strong>. In the dialog, set the expected probabilities (e.g., 0.45, 0.40, 0.11, 0.04) or equal proportions. JMP displays the Pearson chi‑square statistic, degrees of freedom and p‑value.</li>
</ol>
</section>
<section id="recap-3" class="level4">
<h4 class="anchored" data-anchor-id="recap-3">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition/Formula</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Goodness‑of‑fit test</strong></td>
<td>Evaluates whether observed categorical data follow a specified distribution.</td>
</tr>
<tr class="even">
<td><strong>Expected count</strong></td>
<td><span class="math inline">\(E_i = n p_{i,0}\)</span>; should be at least 5 in each category.</td>
</tr>
<tr class="odd">
<td><strong>Chi‑square statistic</strong></td>
<td><span class="math inline">\(\sum (O_i-E_i)^2/E_i\)</span>; follows a chi‑square distribution with <span class="math inline">\(k-1\)</span> degrees of freedom.</td>
</tr>
<tr class="even">
<td><strong>Bonferroni adjustment</strong></td>
<td>Divide <span class="math inline">\(\alpha\)</span> by the number of categories when examining individual residuals to control the family‑wise error rate.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-3" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-3">Check your understanding</h3>
<ol type="1">
<li>A genetics lab predicts a 3 : 1 ratio of dominant to recessive phenotypes in a monohybrid cross. In a sample of 500 offspring there are 375 dominant and 125 recessive. Perform a goodness‑of‑fit test at <span class="math inline">\(\alpha=0.05\)</span> and interpret the standardized residuals.</li>
<li>A restaurant anticipates that dinner orders will be evenly split among four meal types (fish, chicken, beef, vegetarian). One night the observed counts are (80, 60, 100, 60) out of 300 orders. Test whether the distribution differs from expectation and identify which meals are unusually popular or unpopular. Use a Bonferroni correction.</li>
<li>Why is the chi‑square goodness‑of‑fit test always one‑sided? How does this affect the calculation of the p‑value?</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Expected counts under a 3 : 1 ratio are <span class="math inline">\((375,125)\)</span>. The chi‑square statistic is <span class="math inline">\((375-375)^2/375+(125-125)^2/125=0\)</span> with p‑value 1. We fail to reject <span class="math inline">\(H_0\)</span>; the observed distribution perfectly matches the prediction.</p></li>
<li><p>Expected counts are (75, 75, 75, 75). The chi‑square statistic is <span class="math inline">\(((80-75)^2+(60-75)^2+(100-75)^2+(60-75)^2)/75 = 20\)</span>. With 3 degrees of freedom the p‑value is about 0.00016, so the distribution differs significantly. Standardized residuals are <span class="math inline">\((0.58,-1.73,2.89,-1.73)\)</span>. With Bonferroni adjustment (<span class="math inline">\(\alpha/4=0.0125\)</span>) the critical value is <span class="math inline">\(\approx 2.49\)</span>; only the beef category residual of 2.89 exceeds this threshold. Beef orders are significantly more frequent than expected.</p></li>
<li><p>The chi‑square statistic sums squared standardized deviations, so any deviation from expected counts (whether above or below) increases the statistic. Thus a large chi‑square statistic indicates lack of fit regardless of the direction of deviations. The p‑value is the upper‑tail probability <span class="math inline">\(P(\chi^2_{k-1} \geq \chi^2)\)</span>; there is no “lower tail” of interest because small values indicate good fit, not evidence against the null.</p></li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-11_04" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="sec-11_04"><span class="header-section-number">11.5</span> Chi‑Square Test for Association</h2>
<blockquote class="blockquote">
<p>“Although we often hear that data speak for themselves, their voices can be soft and sly.” - Frederick Mosteller</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>Are two categorical variables associated? If so, how can we identify the pattern of association?</em></p>
</blockquote>
<p>The chi‑square test for <blank>association</blank> (also called the chi‑square test of independence) examines whether two categorical variables are related. It generalizes the two‑sample proportion test when the explanatory variable has more than two categories or when the response variable has more than two categories. Examples include assessing the association between smoking status and lung disease, genotype and phenotype, or customer gender and product preference.</p>
<p><img src="images/07.png" class="img-fluid"></p>
<section id="hypotheses-and-assumptions-3" class="level3">
<h3 class="anchored" data-anchor-id="hypotheses-and-assumptions-3">Hypotheses and assumptions</h3>
<p>Suppose a contingency table has <span class="math inline">\(r\)</span> rows (categories of the response variable) and <span class="math inline">\(c\)</span> columns (categories of the explanatory variable). Let <span class="math inline">\(O_{ij}\)</span> be the observed count in cell <span class="math inline">\((i,j)\)</span> with row total <span class="math inline">\(R_i\)</span>, column total <span class="math inline">\(C_j\)</span> and grand total <span class="math inline">\(N\)</span>. The null hypothesis posits that the two variables are independent; equivalently, <span class="math display">\[
P(\text{row }i \text{ and column }j) = P(\text{row }i)×P(\text{column }j)
\]</span></p>
<p>The <em>alternative</em> states that at least one cell’s probability differs from the product of its marginal probabilities. Independence implies no association; rejecting it suggests an association exists.</p>
<p>The data must be counts from a simple random sample, both variables must be categorical, and all expected counts should be at least 5. These conditions parallel those of the goodness‑of‑fit test and ensure the chi‑square approximation is valid.</p>
</section>
<section id="test-statistic-2" class="level3">
<h3 class="anchored" data-anchor-id="test-statistic-2">Test statistic</h3>
<p>For each cell compute the expected count under independence:</p>
<p><span class="math display">\[
E_{ij} = \frac{R_i C_j}{N}.
\]</span></p>
<p>The chi‑square statistic is</p>
<p><span class="math display">\[
\chi^2 = \sum_{i=1}^r \sum_{j=1}^c \frac{(O_{ij}-E_{ij})^2}{E_{ij}},
\]</span></p>
<p>which follows a chi‑square distribution with <span class="math inline">\((r-1)(c-1)\)</span> degrees of freedom under <span class="math inline">\(H_0\)</span>. As with the goodness‑of‑fit test, the p‑value is the upper‑tail probability: large values indicate evidence of association.</p>
</section>
<section id="posthoc-analysis" class="level3">
<h3 class="anchored" data-anchor-id="posthoc-analysis">Post‑hoc analysis</h3>
<p>A significant result signals that the variables are associated but does not reveal the nature of the association. Two common post‑hoc approaches are:</p>
<ol type="1">
<li><p><strong>Standardized and adjusted residuals.</strong> Compute cell residuals <span class="math inline">\(r_{ij} = (O_{ij}-E_{ij})/\sqrt{E_{ij}}\)</span>. Residuals with absolute value greater than about 2 highlight cells contributing to the chi‑square statistic. Adjusted Pearson residuals account for the degrees of freedom and have approximately a standard normal distribution. Apply a Bonferroni correction by dividing <span class="math inline">\(\alpha\)</span> by the number of cells examined when identifying significant residuals.</p></li>
<li><p><strong>Pairwise proportion tests.</strong> For a table with more than two columns, perform two‑sample proportion tests on pairs of columns. For example, if you have 3 columns there are 3 pairwise comparisons; use <span class="math inline">\(\alpha^*=\alpha/3\)</span> when computing p‑values or confidence intervals.</p></li>
</ol>
<p>You can also compute measures of association such as <strong>Cramér’s V</strong>, which rescales the chi‑square statistic to lie between 0 (no association) and 1 (perfect association).</p>
</section>
<section id="example-11.10-smoking-status-and-lung-disease-medicine" class="level3">
<h3 class="anchored" data-anchor-id="example-11.10-smoking-status-and-lung-disease-medicine">Example 11.10 – Smoking status and lung disease (medicine)</h3>
<p>A health researcher investigates the relationship between smoking status (non‑smoker, past smoker, current smoker) and diagnosis of a chronic lung disease (present or absent). The observed counts for 400 participants are:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Disease present</th>
<th>Disease absent</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Non‑smoker</td>
<td>20</td>
<td>180</td>
<td><strong>200</strong></td>
</tr>
<tr class="even">
<td>Past smoker</td>
<td>25</td>
<td>75</td>
<td><strong>100</strong></td>
</tr>
<tr class="odd">
<td>Current smoker</td>
<td>30</td>
<td>70</td>
<td><strong>100</strong></td>
</tr>
<tr class="even">
<td><strong>Total</strong></td>
<td><strong>75</strong></td>
<td><strong>325</strong></td>
<td><strong>400</strong></td>
</tr>
</tbody>
</table>
<p>Under independence the expected count for the first cell is <span class="math inline">\((200\times75)/400=37.5\)</span>, and similarly for the other cells. The chi‑square statistic is</p>
<p><span class="math display">\[
\chi^2 = \sum_{i,j}\frac{(O_{ij}-E_{ij})^2}{E_{ij}} \approx 20.923,
\]</span></p>
<p>with <span class="math inline">\((3-1)(2-1)=2\)</span> degrees of freedom. The p‑value is &lt;0.0001. We reject the null hypothesis; smoking status and lung disease are associated.</p>
<p>In JMP, the output looks like</p>
<p><img src="images/chisq3.png" class="img-fluid"></p>
<!-- ### Example 11.11 – Genotype and phenotype (biology) -->

<!-- Suppose a geneticist records the genotype (AA, Aa, aa) and phenotype (normal, affected) for 300 animals.  The contingency table is: -->
<!-- |         | Normal | Affected | Total | -->
<!-- |--------|--------|---------|------| -->
<!-- | AA     | 90     | 10      | 100  | -->
<!-- | Aa     | 85     | 15      | 100  | -->
<!-- | aa     | 60     | 40      | 100  | -->
<!-- | **Total** | **235** | **65** | **300** | -->
<!-- The chi‑square statistic is computed from the expected counts $(R_i C_j)/N$; here the value is approximately 23.55 with $(3-1)(2-1)=2$ degrees of freedom.  The p‑value is <0.00001, indicating a strong association.  Standardized residuals show that the aa genotype is overrepresented among affected individuals and underrepresented among normals, while AA individuals are underrepresented among affected animals.  Pairwise tests comparing genotype proportions across phenotype categories confirm that aa animals have a significantly higher disease rate. -->
<!-- ### Example 11.12 – Marketing preference by gender (business) -->
<!-- An advertising firm surveys 600 customers about their preferred product category (electronics, clothing, home goods) and records each customer’s gender (male, female).  The observed counts are: -->
<!-- |             | Electronics | Clothing | Home goods | Total | -->
<!-- |------------|------------|---------|-----------|------| -->
<!-- | Male       | 90         | 110     | 70        | 270  | -->
<!-- | Female     | 80         | 150     | 100       | 330  | -->
<!-- | **Total**  | **170**    | **260** | **170**   | **600** | -->
<!-- The chi‑square statistic with $(2-1)(3-1)=2$ degrees of freedom is about 13.91 with a p‑value of 0.00096, indicating an association between gender and product preference.  Standardized residuals reveal that males purchase home goods less often than expected and females purchase clothing more often.  Pairwise two‑sample tests for each product category, with Bonferroni‑adjusted $\alpha/3=0.0167$, can quantify the magnitude of these differences. -->
<section id="performing-the-chisquare-test-for-association-in-jmp-pro-18" class="level4">
<h4 class="anchored" data-anchor-id="performing-the-chisquare-test-for-association-in-jmp-pro-18">Performing the chi‑square test for association in JMP Pro 18</h4>
<ol type="1">
<li><strong>Organize your data.</strong> Each row should represent an individual with two categorical variables. If you have aggregated counts, include a Freq column.</li>
<li><strong>Use the Contingency platform.</strong> Select <code>Analyze → Fit Y by X</code>. Assign one variable to <strong>Y</strong>, the other to <strong>X</strong>, and the counts to <strong>Freq</strong> if needed. Click OK to obtain the contingency table.</li>
<li><strong>Run the chi‑square test.</strong> JMP displays the chi‑square statistic, degrees of freedom and p‑value. Verify that all expected counts exceed 5.</li>
</ol>
</section>
<section id="recap-4" class="level4">
<h4 class="anchored" data-anchor-id="recap-4">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition/Formula</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Chi‑square test for association</strong></td>
<td>Tests independence between two categorical variables; the statistic sums <span class="math inline">\((O_{ij}-E_{ij})^2/E_{ij}\)</span> over all cells.</td>
</tr>
<tr class="even">
<td><strong>Expected count</strong></td>
<td><span class="math inline">\(E_{ij} = (R_i C_j)/N\)</span>; must be at least 5 in each cell.</td>
</tr>
<tr class="odd">
<td><strong>Degrees of freedom</strong></td>
<td><span class="math inline">\((r-1)(c-1)\)</span> for an <span class="math inline">\(r\times c\)</span> contingency table.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-4" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-4">Check your understanding</h3>
<ol type="1">
<li>A study records the preferred news source (TV, radio, internet, newspaper) and political affiliation (Democrat, Republican, Independent) for 900 voters. Describe how to test for independence between news source and political affiliation. If the overall test is significant, how would you identify which cells contribute most to the association?</li>
<li>The table below shows the relationship between genotype (AA, Aa, aa) and survival (survived, died) in a sample of 450 organisms. Perform a chi‑square test for association and interpret the results. Then compute standardized residuals and determine which genotype categories differ most from expectation.</li>
</ol>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Survived</th>
<th>Died</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AA</td>
<td>130</td>
<td>20</td>
<td>150</td>
</tr>
<tr class="even">
<td>Aa</td>
<td>120</td>
<td>30</td>
<td>150</td>
</tr>
<tr class="odd">
<td>aa</td>
<td>80</td>
<td>70</td>
<td>150</td>
</tr>
<tr class="even">
<td><strong>Total</strong></td>
<td><strong>330</strong></td>
<td><strong>120</strong></td>
<td><strong>450</strong></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Enter counts in a contingency table with rows for political affiliation and columns for news source. Compute expected counts <span class="math inline">\(E_{ij}=R_i C_j/N\)</span> and the chi‑square statistic <span class="math inline">\(\chi^2 = \sum (O_{ij}-E_{ij})^2/E_{ij}\)</span>. With <span class="math inline">\((r-1)(c-1)\)</span> degrees of freedom, find the p‑value and decide whether to reject independence. If significant, calculate standardized residuals for each cell and compare them to a Bonferroni‑adjusted critical value (e.g., <span class="math inline">\(\alpha/(rc)\)</span>). Cells with large positive residuals occur more often than expected; large negative residuals occur less often.</p></li>
<li><p>Expected counts: row totals × column totals divided by 450. For AA survived: <span class="math inline">\((150×330)/450=110\)</span>; for AA died: 40; for Aa survived: 110; Aa died: 40; aa survived: 110; aa died: 40. The chi‑square statistic is <span class="math inline">\(((130-110)^2/110 + (20-40)^2/40 + (120-110)^2/110 + (30-40)^2/40 + (80-110)^2/110 + (70-40)^2/40)=\ldots\)</span> which simplifies to 39.09. With <span class="math inline">\((3-1)(2-1)=2\)</span> degrees of freedom the p‑value is essentially zero, so genotype and survival are associated. Standardized residuals: AA survived <span class="math inline">\((130-110)/\sqrt{110}=1.91\)</span>, AA died <span class="math inline">\((20-40)/\sqrt{40}=-3.16\)</span>, Aa survived <span class="math inline">\((120-110)/\sqrt{110}=0.95\)</span>, Aa died <span class="math inline">\((30-40)/\sqrt{40}=-1.58\)</span>, aa survived <span class="math inline">\((80-110)/\sqrt{110}=-2.86\)</span>, aa died <span class="math inline">\((70-40)/\sqrt{40}=4.74\)</span>. After Bonferroni adjustment (<span class="math inline">\(\alpha/6\)</span>), the critical value is about 2.73. The aa died cell (4.74) and AA died cell (–3.16) show significant deviations: aa individuals die more often than expected while AA individuals die less often.</p></li>
</ol>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>