<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STA 2381 Introductory Statistical Methods - 13&nbsp; Analysis of Variance</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style type="text/css">
.sidebar .chapter-number {
color: #FFB81c;
}
freeblank {
  color: transparent;
  cursor: pointer;
}
freeblank.clicked {
  color: red;
}
blank {
  display: inline-block; 
  position: relative;
  padding: 0 10px;
  color: transparent;
  cursor: pointer;
}
blank::before {
  content: ''; /* Creates a custom underline */
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  height: 1px; /* Thickness of the underline */
  background-color: black; /* Color of the underline */
}
blank.clicked {
  color: red;
}
</style>
<script>
document.addEventListener('click', (event) => {
  if (event.target.tagName === 'BLANK') {
    event.target.classList.add('clicked');
  }
});
document.addEventListener('click', (event) => {
  if (event.target.tagName === 'FREEBLANK') {
    event.target.classList.add('clicked');
  }
});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./13.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Analysis of Variance</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Collecting Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Describing Data with Tables and Graphs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Describing Data with Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability Concepts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Estimation and Confidence Intervals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Hypothesis Testing: The Basics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Hypothesis Testing with Categorical Response</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Methods for Quantitative Response Variables – One and Two Groups</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Analysis of Variance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Correlation and Simple Linear Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-13_01" id="toc-sec-13_01" class="nav-link active" data-scroll-target="#sec-13_01"><span class="header-section-number">13.1</span> Why compare more than two means?</a>
  <ul class="collapse">
  <li><a href="#between-and-withingroup-variation" id="toc-between-and-withingroup-variation" class="nav-link" data-scroll-target="#between-and-withingroup-variation">Between‑ and within‑group variation</a></li>
  <li><a href="#assumptions" id="toc-assumptions" class="nav-link" data-scroll-target="#assumptions">Assumptions</a></li>
  <li><a href="#example-cholesterollowering-treatments" id="toc-example-cholesterollowering-treatments" class="nav-link" data-scroll-target="#example-cholesterollowering-treatments">Example: Cholesterol‑lowering treatments</a></li>
  <li><a href="#check-your-understanding" id="toc-check-your-understanding" class="nav-link" data-scroll-target="#check-your-understanding">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-13_02" id="toc-sec-13_02" class="nav-link" data-scroll-target="#sec-13_02"><span class="header-section-number">13.2</span> Post‑hoc comparisons</a>
  <ul class="collapse">
  <li><a href="#common-posthoc-methods" id="toc-common-posthoc-methods" class="nav-link" data-scroll-target="#common-posthoc-methods">Common post‑hoc methods</a></li>
  <li><a href="#tukeys-honestly-significant-difference-hsd" id="toc-tukeys-honestly-significant-difference-hsd" class="nav-link" data-scroll-target="#tukeys-honestly-significant-difference-hsd">Tukey’s honestly significant difference (HSD)</a></li>
  <li><a href="#example-plant-growth-under-different-fertilizers" id="toc-example-plant-growth-under-different-fertilizers" class="nav-link" data-scroll-target="#example-plant-growth-under-different-fertilizers">Example: Plant growth under different fertilizers</a></li>
  <li><a href="#check-your-understanding-1" id="toc-check-your-understanding-1" class="nav-link" data-scroll-target="#check-your-understanding-1">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-13_03" id="toc-sec-13_03" class="nav-link" data-scroll-target="#sec-13_03"><span class="header-section-number">13.3</span> Two‑way ANOVA and randomized blocks</a>
  <ul class="collapse">
  <li><a href="#model-and-hypotheses" id="toc-model-and-hypotheses" class="nav-link" data-scroll-target="#model-and-hypotheses">Model and hypotheses</a></li>
  <li><a href="#partitioning-variation" id="toc-partitioning-variation" class="nav-link" data-scroll-target="#partitioning-variation">Partitioning variation</a></li>
  <li><a href="#randomized-block-designs" id="toc-randomized-block-designs" class="nav-link" data-scroll-target="#randomized-block-designs">Randomized block designs</a></li>
  <li><a href="#example-antidepressants-and-age" id="toc-example-antidepressants-and-age" class="nav-link" data-scroll-target="#example-antidepressants-and-age">Example: Antidepressants and Age</a></li>
  <li><a href="#performing-twoway-anova-in-jmp-18-student-edition" id="toc-performing-twoway-anova-in-jmp-18-student-edition" class="nav-link" data-scroll-target="#performing-twoway-anova-in-jmp-18-student-edition">Performing two‑way ANOVA in JMP 18 Student Edition</a></li>
  <li><a href="#check-your-understanding-2" id="toc-check-your-understanding-2" class="nav-link" data-scroll-target="#check-your-understanding-2">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-13_04" id="toc-sec-13_04" class="nav-link" data-scroll-target="#sec-13_04"><span class="header-section-number">13.4</span> Repeated measures ANOVA</a>
  <ul class="collapse">
  <li><a href="#model-and-partitioning-variance" id="toc-model-and-partitioning-variance" class="nav-link" data-scroll-target="#model-and-partitioning-variance">Model and partitioning variance</a></li>
  <li><a href="#assumptions-and-sphericity" id="toc-assumptions-and-sphericity" class="nav-link" data-scroll-target="#assumptions-and-sphericity">Assumptions and sphericity</a></li>
  <li><a href="#example-pain-scores-over-time" id="toc-example-pain-scores-over-time" class="nav-link" data-scroll-target="#example-pain-scores-over-time">Example: Pain scores over time</a></li>
  <li><a href="#conducting-repeated-measures-anova-in-jmp-18-student-edition" id="toc-conducting-repeated-measures-anova-in-jmp-18-student-edition" class="nav-link" data-scroll-target="#conducting-repeated-measures-anova-in-jmp-18-student-edition">Conducting repeated measures ANOVA in JMP 18 Student Edition</a></li>
  <li><a href="#check-your-understanding-3" id="toc-check-your-understanding-3" class="nav-link" data-scroll-target="#check-your-understanding-3">Check your understanding</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Analysis of Variance</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="sec-13_01" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="sec-13_01"><span class="header-section-number">13.1</span> Why compare more than two means?</h2>
<blockquote class="blockquote">
<p>“The analysis of variance is the Hubble telescope of the experimenter; it lets you see structures you would miss if you only looked one piece at a time.” – George Box</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>When and why do we use ANOVA instead of doing several two‑sample t‑tests?</em></p>
</blockquote>
<p>Imagine a physician comparing the average reduction in systolic blood pressure from three different antihypertensive medications. We could do a t-test for all possible pairs of the groups. So we would have the following sets of hypotheses: <span class="math display">\[
\begin{align*}
   &amp;{H_0: \mu_1=\mu_2}\qquad\qquad &amp;{H_0: \mu_1=\mu_3}\qquad\qquad &amp;{H_0: \mu_2=\mu_3}\\
   &amp;{H_a: \mu_1\ne \mu_2}\qquad\qquad&amp;{H_a: \mu_1\ne\mu_3}\qquad\qquad&amp;{H_a: \mu_2\ne \mu_3}
\end{align*}
\]</span></p>
<p>In general, for <span class="math inline">\(g\)</span> groups, there would be <span class="math display">\[
\begin{align*}
  { {}_g C_2 = {g \choose 2} = \frac{g!}{2!(g-2)!}}
\end{align*}
\]</span></p>
<p>Suppose you have 5 groups. We would have to do <span class="math display">\[
\begin{align*}
  { {}_5 C_2} &amp;{= {5 \choose 2} = \frac{5!}{2!(5-2)!}}\\\\
   &amp;{=\frac{120}{2(6)}}\\\\
   &amp;{=10}
\end{align*}
\]</span></p>
<p>tests to see if there were any differences between the means of the five groups.</p>
<p>What is the danger in doing this many hypothesis tests?</p>
<p>Recall the <blank>significance level</blank>, <span class="math inline">\(\alpha\)</span>, is chosen by the researcher before doing the test. Usually, <span class="math inline">\(\alpha=0.05\)</span>.</p>
<p>The significance level is also the probability of making a <blank>Type I Error</blank> (Rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is actually true). This would be saying the means are different, when they actually are not different.</p>
<p>The complement of Type I error is failing to reject <span class="math inline">\(H_0\)</span> when it is actually true. This would be saying the means are not different, when they actually are not different.</p>
<p>The probability of concluding the means are not different when they actually are not different is <span class="math display">\[
    \begin{align*}
  { 1-\alpha = 0.95}
\end{align*}
\]</span></p>
<p>If we were to conduct two hypothesis test for comparing the means, then the probability of saying that none of the means are different, when the actually are not will be <span class="math display">\[
        \begin{align*}
  { 0.95\times 0.95=0.9025}
\end{align*}
\]</span> The complement of this would be the probability of making a Type I error in either test: <span class="math display">\[
            \begin{align*}
  { 1-0.9025=0.0975}
\end{align*}
\]</span> So even though the researcher picks <span class="math inline">\(\alpha=0.05\)</span> for each test, the probability of making a Type I error in either of the tests would be 0.0975.</p>
<p>What if we do 10 tests (number of comparisons when there are five groups)? <span class="math display">\[
            \begin{align*}
  { 1-(1-0.05)^{10}=0.4013}
\end{align*}    
\]</span> So the probability of making a Type I error in any of the tests is 0.4013. As the number of comparisons increases, the probability of at least one erroneous conclusion skyrockets. Analysis of variance (<em>ANOVA</em>) was designed to answer a single overarching question—“Are there any differences among the group means?”—while controlling the overall Type I error rate.</p>
<p>A <blank>one‑way ANOVA</blank> compares the means of three or more independent groups. The groups correspond to different levels of a single explanatory factor (for example, different diets, treatments or business strategies).</p>
<p>Under the null hypothesis all group means are equal, while the alternative is that at least one mean differs.</p>
<p><span class="math display">\[
\begin{align*}
&amp;H_0: {\mu_1=\mu_2=\cdots=\mu_m}\\
&amp;H_a: \text{At least one mean differs}
\end{align*}
\]</span></p>
<p>The test statistic is an F ratio—the ratio of variation between groups to variation within groups. If <span class="math inline">\(H_0\)</span> is false, perhaps all the population means differ, but perhaps only one mean differs from the others.</p>
<p>The test analyzes whether the differences observed among the sample means could have reasonably occurred by chance, if the null hypothesis of equal population means was true.</p>
<!-- ![](images/13.png) -->
<section id="between-and-withingroup-variation" class="level3">
<h3 class="anchored" data-anchor-id="between-and-withingroup-variation">Between‑ and within‑group variation</h3>
<p>Consider <span class="math inline">\(m\)</span> groups with <span class="math inline">\(n_i\)</span> observations in group <span class="math inline">\(i\)</span>. Let <span class="math inline">\(\bar{y}_{i\cdot}\)</span> be the sample mean of group <span class="math inline">\(i\)</span> and <span class="math inline">\(\bar{y}_{\cdot\cdot}\)</span> be the grand mean. ANOVA partitions the total sum of squares,</p>
<p><span class="math display">\[
\mathrm{SS}_{\mathrm{Total}} = \sum_{i=1}^m\sum_{j=1}^{n_i} (y_{ij} - \bar{y}_{\cdot\cdot})^2
\]</span></p>
<p>into between‑group variability</p>
<p><span class="math display">\[
\mathrm{SS}_{\mathrm{Between}} = \sum_{i=1}^m n_i\,(\bar{y}_{i\cdot} - \bar{y}_{\cdot\cdot})^2
\]</span></p>
<p>and within‑group (error) variability</p>
<p><span class="math display">\[
\mathrm{SS}_{\mathrm{Error}} = \sum_{i=1}^m\sum_{j=1}^{n_i} (y_{ij} - \bar{y}_{i\cdot})^2
\]</span></p>
<p>The total variability satisfies <span class="math display">\[
\mathrm{SS}_{\mathrm{Total}}=\mathrm{SS}_{\mathrm{Between}}+\mathrm{SS}_{\mathrm{Error}}
\]</span><br>
Dividing each sum of squares by its degrees of freedom gives the mean squares:</p>
<p><span class="math display">\[
\mathrm{MS}_{\mathrm{Between}} = \frac{\mathrm{SS}_{\mathrm{Between}}}{m-1},\quad \mathrm{MS}_{\mathrm{Error}} = \frac{\mathrm{SS}_{\mathrm{Error}}}{N - m}
\]</span></p>
<p>where <span class="math inline">\(N=\sum_{i=1}^m n_i\)</span> is the total sample size. The <em>F statistic</em> is the ratio of these mean squares:</p>
<p><span class="math display">\[
F = \frac{\mathrm{MS}_{\mathrm{Between}}}{\mathrm{MS}_{\mathrm{Error}}}
\]</span><br>
Under <span class="math inline">\(H_0\)</span> the F statistic follows an <span class="math inline">\(F\)</span> distribution with <span class="math inline">\((m-1,\,N-m)\)</span> degrees of freedom. A large F value indicates that the variability between group means is large relative to the random variability within groups, suggesting that at least one mean differs from the others.</p>
<p>The results of an ANOVA F-test are usually presented in a table. The ANOVA table usually takes the form</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 14%">
<col style="width: 10%">
<col style="width: 22%">
<col style="width: 12%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Source</strong></th>
<th><strong>Sum of Squares</strong></th>
<th><strong>df</strong></th>
<th><strong>Mean Square</strong></th>
<th><strong>F</strong></th>
<th><strong>p-value</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Between</strong></td>
<td><span class="math inline">\(\text{SS}_\text{Between}\)</span></td>
<td><span class="math inline">\(m-1\)</span></td>
<td><span class="math inline">\(\text{MS}_\text{Between}\)</span></td>
<td><span class="math inline">\(\frac{\text{MS}_\text{Between}}{\text{MS}_\text{Error}}\)</span></td>
<td><span class="math inline">\(P(F&gt;\frac{\text{MS}_\text{Between}}{\text{MS}_\text{Error}})\)</span></td>
</tr>
<tr class="even">
<td><strong>Error</strong></td>
<td><span class="math inline">\(\text{SS}_\text{Error}\)</span></td>
<td><span class="math inline">\(N-m\)</span></td>
<td><span class="math inline">\(\text{MS}_\text{Error}\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td><span class="math inline">\(\text{SS}_\text{Total}\)</span></td>
<td><span class="math inline">\(N-1\)</span></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="assumptions" class="level3">
<h3 class="anchored" data-anchor-id="assumptions">Assumptions</h3>
<p>ANOVA relies on a few conditions. Each observation should be independent of the others, the response variable should be continuous and approximately normally distributed within each group, and the population variances in all groups should be equal. In practice the F test is fairly robust to mild departures from normality, especially when the sample sizes are similar. If sample variances are markedly different, alternatives such as Welch’s ANOVA may be more appropriate.</p>
</section>
<section id="example-cholesterollowering-treatments" class="level3">
<h3 class="anchored" data-anchor-id="example-cholesterollowering-treatments">Example: Cholesterol‑lowering treatments</h3>
<p>Suppose four cholesterol‑lowering drugs—A, B, C and D—are given to randomly selected patients. After 6 weeks the reduction in LDL cholesterol (mg/dL) is measured. We want to know if the average reduction differs among the four drugs. Rather than perform six t‑tests, we compute the ANOVA F statistic. An F ratio much larger than 1 would suggest that at least one mean reduction differs from the others.</p>
<p>We can visualize the data using boxplots.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="13_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>The boxplot hints at possible differences—drug D seems to reduce cholesterol more than the others. The F test will confirm whether such differences are statistically significant. B</p>
<p>Below is the JMP output of the ANOVA table for this data.</p>
<p><img src="images/anova1.png" class="img-fluid"></p>
<p>Using <span class="math inline">\(\alpha=0.05\)</span>, we reject the null hypothesis. At the 5% significance level, there is enough evidence to conclude that at least one of the drugs differs. We will discuss how to determine which drugs differ with confidence intervals in the next section.</p>
<section id="recap" class="level4">
<h4 class="anchored" data-anchor-id="recap">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>One‑way ANOVA</strong></td>
<td>A procedure for testing whether the means of three or more independent groups are equal.</td>
</tr>
<tr class="even">
<td><strong>Between‑group variability</strong></td>
<td>Variability due to differences among group means.</td>
</tr>
<tr class="odd">
<td><strong>Within‑group (error) variability</strong></td>
<td>Variability of observations around their group means.</td>
</tr>
<tr class="even">
<td><strong>F statistic</strong></td>
<td>The ratio <span class="math inline">\(\mathrm{MS}_{\mathrm{Between}}/\mathrm{MS}_{\mathrm{Error}}\)</span> used to test <span class="math inline">\(H_0\)</span> that all group means are equal.</td>
</tr>
<tr class="odd">
<td><strong>Assumptions</strong></td>
<td>Independence, normality of each group and equality of variances across groups.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding">Check your understanding</h3>
<ol type="1">
<li>Why is it not advisable to use multiple t‑tests to compare the means of four or more groups?</li>
<li>In your own words, explain what it means if the ANOVA F statistic is close to 1.</li>
<li>List the key assumptions of a one‑way ANOVA.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Performing several independent t‑tests inflates the probability of making at least one Type I error (false positive). ANOVA tests all the means simultaneously and controls the overall error rate.</li>
<li>An F ratio near 1 means that the variability between group means is similar to the variability within groups. Under such circumstances the data are consistent with all groups having the same mean, and we would likely fail to reject <span class="math inline">\(H_0\)</span>.</li>
<li>The response variable should be continuous and approximately normally distributed in each group, observations should be independent, and the population variances should be equal.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-13_02" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="sec-13_02"><span class="header-section-number">13.2</span> Post‑hoc comparisons</h2>
<blockquote class="blockquote">
<p>“Statistics is a science in my opinion, and it is no more a branch of mathematics than are physics, chemistry, and economics; for if its methods fail the test of experience–not the test of logic–they will be discarded.” - John Tukey</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>After finding a significant ANOVA result, how do we determine which group means differ?</em></p>
</blockquote>
<p>The global F test in a one‑way ANOVA tells us that not all group means are equal, but it does not identify <em>which</em> pairs of means differ. Performing multiple two‑sample t‑tests on the same data inflates the family‑wise error rate. Post‑hoc procedures are designed to compare all pairs of group means while controlling the overall probability of making any false positives. The basic idea is to construct confidence intervals for each pair of means and adjust the critical values so that the chance of incorrectly claiming a difference remains at or below the chosen <span class="math inline">\(\alpha\)</span> level.</p>
<section id="common-posthoc-methods" class="level3">
<h3 class="anchored" data-anchor-id="common-posthoc-methods">Common post‑hoc methods</h3>
<p>Several procedures exist for comparing means after an ANOVA. Here is a brief overview:</p>
<ul>
<li><strong>Fisher’s least significant difference (LSD)</strong> – performs unadjusted two‑sample t‑tests for each pair of means but only after the omnibus F test is significant. Simple to compute but does not control the family‑wise error rate when there are many comparisons.</li>
<li><strong>Bonferroni</strong> – divides the desired significance level by the number of comparisons (or multiplies p‑values by that number). Valid for unequal sample sizes, but conservative when many comparisons are made.</li>
<li><strong>Scheffé’s method</strong> – constructs simultaneous confidence intervals for <em>all</em> possible contrasts among means. Highly conservative but useful when testing complex hypotheses involving multiple groups.</li>
</ul>
<p>Other specialized procedures include Holm’s sequential Bonferroni and Dunnett’s test (for comparing several treatments against a control), which we will not cover in detail here.</p>
</section>
<section id="tukeys-honestly-significant-difference-hsd" class="level3">
<h3 class="anchored" data-anchor-id="tukeys-honestly-significant-difference-hsd">Tukey’s honestly significant difference (HSD)</h3>
<p>Because it balances power and control of the family‑wise error rate, <blank>tukey’s hsd</blank> is the most widely used post‑hoc procedure in one‑way ANOVA. It relies on the <em>studentized range</em> distribution, which models the range of sample means standardized by the within‑group variability. After computing the ANOVA F test, the critical difference for comparing means of groups <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is</p>
<p><span class="math display">\[
\mathrm{HSD} = \mathrm{q}_{1-\alpha, m, N - m}\,\sqrt{\frac{\mathrm{MS}_{\mathrm{Error}}}{2}\left(\frac{1}{n_i} + \frac{1}{n_j}\right)}
\]</span></p>
<p>where <span class="math inline">\(\mathrm{MS}_{\mathrm{Error}}\)</span> is the within‑group mean square from the ANOVA table and <span class="math inline">\(\mathrm{q}_{1-\alpha, m, N - m}\)</span> is the critical value from the studentized range distribution. For equal group sizes <span class="math inline">\(n_i = n_j = n\)</span>, this simplifies to <span class="math display">\[
\mathrm{HSD} = \mathrm{q}\,\sqrt{\mathrm{MS}_{\mathrm{Error}}/n}
\]</span><br>
A pair of sample means <span class="math inline">\(\bar{y}_{i\cdot}\)</span> and <span class="math inline">\(\bar{y}_{j\cdot}\)</span> is declared significantly different if <span class="math inline">\(|\bar{y}_{i\cdot} - \bar{y}_{j\cdot}| &gt; \mathrm{HSD}\)</span>. Equivalently, the <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval for the difference <span class="math inline">\(\bar{y}_{i\cdot} - \bar{y}_{j\cdot}\)</span> is</p>
<p><span class="math display">\[
\bar{y}_{i\cdot} - \bar{y}_{j\cdot} \pm \mathrm{HSD}
\]</span></p>
<p>Because Tukey’s method is based on the largest range among means, it controls the family‑wise error rate exactly when all group sizes are equal and remains robust for slight imbalances.</p>
<!-- #### Interpreting Tukey’s results -->
<!-- When you apply Tukey’s HSD, the output typically lists the difference between each pair of group means, the standard error, and the lower and upper confidence limits.  If the interval does not include zero, the means differ significantly.  For example, in the plant growth example below, the interval for the difference between **SuperGrow** and **Nitro** might be $(2.1, 7.8)$, indicating that SuperGrow yields at least 2.1 grams more dry weight than Nitro with 95 % confidence. -->
<section id="performing-tukeys-hsd-in-jmp-18-student-edition" class="level4">
<h4 class="anchored" data-anchor-id="performing-tukeys-hsd-in-jmp-18-student-edition">Performing Tukey’s HSD in JMP 18 Student Edition</h4>
<ol type="1">
<li>Use <strong>Analyze &gt; Fit Y by X</strong> to fit the one‑way ANOVA. Assign the continuous response variable to <em>Y</em> and the categorical factor to <em>X</em>.</li>
<li>Click the red triangle next to the Oneway analysis report and choose <em>Means/Anova</em> to display the ANOVA table.</li>
<li>From the red triangle menu in the Oneway window, select <em>Compare Means &gt; All Pairwise, Tukey HSD</em>. A dialog box will prompt you to specify the significance level (default is 0.05); you can adjust this if needed.</li>
<li>JMP adds a table labeled <strong>Tukey HSD</strong> listing each pair of groups, the difference in means, standard error, confidence interval and adjusted p‑value. Pairs with intervals that do not contain zero are flagged as significantly different.</li>
<li>You can visualize the results by selecting <em>Plot</em> in the same menu, which adds confidence interval plots for each pairwise comparison. Always ensure that the global ANOVA F test is significant before interpreting post‑hoc comparisons.</li>
</ol>
</section>
</section>
<section id="example-plant-growth-under-different-fertilizers" class="level3">
<h3 class="anchored" data-anchor-id="example-plant-growth-under-different-fertilizers">Example: Plant growth under different fertilizers</h3>
<p>Suppose an agronomist measures the dry weight (grams) of plants grown under three fertilizers—Nitro, SuperGrow and GreenUp—with twenty plants in each group. Below are boxplots of the data.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="13_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>The one‑way ANOVA yields a significant F statistic, indicating that not all mean weights are equal.</p>
<p><img src="images/anova3.png" class="img-fluid"></p>
<p>At the 5% significance level, there is enough evidence to conclude that at least one of the fertilizers has a mean different than the others.</p>
<p>Below is the JMP output for Tukey’s HSD:</p>
<p><img src="images/anova4.png" class="img-fluid"> For the difference between SuperGrow and GreenUp, we see the confidence interval does not include zero. Thus, there is a significant difference between these two fertilizers. In addition, the interval indicates that SuperGrow is between 3.09 and 11.94 grams more than GreenUp, on average.</p>
<p>Likewise, we see that SuperGrow is between 1.24 and 10.09 grams more thant Nitro, on Average.</p>
<p>For the difference between Nitro and GreenUp, we see the confidence intervals does include zero. Therefore, there is not enough evidence that these two fertilizers are different.</p>
<p>In all three of these results, we are 95% confident that all three of these intervals contain the true differences.</p>
<section id="recap-1" class="level4">
<h4 class="anchored" data-anchor-id="recap-1">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Post‑hoc test </strong></td>
<td>A procedure for comparing pairs of group means after an ANOVA indicates that not all means are equal, while controlling the family‑wise error rate.</td>
</tr>
<tr class="even">
<td><strong>Tukey’s HSD </strong></td>
<td>Uses the studentized range distribution to construct simultaneous confidence intervals for all pairwise differences; exact for equal group sizes and less conservative than Bonferroni.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-1" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-1">Check your understanding</h3>
<ol type="1">
<li>In your own words, describe how Tukey’s HSD controls the family‑wise error rate.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Tukey’s HSD uses the studentized range distribution to adjust the critical value. It accounts for the probability of the <em>largest</em> difference among group means exceeding a threshold, ensuring that the chance of falsely declaring any difference among the means is at most <span class="math inline">\(\alpha\)</span>.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-13_03" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="sec-13_03"><span class="header-section-number">13.3</span> Two‑way ANOVA and randomized blocks</h2>
<blockquote class="blockquote">
<p>“Statistics is the art of stating in precise terms that which one does not know.” - William Kruskal</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>How do we assess the effects of two explanatory variables on a single quantitative response?</em></p>
</blockquote>
<p>When experiments involve two categorical factors—say, <em>treatment</em> and <em>gender</em>, or <em>fertilizer type</em> and <em>irrigation level</em>—we can use a <blank>two‑way ANOVA</blank>. This model allows us to test for <blank>main effects</blank> of each factor and to examine whether the effect of one factor depends on the level of the other (the <blank>interaction</blank>). In certain designs where a second factor is used only to reduce variability and is not of substantive interest, we call it a <blank>randomized block design</blank>.</p>
<section id="model-and-hypotheses" class="level3">
<h3 class="anchored" data-anchor-id="model-and-hypotheses">Model and hypotheses</h3>
<p>Suppose we have two factors, <span class="math inline">\(A\)</span> with <span class="math inline">\(a\)</span> levels and <span class="math inline">\(B\)</span> with <span class="math inline">\(b\)</span> levels. Each treatment combination has <span class="math inline">\(n_{ij}\)</span> observations. Let <span class="math inline">\(\mu_{ij}\)</span> be the mean for combination <span class="math inline">\((i,j)\)</span>. We write the model as</p>
<p><span class="math display">\[y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \varepsilon_{ijk},\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the grand mean, <span class="math inline">\(\alpha_i\)</span> is the effect of level <span class="math inline">\(i\)</span> of factor <span class="math inline">\(A\)</span>, <span class="math inline">\(\beta_j\)</span> is the effect of level <span class="math inline">\(j\)</span> of factor <span class="math inline">\(B\)</span>, <span class="math inline">\((\alpha\beta)_{ij}\)</span> is the interaction effect, and <span class="math inline">\(\varepsilon_{ijk}\)</span> are independent normal errors with common variance. The hypotheses for each effect are:</p>
<ul>
<li><p><strong>Main effect of <span class="math inline">\(A\)</span>:</strong> <span class="math display">\[
H_0: \alpha_1 = \alpha_2 = \cdots = \alpha_a = 0\quad \text{vs.}\quad H_a: \text{At least one } \alpha_i \neq 0
\]</span> This tests whether the mean response differs across levels of factor <span class="math inline">\(A\)</span>. This is equivalent to testing <span class="math display">\[
H_0: \mu_1 = \mu_2 = \cdots = \mu_a\quad \text{vs.}\quad H_a: \text{At least one differs}
\]</span> For all levels of factor <span class="math inline">\(B\)</span>.</p></li>
<li><p><strong>Main effect of <span class="math inline">\(B\)</span>:</strong> <span class="math display">\[
H_0: \beta_1 = \beta_2 = \cdots = \beta_b = 0\quad \text{vs.}\quad H_a: \text{At least one } \beta_j \neq 0
\]</span> This is equivalent to testing <span class="math display">\[
H_0: \mu_1 = \mu_2 = \cdots = \mu_b\quad \text{vs.}\quad H_a: \text{At least one differs}
\]</span> for all levels of factor <span class="math inline">\(A\)</span>.</p></li>
<li><p><strong>Interaction:</strong> <span class="math display">\[
H_0: (\alpha\beta)_{ij} = 0\ \text{for all } i,j\quad \text{vs.}\quad H_a: \text{At least one } (\alpha\beta)_{ij} \neq 0
\]</span> We can write this hypothesis without the math symbols as <span class="math display">\[
\begin{align*}
&amp;H_0: \text{There is no interaction between the two factors}\\
&amp;H_a: \text{There is interaction between the two factors}
\end{align*}
\]</span></p></li>
</ul>
<p>For each hypothesis, an F statistic is computed by dividing the mean square for that factor or interaction by the mean square error. Large F values suggest significant effects.</p>
</section>
<section id="partitioning-variation" class="level3">
<h3 class="anchored" data-anchor-id="partitioning-variation">Partitioning variation</h3>
<p>The two‑way ANOVA partitions the total variability into contributions from factor <span class="math inline">\(A\)</span>, factor <span class="math inline">\(B\)</span>, their interaction, and random error. For balanced designs with equal sample sizes <span class="math inline">\(n\)</span> per combination, the sums of squares are</p>
<p><span class="math display">\[
\mathrm{SS}_A = bn\sum_{i=1}^a(\bar{y}_{i\cdot\cdot} - \bar{y}_{\cdot\cdot\cdot})^2,\quad \mathrm{SS}_B = an\sum_{j=1}^b(\bar{y}_{\cdot j\cdot} - \bar{y}_{\cdot\cdot\cdot})^2
\]</span></p>
<p><span class="math display">\[
\mathrm{SS}_{AB} = n\sum_{i=1}^a\sum_{j=1}^b (\bar{y}_{ij\cdot} - \bar{y}_{i\cdot\cdot} - \bar{y}_{\cdot j\cdot} + \bar{y}_{\cdot\cdot\cdot})^2,
\]</span></p>
<p>and the error sum of squares captures the variability of observations around their cell means. Dividing each sum of squares by its degrees of freedom yields mean squares for computing F statistics.</p>
</section>
<section id="randomized-block-designs" class="level3">
<h3 class="anchored" data-anchor-id="randomized-block-designs">Randomized block designs</h3>
<p>In a randomized block design, one factor is a <blank>blocking factor</blank> used to group similar experimental units and reduce variability. For example, in a drug trial, patients might be blocked by age group; in agricultural experiments, plots might be blocked by soil type. The model is the same as the two‑way ANOVA model, but only the treatment factor is of interest; the block factor is included solely to account for variation among blocks.</p>
<p>We typically test the <blank>treatment effect</blank> and ignore the block effect. When the blocking factor is actually a repeated measurement on the same subject, we instead use a repeated measures ANOVA (see next section).</p>
</section>
<section id="example-antidepressants-and-age" class="level3">
<h3 class="anchored" data-anchor-id="example-antidepressants-and-age">Example: Antidepressants and Age</h3>
<p>A psychiatrist wants to study the effects of three antidepressants on subjects in three different age groups. There were 12 subjects in each age group who were then randomly assigned one of the three antidepressants. Each subject was rated on a scale of 0 to 100, with higher numbers indicating greater relief from depression. The data is presented in the following table (and can be found in the file <code>antidepressantrating.jmp</code>):</p>
<table class="table">
<colgroup>
<col style="width: 13%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;"><strong>18–30</strong></th>
<th style="text-align: left;"><strong>31–50</strong></th>
<th style="text-align: left;"><strong>51–80</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Drug A</strong></td>
<td style="text-align: left;">43, 43, 41, 42</td>
<td style="text-align: left;">53, 51, 53, 52</td>
<td style="text-align: left;">57, 55, 58, 56</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Drug B</strong></td>
<td style="text-align: left;">52, 51, 51, 50</td>
<td style="text-align: left;">62, 61, 60, 61</td>
<td style="text-align: left;">65, 66, 66, 67</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Drug C</strong></td>
<td style="text-align: left;">71, 72, 70, 71</td>
<td style="text-align: left;">81, 83, 82, 82</td>
<td style="text-align: left;">86, 84, 87, 86</td>
</tr>
</tbody>
</table>
<p>In two-way ANOVA, a null hypothesis states that the population means are the same in each category of one factor, at each fixed level of the other factor.</p>
<p>For example, we could test <span class="math display">\[
\begin{align*}
H_0: \text{Mean rating is equal for all three drugs for each age group}
\end{align*}
\]</span> We could also test <span class="math display">\[
\begin{align*}
H_0: \text{Mean rating is equal for all age groups for each drug }
\end{align*}
\]</span></p>
<p>Suppose the population means for each of the cells were displayed in table (a) below. Since the means are the same for all three drugs in each age group, our first null hypothesis above would be true. If the means were as displayed in table (b), then the means would be the same for all three age groups in each drug group. So, our second null hypothesis above would be correct.</p>
<table class="table">
<colgroup>
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 2%">
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>(a)</strong></th>
<th style="text-align: left;"><strong>Drug</strong></th>
<th style="text-align: center;"><strong>18–30</strong></th>
<th style="text-align: center;"><strong>31–50</strong></th>
<th style="text-align: center;"><strong>51–80</strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>(b)</strong></th>
<th style="text-align: left;"><strong>Drug</strong></th>
<th style="text-align: center;"><strong>18–30</strong></th>
<th style="text-align: center;"><strong>31–50</strong></th>
<th style="text-align: center;"><strong>51–80</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Drug A</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: left;">Drug A</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: left;">Drug B</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: left;">Drug B</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">60</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: left;">Drug C</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: left;">Drug C</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">70</td>
</tr>
</tbody>
</table>
<section id="exploring-interaction-between-factors-in-two-way-anova" class="level4">
<h4 class="anchored" data-anchor-id="exploring-interaction-between-factors-in-two-way-anova">Exploring Interaction Between Factors in Two-Way ANOVA</h4>
<p>Investigating whether <blank>interaction</blank> occurs is important whenever we analyze multivariate relationships.</p>
<p>No interaction between two factors means that the effect of either factor on the response variable is the same at each category of the other factor.</p>
<p>The ANOVA tests of main effects assume there is no interaction between the factors. What does this mean in this context?</p>
<p>Let’s plot the means for the three drugs, within each age group.</p>
<p>The figure below shows a plot in which the y-axis gives estimated mean ratings, and points are shown for the nine drug / age group combinations.</p>
<p><img src="images/14_interaction_plot.png" class="img-fluid"></p>
<p>The horizontal axis is not a numerical scale but merely lists the three drugs. The drawn lines connect the means for the three drugs, for a given age group. The absence of interaction is indicated by the (approximate) parallel lines.</p>
<p>The parallel lines occur because the difference in the estimated mean rating between the three drugs is the <blank>same</blank> for each age group.</p>
<p>By contrast, the figure below shows a set of means for which there is interaction. <img src="images/14_interaction_2.png" class="img-fluid"></p>
<p>Here, the difference in means depends on the age group: According to these means, drug A is better for the 51-80 age group, drug B is better for the 31-50 age group, and drug C is better for the 18-30 age group.</p>
<p>The lines in the previous figure are not parallel.</p>
<p><em>It is not meaningful to test the main effects hypotheses when there is interaction</em>.</p>
<p>Below is the JMP output for the two-way ANOVA for this example.</p>
<p><img src="images/14_antidepressant_anova_interaction.png" class="img-fluid"></p>
<p>At the 5% significance level, there is not enough evidence to conclude that there is interaction between Drug and Age Group. Because there is no significant interaction, we can test the main effects.</p>
<p>At the 5% significance level there is enough evidence to conclude that at least one of the drugs differs in mean for each Age Group.</p>
<p>At the 5% significance level there is enough evidence to conclude that at least one of the Age Group differs in mean for each Drug.</p>
<p>We can also do Tukey’s HSD method to determine which of the groups are different for each main effect.</p>
<p><img src="images/anova2waytukey1.png" class="img-fluid"></p>
<p><img src="images/anova2waytukey2.png" class="img-fluid"></p>
<!-- ### Example: Sales training and incentive programs -->
<!-- Imagine a business study examining whether a sales training program (online vs. in‑person) and incentive type (commission vs. salary) affect monthly sales (in $10^3$ dollars).  Each combination is assigned to ten sales representatives, and monthly sales are recorded.  A two‑way ANOVA allows us to test whether the training method has a main effect, whether the incentive type has a main effect, and whether there is an interaction—that is, whether the effectiveness of training depends on the incentive scheme.  The code below simulates such a dataset and fits the model. -->
<!-- ```{r} -->
<!-- set.seed(789) -->
<!-- library(tidyverse) -->
<!-- dat <- expand_grid( -->
<!--   training = c("Online", "In‑person"), -->
<!--   incentive = c("Commission", "Salary"), -->
<!--   rep = 1:10 -->
<!-- ) %>% -->
<!--   mutate( -->
<!--     sales = 50 + (training == "In‑person")*5 + (incentive == "Commission")*8 + -->
<!--       (training == "In‑person" & incentive == "Commission")*3 + -->
<!--       rnorm(n(), 0, 6) -->
<!--   ) -->
<!-- model <- aov(sales ~ training * incentive, data = dat) -->
<!-- summary(model) -->
<!-- ``` -->

<!-- The ANOVA table shows F statistics for the main effects and interaction.  A significant interaction term would suggest that the effect of training depends on the incentive type.  If the interaction is not significant, we interpret the main effects. -->
</section>
</section>
<section id="performing-twoway-anova-in-jmp-18-student-edition" class="level3">
<h3 class="anchored" data-anchor-id="performing-twoway-anova-in-jmp-18-student-edition">Performing two‑way ANOVA in JMP 18 Student Edition</h3>
<p>To carry out a two‑way ANOVA or a randomized block design in JMP, choose <strong>Analyze &gt; Fit Model</strong>. Select your response variable for <em>Y</em> and add both factors to the <em>Construct Model Effects</em> box. If you have a complete factorial design, click <em>Macros &gt; Full Factorial</em> to include the main effects and interaction. Click <em>Run</em> to produce the ANOVA table. JMP will display an <em>Effect Tests</em> table with F statistics for each effect. Use the prediction profiler to visualize interactions, and check residual plots to assess model assumptions.</p>
<section id="recap-2" class="level4">
<h4 class="anchored" data-anchor-id="recap-2">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Two‑way ANOVA</strong></td>
<td>A model with two categorical explanatory variables (factors) that tests for main effects and interactions.</td>
</tr>
<tr class="even">
<td><strong>Main effect</strong></td>
<td>The effect of a factor averaged over the levels of the other factor; tested by comparing <span class="math inline">\(\mathrm{MS}_{\text{factor}}\)</span> to <span class="math inline">\(\mathrm{MS}_{\mathrm{Error}}\)</span>.</td>
</tr>
<tr class="odd">
<td><strong>Interaction</strong></td>
<td>Occurs when the effect of one factor depends on the level of the other; tested via an F ratio using <span class="math inline">\(\mathrm{MS}_{AB}\)</span>.</td>
</tr>
<tr class="even">
<td><strong>Randomized block design</strong></td>
<td>A special two‑way ANOVA where one factor (the block) is used to control variability; only the treatment factor is of interest and the block factor accounts for nuisance variation.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-2" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-2">Check your understanding</h3>
<ol type="1">
<li>Describe the difference between a main effect and an interaction effect in a two‑way ANOVA.</li>
<li>In a randomized block design with five treatments and four blocks, how many degrees of freedom are associated with the treatment, block and error sums of squares?</li>
<li>Why is it important to include the blocking factor in the model when analyzing a randomized block design?</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>A main effect measures the average difference in the response across the levels of a factor, ignoring (averaging over) the other factor. An interaction effect tests whether the effect of one factor varies depending on the level of the other factor; if significant, the factors do not act independently.</li>
<li>The treatment factor has <span class="math inline">\(a-1\)</span> degrees of freedom and the block factor has <span class="math inline">\(b-1\)</span>, where <span class="math inline">\(a\)</span> is the number of treatments and <span class="math inline">\(b\)</span> the number of blocks. The error degrees of freedom are <span class="math inline">\((a-1)(b-1)\)</span> for a balanced design with one observation per cell. In this case, <span class="math inline">\(a=5\)</span> and <span class="math inline">\(b=4\)</span>, so the treatment, block and error degrees of freedom are <span class="math inline">\(4\)</span>, <span class="math inline">\(3\)</span> and <span class="math inline">\(12\)</span>, respectively.</li>
<li>The block factor captures variation among blocks. Omitting it would inflate the error term, reducing power to detect treatment differences. Including the blocking factor removes block‑to‑block variability from the error and improves precision.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-13_04" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="sec-13_04"><span class="header-section-number">13.4</span> Repeated measures ANOVA</h2>
<blockquote class="blockquote">
<p>“Beware of the problem of testing too many hypotheses; the more you torture the data, the more likely they are to confess, but confessions obtained under duress may not be admissible in the court of scientific opinion.” - Stephen Stigler</p>
</blockquote>
<blockquote class="blockquote">
<p><strong>Guiding question:</strong> <em>How do we compare means when the same subjects are measured repeatedly over time or under several conditions?</em></p>
</blockquote>
<p>In many experiments the same experimental units are observed under multiple conditions—for example, measuring patients’ blood pressure at baseline, 1 month and 3 months after starting medication. Because measurements on the same subject are correlated, we cannot treat them as independent. A <blank>repeated measures ANOVA</blank> compares the means of three or more related measurements on the same subjects, taking into account this correlation.</p>
<section id="model-and-partitioning-variance" class="level3">
<h3 class="anchored" data-anchor-id="model-and-partitioning-variance">Model and partitioning variance</h3>
<p>For a one‑factor repeated measures design with <span class="math inline">\(m\)</span> time points or conditions, we have <span class="math inline">\(n\)</span> subjects each observed under all <span class="math inline">\(m\)</span> conditions. Let <span class="math inline">\(y_{ij}\)</span> denote the response of subject <span class="math inline">\(j\)</span> at time <span class="math inline">\(i\)</span>. The model can be written as</p>
<p><span class="math display">\[
y_{ij} = \mu + \tau_i + s_j + \varepsilon_{ij}
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the grand mean, <span class="math inline">\(\tau_i\)</span> is the effect of condition <span class="math inline">\(i\)</span>, <span class="math inline">\(s_j\)</span> is the effect of subject <span class="math inline">\(j\)</span> (a random subject effect), and <span class="math inline">\(\varepsilon_{ij}\)</span> are error terms.</p>
<p>The ANOVA partitions the total variation into <em>between‑treatments</em> (conditions), <em>between‑subjects</em>, and <em>error (within‑subjects)</em> components. The F statistic for testing <span class="math inline">\(H_0: \tau_1=\cdots=\tau_m=0\)</span> uses the mean square for treatments divided by the mean square error:</p>
<p><span class="math display">\[
F = \frac{\mathrm{MS}_{\text{Treatments}}}{\mathrm{MS}_{\text{Error}}}
\]</span></p>
<p>The error term is derived by subtracting the between‑subjects variation from the within‑subjects variation, leading to a smaller denominator and increased power compared with ordinary one‑way ANOVA.</p>
</section>
<section id="assumptions-and-sphericity" class="level3">
<h3 class="anchored" data-anchor-id="assumptions-and-sphericity">Assumptions and sphericity</h3>
<p>Repeated measures ANOVA requires that the differences between all pairs of conditions have equal variances—a property known as <em>sphericity</em>. If sphericity is violated (common when measurements are taken at closely spaced time points), the F statistics may be too liberal. Solutions include applying a <em>Huynh–Feldt</em> or <em>Greenhouse–Geisser</em> correction to the degrees of freedom or using a multivariate approach such as MANOVA. Another assumption is that the subjects are independent; repeated measures should not be confused with randomized block designs in which treatments are assigned to different units within a block.</p>
</section>
<section id="example-pain-scores-over-time" class="level3">
<h3 class="anchored" data-anchor-id="example-pain-scores-over-time">Example: Pain scores over time</h3>
<p>Suppose researchers collect pain scores on 12 patients after a surgical procedure at baseline, 2 hours, 6 hours, and 24 hours post‑surgery. The goal is to determine whether mean pain changes over time. The repeated measures ANOVA compares mean pain at the four time points.</p>
<p>JMP output for the repeated measures ANOVA is shown below:</p>
<p><img src="images/repeated measures1.png" class="img-fluid"></p>
<p>At the 5% significance level, there is not enough evidence to conclude the mean pain levels differs over time. We can also construct Tukey HSD confidence intervals as we have done before. Since we did not find the mean pain levels differ over any of the time points, we expect these intervals to all include zero.</p>
<p><img src="images/repeated measures2.png" class="img-fluid"></p>
<!-- # ```{r} -->
<!-- # # set.seed(101) -->
<!-- # # library(tidyverse) -->
<!-- # #  -->
<!-- # # dat <- tibble( -->
<!-- # #   subject = factor(rep(1:12, each = 4)), -->
<!-- # #   time = factor(rep(c("Baseline", "2 hr", "6 hr", "24 hr"), times = 12), -->
<!-- # #                 levels = c("Baseline","2 hr","6 hr","24 hr")), -->
<!-- # #   pain = rep(c(6,5,3,2), each = 12) + rep(round(rnorm(12,0,1),2), each = 4) + round(rnorm(48,0,0.5),2) -->
<!-- # # ) -->
<!-- # #  -->
<!-- # # # write_csv(dat, "pain and time.csv") -->
<!-- # #  -->
<!-- # # model <- aov(pain ~ time + Error(subject/time), data = dat) -->
<!-- # # summary(model) -->
<!-- # ``` -->
</section>
<section id="conducting-repeated-measures-anova-in-jmp-18-student-edition" class="level3">
<h3 class="anchored" data-anchor-id="conducting-repeated-measures-anova-in-jmp-18-student-edition">Conducting repeated measures ANOVA in JMP 18 Student Edition</h3>
<p>Stack the repeated measurements into a single column with a factor column indicating the measurement occasion. Then use <strong>Analyze &gt; Fit Model</strong> with the response variable as <em>Y</em> and include the repeated factor, the subject identifier, and their interaction. Select <em>Random Effects</em> for the subject term to specify the correlation structure. This approach yields the usual ANOVA table and F tests with appropriate degrees of freedom.</p>
<section id="recap-3" class="level4">
<h4 class="anchored" data-anchor-id="recap-3">Recap</h4>
<table class="table">
<colgroup>
<col style="width: 55%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Definition</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Repeated measures ANOVA</strong></td>
<td>A method for comparing means of three or more measurements on the same subjects, accounting for correlation among repeated observations.</td>
</tr>
<tr class="even">
<td><strong>Sphericity</strong></td>
<td>The assumption that the variances of differences between all pairs of conditions are equal.</td>
</tr>
<tr class="odd">
<td><strong>Between‑subjects variation</strong></td>
<td>Variability due to differences among subjects; removed from the error term in repeated measures ANOVA to increase sensitivity.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="check-your-understanding-3" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-3">Check your understanding</h3>
<ol type="1">
<li>Why can’t we treat repeated measurements on the same subject as independent observations?</li>
<li>What is the purpose of the sphericity assumption, and what adjustments can be made when it is violated?</li>
<li>Describe one advantage of the repeated measures design over a completely randomized design when the same subjects are measured multiple times.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Measurements taken on the same subject are correlated; they share subject‑specific variability that violates the independence assumption of one‑way ANOVA. Repeated measures ANOVA models this correlation by separating between‑subjects and within‑subjects variation.</li>
<li>Sphericity ensures equal variances of pairwise differences between conditions. When sphericity is violated, F statistics can be adjusted using the Greenhouse–Geisser or Huynh–Feldt correction, or one can use a multivariate approach such as MANOVA.</li>
<li>Because each subject serves as their own control, repeated measures designs reduce the impact of between‑subject variability. This typically increases statistical power and requires fewer subjects to detect a given effect.</li>
</ol>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>