<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STA 2381 Introductory Statistical Methods - 14&nbsp; Correlation and Simple Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style type="text/css">
.sidebar .chapter-number {
color: #FFB81c;
}
freeblank {
  color: transparent;
  cursor: pointer;
}
freeblank.clicked {
  color: red;
}
blank {
  display: inline-block; 
  position: relative;
  padding: 0 10px;
  color: transparent;
  cursor: pointer;
}
blank::before {
  content: ''; /* Creates a custom underline */
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  height: 1px; /* Thickness of the underline */
  background-color: black; /* Color of the underline */
}
blank.clicked {
  color: red;
}
</style>
<script>
document.addEventListener('click', (event) => {
  if (event.target.tagName === 'BLANK') {
    event.target.classList.add('clicked');
  }
});
document.addEventListener('click', (event) => {
  if (event.target.tagName === 'FREEBLANK') {
    event.target.classList.add('clicked');
  }
});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./14.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Correlation and Simple Linear Regression</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Collecting Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Describing Data with Tables and Graphs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Describing Data with Numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Probability Concepts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sampling Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Estimation and Confidence Intervals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Hypothesis Testing: The Basics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Hypothesis Testing with Categorical Response</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Methods for Quantitative Response Variables – One and Two Groups</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Analysis of Variance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Correlation and Simple Linear Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-14_01" id="toc-sec-14_01" class="nav-link active" data-scroll-target="#sec-14_01"><span class="header-section-number">14.1</span> Scatterplots and the Correlation Coefficient</a>
  <ul class="collapse">
  <li><a href="#measuring-linear-association" id="toc-measuring-linear-association" class="nav-link" data-scroll-target="#measuring-linear-association">Measuring linear association</a></li>
  <li><a href="#example-volume-of-lumber" id="toc-example-volume-of-lumber" class="nav-link" data-scroll-target="#example-volume-of-lumber">Example: Volume of lumber</a></li>
  <li><a href="#correlation-coefficient" id="toc-correlation-coefficient" class="nav-link" data-scroll-target="#correlation-coefficient">Correlation Coefficient</a></li>
  <li><a href="#example-age-and-systolic-blood-pressure" id="toc-example-age-and-systolic-blood-pressure" class="nav-link" data-scroll-target="#example-age-and-systolic-blood-pressure">Example: Age and systolic blood pressure</a></li>
  <li><a href="#some-examples-of-r" id="toc-some-examples-of-r" class="nav-link" data-scroll-target="#some-examples-of-r">Some Examples of <span class="math inline">\(r\)</span></a></li>
  <li><a href="#the-population-correlation-coefficient" id="toc-the-population-correlation-coefficient" class="nav-link" data-scroll-target="#the-population-correlation-coefficient">The Population Correlation Coefficient</a></li>
  <li><a href="#creating-scatterplots-and-computing-correlation-in-jmp-18" id="toc-creating-scatterplots-and-computing-correlation-in-jmp-18" class="nav-link" data-scroll-target="#creating-scatterplots-and-computing-correlation-in-jmp-18">Creating scatterplots and computing correlation in JMP 18</a></li>
  <li><a href="#recap" id="toc-recap" class="nav-link" data-scroll-target="#recap">Recap</a></li>
  <li><a href="#check-your-understanding" id="toc-check-your-understanding" class="nav-link" data-scroll-target="#check-your-understanding">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-14_02" id="toc-sec-14_02" class="nav-link" data-scroll-target="#sec-14_02"><span class="header-section-number">14.2</span> Least Squares Regression Line</a>
  <ul class="collapse">
  <li><a href="#fitting-the-model-the-method-of-least-squares" id="toc-fitting-the-model-the-method-of-least-squares" class="nav-link" data-scroll-target="#fitting-the-model-the-method-of-least-squares">Fitting the Model: The Method of Least Squares</a></li>
  <li><a href="#example-advertising-and-sales-business" id="toc-example-advertising-and-sales-business" class="nav-link" data-scroll-target="#example-advertising-and-sales-business">Example: Advertising and sales (business)</a></li>
  <li><a href="#performing-regression-in-jmp-18" id="toc-performing-regression-in-jmp-18" class="nav-link" data-scroll-target="#performing-regression-in-jmp-18">Performing regression in JMP 18</a></li>
  <li><a href="#recap-1" id="toc-recap-1" class="nav-link" data-scroll-target="#recap-1">Recap</a></li>
  <li><a href="#check-your-understanding-1" id="toc-check-your-understanding-1" class="nav-link" data-scroll-target="#check-your-understanding-1">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-14_03" id="toc-sec-14_03" class="nav-link" data-scroll-target="#sec-14_03"><span class="header-section-number">14.3</span> Interpreting the Slope and Intercept</a>
  <ul class="collapse">
  <li><a href="#examples-across-fields" id="toc-examples-across-fields" class="nav-link" data-scroll-target="#examples-across-fields">Examples across fields</a></li>
  <li><a href="#inference-for-the-regression-slope" id="toc-inference-for-the-regression-slope" class="nav-link" data-scroll-target="#inference-for-the-regression-slope">Inference for the Regression Slope</a></li>
  <li><a href="#recap-2" id="toc-recap-2" class="nav-link" data-scroll-target="#recap-2">Recap</a></li>
  <li><a href="#check-your-understanding-2" id="toc-check-your-understanding-2" class="nav-link" data-scroll-target="#check-your-understanding-2">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-14_04" id="toc-sec-14_04" class="nav-link" data-scroll-target="#sec-14_04"><span class="header-section-number">14.4</span> Assessing the Fit</a>
  <ul class="collapse">
  <li><a href="#proportion-of-variation-explained" id="toc-proportion-of-variation-explained" class="nav-link" data-scroll-target="#proportion-of-variation-explained">Proportion of Variation Explained</a></li>
  <li><a href="#interpreting-r2" id="toc-interpreting-r2" class="nav-link" data-scroll-target="#interpreting-r2">Interpreting <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#getting-r2-in-jmp" id="toc-getting-r2-in-jmp" class="nav-link" data-scroll-target="#getting-r2-in-jmp">Getting <span class="math inline">\(R^2\)</span> in JMP</a></li>
  <li><a href="#recap-3" id="toc-recap-3" class="nav-link" data-scroll-target="#recap-3">Recap</a></li>
  <li><a href="#check-your-understanding-3" id="toc-check-your-understanding-3" class="nav-link" data-scroll-target="#check-your-understanding-3">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-14_05" id="toc-sec-14_05" class="nav-link" data-scroll-target="#sec-14_05"><span class="header-section-number">14.5</span> Residual Analysis</a>
  <ul class="collapse">
  <li><a href="#residual-plots" id="toc-residual-plots" class="nav-link" data-scroll-target="#residual-plots">Residual plots</a></li>
  <li><a href="#conducting-residual-analysis-in-jmp" id="toc-conducting-residual-analysis-in-jmp" class="nav-link" data-scroll-target="#conducting-residual-analysis-in-jmp">Conducting residual analysis in JMP</a></li>
  <li><a href="#recap-4" id="toc-recap-4" class="nav-link" data-scroll-target="#recap-4">Recap</a></li>
  <li><a href="#check-your-understanding-4" id="toc-check-your-understanding-4" class="nav-link" data-scroll-target="#check-your-understanding-4">Check your understanding</a></li>
  </ul></li>
  <li><a href="#sec-14_06" id="toc-sec-14_06" class="nav-link" data-scroll-target="#sec-14_06"><span class="header-section-number">14.6</span> Prediction Intervals and Confidence Intervals</a>
  <ul class="collapse">
  <li><a href="#the-residual-standard-deviation" id="toc-the-residual-standard-deviation" class="nav-link" data-scroll-target="#the-residual-standard-deviation">The Residual Standard Deviation</a></li>
  <li><a href="#confidence-and-prediction-intervals" id="toc-confidence-and-prediction-intervals" class="nav-link" data-scroll-target="#confidence-and-prediction-intervals">Confidence and Prediction Intervals</a></li>
  <li><a href="#sampling-errors-for-the-estimator-of-the-mean-of-y-and-the-predictor-of-an-individual-new-value-of-y" id="toc-sampling-errors-for-the-estimator-of-the-mean-of-y-and-the-predictor-of-an-individual-new-value-of-y" class="nav-link" data-scroll-target="#sampling-errors-for-the-estimator-of-the-mean-of-y-and-the-predictor-of-an-individual-new-value-of-y">Sampling Errors for the Estimator of the Mean of <span class="math inline">\(y\)</span> and the Predictor of an Individual New Value of <span class="math inline">\(y\)</span></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Correlation and Simple Linear Regression</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="sec-14_01" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="sec-14_01"><span class="header-section-number">14.1</span> Scatterplots and the Correlation Coefficient</h2>
<blockquote class="blockquote">
<p>“The modern student, and too often his teacher, overlook the fact that such a simple thing as a scatter diagram is a more important tool of prediction than the correlation coefficient…” – W. Edwards Deming</p>
</blockquote>
<blockquote class="blockquote">
<p><em>Guiding question:</em> <em>How do we visualize and measure the strength and direction of a linear relationship between two quantitative variables?</em></p>
</blockquote>
<p>When exploring two numerical variables, the first step is to look at the variables graphically. A <blank>scatterplot</blank> is simply a collection of points in the plane where each point represents one observation. We usually plot the explanatory variable on the horizontal axis and the response variable on the vertical axis. If you are unsure which variable should go on which axis, it often does not matter for descriptive purposes, but if your goal is prediction you should place the variable you wish to predict on the vertical axis.</p>
<p>Scatterplots reveal patterns that numbers alone cannot. If the points lie cluster around a straight line, the relationship is approximately <blank>linear</blank>. If the points form a curved band, the association is nonlinear. The closer the points are to a straight line, the stronger the linear relationship. Outliers can distort our impression, so always scan the plot before jumping into calculations.</p>
<section id="measuring-linear-association" class="level3">
<h3 class="anchored" data-anchor-id="measuring-linear-association">Measuring linear association</h3>
<p>To quantify the strength and direction of a linear relationship we use the <blank>correlation coefficient</blank>.</p>
<p>It is computed as <span class="math display">\[
\begin{align*}
    {r=\frac{SS_{xy}}{\sqrt{SS_{xx}SS_{yy}}}}
\end{align*}
\]</span> where <span class="math display">\[
\begin{align*}
SS_{xy} =&amp; \sum \left(y_i-\bar{y}\right)\left(x_i-\bar{x}\right)\\
SS_{xx} =&amp; \sum \left(x_i-\bar{x}\right)^2\\
SS_{yy} =&amp; \sum \left(y_i-\bar{y}\right)^2
\end{align*}
\]</span></p>
<p><span class="math inline">\(SS_{xx}\)</span> and <span class="math inline">\(SS_{yy}\)</span> are measures of <em>variability</em> of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, respectively. That is, they indicate how <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> varies about their mean, individually.</p>
<p><span class="math inline">\(SS_{xy}\)</span> is a measure of how <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> vary <em>together</em>.</p>
<p>For example, consider the data in the scatterplot below. The two red lines represent the mean of the <span class="math inline">\(x\)</span> variable (the vertical red line is for <span class="math inline">\(\bar{x}\)</span>) and the mean of the <span class="math inline">\(y\)</span> variable (the horizontal red line is for <span class="math inline">\(\bar{y}\)</span>).</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>Let’s find <span class="math inline">\(SS_{xx}\)</span>, <span class="math inline">\(SS_{yy}\)</span>, and <span class="math inline">\(SS_{xy}\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 7%">
<col style="width: 6%">
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(x\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y\)</span></th>
<th style="text-align: right;"><span class="math inline">\((x - \bar{x})^2\)</span></th>
<th style="text-align: right;"><span class="math inline">\((y - \bar{y})^2\)</span></th>
<th style="text-align: right;"><span class="math inline">\((x - \bar{x})(y - \bar{y})\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">2.00</td>
<td style="text-align: right;">16.7587891</td>
<td style="text-align: right;">0.8441016</td>
<td style="text-align: right;">-3.7611328</td>
</tr>
<tr class="even">
<td style="text-align: right;">2.00</td>
<td style="text-align: right;">1.40</td>
<td style="text-align: right;">9.5712891</td>
<td style="text-align: right;">0.1016016</td>
<td style="text-align: right;">-0.9861328</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2.75</td>
<td style="text-align: right;">1.60</td>
<td style="text-align: right;">5.4931641</td>
<td style="text-align: right;">0.2691016</td>
<td style="text-align: right;">-1.2158203</td>
</tr>
<tr class="even">
<td style="text-align: right;">4.00</td>
<td style="text-align: right;">1.25</td>
<td style="text-align: right;">1.1962891</td>
<td style="text-align: right;">0.0284766</td>
<td style="text-align: right;">-0.1845703</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6.00</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">0.8212891</td>
<td style="text-align: right;">0.0066016</td>
<td style="text-align: right;">-0.0736328</td>
</tr>
<tr class="even">
<td style="text-align: right;">7.00</td>
<td style="text-align: right;">0.50</td>
<td style="text-align: right;">3.6337891</td>
<td style="text-align: right;">0.3378516</td>
<td style="text-align: right;">-1.1080078</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8.00</td>
<td style="text-align: right;">0.50</td>
<td style="text-align: right;">8.4462891</td>
<td style="text-align: right;">0.3378516</td>
<td style="text-align: right;">-1.6892578</td>
</tr>
<tr class="even">
<td style="text-align: right;">10.00</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">24.0712891</td>
<td style="text-align: right;">0.4641016</td>
<td style="text-align: right;">-3.3423828</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Note that each value in <span class="math inline">\((x_i-\bar{x})(y_i-\bar{y})\)</span> is negative. This is because as <span class="math inline">\(x\)</span> is below <span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(y\)</span> is above <span class="math inline">\(\bar{y}\)</span>. Likewise, as <span class="math inline">\(x\)</span> is above <span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(y\)</span> is below <span class="math inline">\(\bar{y}\)</span>. In the scatterplot above, you can see how the observations are below or above these lines.</p>
<p>Summing up the values give us: <span class="math display">\[
\begin{align*}
SS_{xx} =&amp; \sum \left(x_i-\bar{x}\right)^2\\
= &amp; 69.9921875\\\\
SS_{yy} =&amp; \sum \left(y_i-\bar{y}\right)^2\\
= &amp; 2.3896875\\\\
SS_{xy} =&amp; \sum \left(y_i-\bar{y}\right)\left(x_i-\bar{x}\right)\\
= &amp; -12.3609375
\end{align*}
\]</span></p>
</section>
<section id="example-volume-of-lumber" class="level3">
<h3 class="anchored" data-anchor-id="example-volume-of-lumber">Example: Volume of lumber</h3>
<p>In the following scatterplot, the volume of timber from 31 black cherry trees are plotted against the diamter of the tree measured at 54 inches off the ground.</p>
<p>Again, we plot the data with red lines representing <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(\bar{y}\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(x\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y\)</span></th>
<th style="text-align: right;"><span class="math inline">\((x - \bar{x})^2\)</span></th>
<th style="text-align: right;"><span class="math inline">\((y - \bar{y})^2\)</span></th>
<th style="text-align: right;"><span class="math inline">\((x - \bar{x})(y - \bar{y})\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">8.3</td>
<td style="text-align: right;">10.3</td>
<td style="text-align: right;">24.4865349</td>
<td style="text-align: right;">394.855359</td>
<td style="text-align: right;">98.3292404</td>
</tr>
<tr class="even">
<td style="text-align: right;">8.6</td>
<td style="text-align: right;">10.3</td>
<td style="text-align: right;">21.6075026</td>
<td style="text-align: right;">394.855359</td>
<td style="text-align: right;">92.3679501</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8.8</td>
<td style="text-align: right;">10.2</td>
<td style="text-align: right;">19.7881478</td>
<td style="text-align: right;">398.839553</td>
<td style="text-align: right;">88.8385952</td>
</tr>
<tr class="even">
<td style="text-align: right;">10.5</td>
<td style="text-align: right;">16.4</td>
<td style="text-align: right;">7.5536316</td>
<td style="text-align: right;">189.639553</td>
<td style="text-align: right;">37.8479501</td>
</tr>
<tr class="odd">
<td style="text-align: right;">10.7</td>
<td style="text-align: right;">18.8</td>
<td style="text-align: right;">6.4942768</td>
<td style="text-align: right;">129.298907</td>
<td style="text-align: right;">28.9776275</td>
</tr>
<tr class="even">
<td style="text-align: right;">10.8</td>
<td style="text-align: right;">19.7</td>
<td style="text-align: right;">5.9945994</td>
<td style="text-align: right;">109.641165</td>
<td style="text-align: right;">25.6369823</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11.0</td>
<td style="text-align: right;">15.6</td>
<td style="text-align: right;">5.0552445</td>
<td style="text-align: right;">212.313101</td>
<td style="text-align: right;">32.7611759</td>
</tr>
<tr class="even">
<td style="text-align: right;">11.0</td>
<td style="text-align: right;">18.2</td>
<td style="text-align: right;">5.0552445</td>
<td style="text-align: right;">143.304069</td>
<td style="text-align: right;">26.9153694</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11.1</td>
<td style="text-align: right;">22.6</td>
<td style="text-align: right;">4.6155671</td>
<td style="text-align: right;">57.319553</td>
<td style="text-align: right;">16.2653694</td>
</tr>
<tr class="even">
<td style="text-align: right;">11.2</td>
<td style="text-align: right;">19.9</td>
<td style="text-align: right;">4.1958897</td>
<td style="text-align: right;">105.492778</td>
<td style="text-align: right;">21.0389178</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11.3</td>
<td style="text-align: right;">24.2</td>
<td style="text-align: right;">3.7962123</td>
<td style="text-align: right;">35.652456</td>
<td style="text-align: right;">11.6337565</td>
</tr>
<tr class="even">
<td style="text-align: right;">11.4</td>
<td style="text-align: right;">21.0</td>
<td style="text-align: right;">3.4165349</td>
<td style="text-align: right;">84.106649</td>
<td style="text-align: right;">16.9514984</td>
</tr>
<tr class="odd">
<td style="text-align: right;">11.4</td>
<td style="text-align: right;">21.4</td>
<td style="text-align: right;">3.4165349</td>
<td style="text-align: right;">76.929875</td>
<td style="text-align: right;">16.2121436</td>
</tr>
<tr class="even">
<td style="text-align: right;">11.7</td>
<td style="text-align: right;">21.3</td>
<td style="text-align: right;">2.3975026</td>
<td style="text-align: right;">78.694069</td>
<td style="text-align: right;">13.7356920</td>
</tr>
<tr class="odd">
<td style="text-align: right;">12.0</td>
<td style="text-align: right;">19.1</td>
<td style="text-align: right;">1.5584703</td>
<td style="text-align: right;">122.566327</td>
<td style="text-align: right;">13.8208533</td>
</tr>
<tr class="even">
<td style="text-align: right;">12.9</td>
<td style="text-align: right;">22.2</td>
<td style="text-align: right;">0.1213736</td>
<td style="text-align: right;">63.536327</td>
<td style="text-align: right;">2.7769823</td>
</tr>
<tr class="odd">
<td style="text-align: right;">12.9</td>
<td style="text-align: right;">33.8</td>
<td style="text-align: right;">0.1213736</td>
<td style="text-align: right;">13.169875</td>
<td style="text-align: right;">-1.2643080</td>
</tr>
<tr class="even">
<td style="text-align: right;">13.3</td>
<td style="text-align: right;">27.4</td>
<td style="text-align: right;">0.0026639</td>
<td style="text-align: right;">7.678262</td>
<td style="text-align: right;">-0.1430177</td>
</tr>
<tr class="odd">
<td style="text-align: right;">13.7</td>
<td style="text-align: right;">25.7</td>
<td style="text-align: right;">0.2039542</td>
<td style="text-align: right;">19.989552</td>
<td style="text-align: right;">-2.0191467</td>
</tr>
<tr class="even">
<td style="text-align: right;">13.8</td>
<td style="text-align: right;">24.9</td>
<td style="text-align: right;">0.3042768</td>
<td style="text-align: right;">27.783101</td>
<td style="text-align: right;">-2.9075338</td>
</tr>
<tr class="odd">
<td style="text-align: right;">14.0</td>
<td style="text-align: right;">34.5</td>
<td style="text-align: right;">0.5649220</td>
<td style="text-align: right;">18.740520</td>
<td style="text-align: right;">3.2537565</td>
</tr>
<tr class="even">
<td style="text-align: right;">14.2</td>
<td style="text-align: right;">31.7</td>
<td style="text-align: right;">0.9055671</td>
<td style="text-align: right;">2.337940</td>
<td style="text-align: right;">1.4550468</td>
</tr>
<tr class="odd">
<td style="text-align: right;">14.5</td>
<td style="text-align: right;">36.3</td>
<td style="text-align: right;">1.5665349</td>
<td style="text-align: right;">37.565036</td>
<td style="text-align: right;">7.6711759</td>
</tr>
<tr class="even">
<td style="text-align: right;">16.0</td>
<td style="text-align: right;">38.3</td>
<td style="text-align: right;">7.5713736</td>
<td style="text-align: right;">66.081165</td>
<td style="text-align: right;">22.3679501</td>
</tr>
<tr class="odd">
<td style="text-align: right;">16.3</td>
<td style="text-align: right;">42.6</td>
<td style="text-align: right;">9.3123413</td>
<td style="text-align: right;">154.480843</td>
<td style="text-align: right;">37.9285952</td>
</tr>
<tr class="even">
<td style="text-align: right;">17.3</td>
<td style="text-align: right;">55.4</td>
<td style="text-align: right;">16.4155671</td>
<td style="text-align: right;">636.504069</td>
<td style="text-align: right;">102.2182726</td>
</tr>
<tr class="odd">
<td style="text-align: right;">17.5</td>
<td style="text-align: right;">55.7</td>
<td style="text-align: right;">18.0762123</td>
<td style="text-align: right;">651.731488</td>
<td style="text-align: right;">108.5395630</td>
</tr>
<tr class="even">
<td style="text-align: right;">17.9</td>
<td style="text-align: right;">58.3</td>
<td style="text-align: right;">21.6375026</td>
<td style="text-align: right;">791.242456</td>
<td style="text-align: right;">130.8453694</td>
</tr>
<tr class="odd">
<td style="text-align: right;">18.0</td>
<td style="text-align: right;">51.5</td>
<td style="text-align: right;">22.5778252</td>
<td style="text-align: right;">454.927617</td>
<td style="text-align: right;">101.3473049</td>
</tr>
<tr class="even">
<td style="text-align: right;">18.0</td>
<td style="text-align: right;">51.0</td>
<td style="text-align: right;">22.5778252</td>
<td style="text-align: right;">433.848585</td>
<td style="text-align: right;">98.9714984</td>
</tr>
<tr class="odd">
<td style="text-align: right;">20.6</td>
<td style="text-align: right;">77.0</td>
<td style="text-align: right;">54.0462123</td>
<td style="text-align: right;">2192.958262</td>
<td style="text-align: right;">344.2689178</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>In this example, most of the observations have <span class="math inline">\((x-\bar{x})(y-\bar{y})\)</span> that are positive. This is because these observations have values of <span class="math inline">\(x\)</span> that are below <span class="math inline">\(\bar{x}\)</span> and values of <span class="math inline">\(y\)</span> that are below <span class="math inline">\(\bar{y}\)</span>, or values of <span class="math inline">\(x\)</span> that are above <span class="math inline">\(\bar{x}\)</span> and values of <span class="math inline">\(y\)</span> that are above <span class="math inline">\(\bar{y}\)</span>.</p>
<p>There are four observations that have a negative value of <span class="math inline">\((x-\bar{x})(y-\bar{y})\)</span>. Although they are negative, the value of <span class="math inline">\(SS_{xy}\)</span> is positive due to all the observations with positive values of <span class="math inline">\((x-\bar{x})(y-\bar{y})\)</span>. Therefore, we say if <span class="math inline">\(SS_{xy}\)</span> is <blank>positive</blank>, then <span class="math inline">\(y\)</span> tends to increase as <span class="math inline">\(x\)</span> increases. Likewise, if <span class="math inline">\(SS_{xy}\)</span> is <blank>negative</blank>, then <span class="math inline">\(y\)</span> tends to decrease as <span class="math inline">\(x\)</span> increases.</p>
<p>If <span class="math inline">\(SS_{xy}\)</span> is zero (or close to zero), then we say <span class="math inline">\(y\)</span> does not tend to change as <span class="math inline">\(x\)</span> increases.</p>
</section>
<section id="correlation-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="correlation-coefficient">Correlation Coefficient</h3>
<p>We first note that <span class="math inline">\(SS_{xy}\)</span> cannot be greater in absolute value than the quantity <span class="math display">\[
\sqrt{SS_{xx}SS_{yy}}
\]</span> We will not prove this here, but it is a direct application of the Cauchy-Schwarz inequality .</p>
<p>Thus, the correlation coefficient <span class="math display">\[
\begin{align}
    r=\frac{SS_{xy}}{\sqrt{SS_{xx}SS_{yy}}}
\end{align}
\]</span> is a value sucha that <span class="math display">\[
-1\le r \le 1
\]</span></p>
<p>If <span class="math inline">\(r=0\)</span>, then there is no linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>If <span class="math inline">\(r\)</span> is positive, then the slope of the linear relationship is positive. If <span class="math inline">\(r\)</span> is negative, then the slope of the linear relationship is negative.</p>
<p>The closer <span class="math inline">\(r\)</span> is to one in absolute value, the stronger the linear relationship is between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>Because it is based on means and standard deviations, Pearson’s <span class="math inline">\(r\)</span> is sensitive to outliers and assumes the data are reasonably normal. When one or both variables are non‑normal, a rank‑based measure such as Spearman’s rho may be used instead (not discussed in this course).</p>
<p>It is tempting to interpret a large correlation as evidence of <blank>causation</blank>, but correlation merely quantifies association. Even a strong correlation can arise from confounding variables or chance. Always consider the context and remember that a scatterplot and subject‑matter knowledge are essential for interpretation.</p>
</section>
<section id="example-age-and-systolic-blood-pressure" class="level3">
<h3 class="anchored" data-anchor-id="example-age-and-systolic-blood-pressure">Example: Age and systolic blood pressure</h3>
<p>To see how scatterplots and correlation work in practice, consider a small study of 20 adults ranging in age from 30 to 80 years. The response variable is systolic blood pressure (measured in mm Hg). The scatterplot below shows the relationship.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>The cloud of points slopes upward, indicating a positive relationship: older participants tend to have higher systolic blood pressure. The correlation coefficient for this dataset is about 0.93, suggesting a strong positive linear association.</p>
</section>
<section id="some-examples-of-r" class="level3">
<h3 class="anchored" data-anchor-id="some-examples-of-r">Some Examples of <span class="math inline">\(r\)</span></h3>
<p>The best way to grasp correlation is to see examples. In <a href="#fig-05_01">Figure&nbsp;<span>14.1</span></a>, scatterplots of 200 observations are shown with a least squares line.</p>
<div id="fig-05_01" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-05_01a" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/fig_02_04_01a.png" class="img-fluid figure-img" data-ref-parent="fig-05_01"></p>
<figcaption class="figure-caption">(a) <span class="math inline">\(r=-0.079\)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-05_01b" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/fig_02_04_01b.png" class="img-fluid figure-img" data-ref-parent="fig-05_01"></p>
<figcaption class="figure-caption">(b) <span class="math inline">\(r=-0.672\)</span></figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-05_01c" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/fig_02_04_01c.png" class="img-fluid figure-img" data-ref-parent="fig-05_01"></p>
<figcaption class="figure-caption">(c) <span class="math inline">\(r=0.723\)</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-05_01d" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/fig_02_04_01d.png" class="img-fluid figure-img" data-ref-parent="fig-05_01"></p>
<figcaption class="figure-caption">(d) <span class="math inline">\(r=0.524\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;14.1: Examples of correlation</figcaption><p></p>
</figure>
</div>
<p>Note how the value of <span class="math inline">\(r\)</span> relates to how spread out the points are from the line as well as to the slope of the line.</p>
</section>
<section id="the-population-correlation-coefficient" class="level3">
<h3 class="anchored" data-anchor-id="the-population-correlation-coefficient">The Population Correlation Coefficient</h3>
<p>The correlation <span class="math inline">\(r\)</span> is for the observed data which is usually from a sample. Thus, <span class="math inline">\(r\)</span> is the <em>sample</em> correlation coefficient.</p>
<p>We could make a hypothesis about the correlation of the <em>population</em> based on the sample. We will denote the population correlation with <span class="math inline">\(\rho\)</span>. The hypothesis we will want to test is <span class="math display">\[
\begin{align*}
  H_0:\rho = 0\\
H_a:\rho \ne 0
\end{align*}
\]</span></p>
<p>The test statistic is <span class="math display">\[
\begin{align}
t &amp; =\frac{r\sqrt{\left(n-2\right)}}{\sqrt{1-r^{2}}}
\end{align}
\]</span></p>
<p>If <span class="math inline">\(H_0\)</span> is true, then <span class="math inline">\(t\)</span> will have a Student’s <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom.</p>
</section>
<section id="creating-scatterplots-and-computing-correlation-in-jmp-18" class="level3">
<h3 class="anchored" data-anchor-id="creating-scatterplots-and-computing-correlation-in-jmp-18">Creating scatterplots and computing correlation in JMP 18</h3>
<p>JMP makes it easy to explore the relationship between two quantitative variables:</p>
<ul>
<li><strong>Create a scatterplot.</strong> Load your data into a JMP table. Choose <strong>Graph → Graph Builder</strong>, drag the explanatory variable to the X‑axis and the response variable to the Y‑axis, and select the <em>Scatter Plot</em> element. You can add a fitted line by clicking the blue triangle next to <strong>Fit Line</strong>.</li>
<li><strong>Compute the correlation.</strong> Choose <strong>Analyze → Multivariate Methods → Multivariate</strong>. Select your variables and click <strong>Y, Columns</strong>. JMP displays a matrix of scatterplots and gives the Pearson correlation coefficient in the correlation table. If normality is questionable, use <strong>Analyze → Multivariate → Nonparametric Correlations</strong> for Spearman’s rho.</li>
</ul>
</section>
<section id="recap" class="level3">
<h3 class="anchored" data-anchor-id="recap">Recap</h3>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Explanation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>scatterplot</strong></td>
<td>A graph of paired quantitative data where each point represents one observation; used to visualize the relationship between two variables.</td>
</tr>
<tr class="even">
<td><strong>Pearson’s correlation coefficient (r)</strong></td>
<td>A measure of the strength and direction of a linear relationship, ranging from −1 to +1; positive values indicate direct association and negative values indicate inverse association.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding">Check your understanding</h3>
<ol type="1">
<li>A study of 30 students reports a correlation of <span class="math inline">\(r=0.85\)</span> between hours studied and exam score. What does this value tell you about the relationship? Would you conclude that studying more <em>causes</em> higher scores? Explain.</li>
<li>Sketch (or describe) how a scatterplot would look if <span class="math inline">\(r\approx -0.6\)</span>. What does the sign and magnitude of this correlation tell you about the relationship?</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>The correlation of 0.85 indicates a strong positive linear association: students who study more tend to score higher. However, correlation on its own does not prove causation. Other factors (prior knowledge, test difficulty) may influence scores, and experimental control would be needed to establish a causal link.</li>
<li>A correlation of <span class="math inline">\(-0.6\)</span> produces a downward‑sloping cloud of points: as one variable increases, the other tends to decrease. The moderate magnitude (0.6) suggests a reasonably strong inverse relationship but with noticeable scatter around a straight line.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-14_02" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="sec-14_02"><span class="header-section-number">14.2</span> Least Squares Regression Line</h2>
<blockquote class="blockquote">
<p>“Regression. It is a universal rule that the unknown kinsman in any degree of any specified man, is probably more mediocre than he.” – Francis Galton</p>
</blockquote>
<blockquote class="blockquote">
<p><em>Guiding question:</em> <em>How can we use a straight line to make predictions and what makes one line better than another?</em></p>
</blockquote>
<p>After visualizing and quantifying the relationship between two variables, the next step is to model that relationship. In <strong>simple linear regression</strong>, we seek the line that best predicts the response variable <span class="math inline">\(y\)</span> from the explanatory variable <span class="math inline">\(x\)</span>. The model has the form <span class="math display">\[
\begin{align*}
y = \beta_0 + \beta_1 x+\varepsilon
\end{align*}
\]</span> where:</p>
<ul>
<li><span class="math inline">\(y\)</span> is the response variable (also known as the <blank>dependent</blank> variable)</li>
<li><span class="math inline">\(x\)</span> is the predictor variable (also called the <blank>independent</blank> variable or explanatory variable)</li>
<li><span class="math inline">\(\varepsilon\)</span> is the <em>random error</em> component</li>
<li><span class="math inline">\(\beta_0\)</span> is the <em>y-intercept</em> of the line (the point where the line intersects the y-axis)</li>
<li><span class="math inline">\(\beta_1\)</span> is the <em>slope</em> of the line (the change in the mean of <span class="math inline">\(y\)</span> for every 1-unit increase in <span class="math inline">\(x\)</span>)</li>
</ul>
<p>We use Greek symbols <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> to denote the y-intercept and slope of the line. These are population <em>parameters</em> with values that would only be known if we had access to the entire population of <span class="math inline">\((x, y)\)</span> measurements.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Review: Greek Letters in Notation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Usually, in Statistics, lower-case Greek letters are used to denote population parameters. In our model above, we have an exception. The Greek letter <span class="math inline">\(\varepsilon\)</span> is not a parameter, but a random variable (parameters are not random variables in frequentist statistics).</p>
</div>
</div>
<section id="fitting-the-model-the-method-of-least-squares" class="level3">
<h3 class="anchored" data-anchor-id="fitting-the-model-the-method-of-least-squares">Fitting the Model: The Method of Least Squares</h3>
<p>Suppose we have the data shown in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a> below and plotted in the scatterplot in <a href="#fig-2_1">Figure&nbsp;<span>14.2</span></a>.</p>
<div id="tbl-table2_1" class="anchored">
<table class="table">
<caption>Table&nbsp;14.1: Data for Scatterplot</caption>
<thead>
<tr class="header">
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td>2</td>
<td>1.4</td>
</tr>
<tr class="odd">
<td>2.75</td>
<td>1.6</td>
</tr>
<tr class="even">
<td>4</td>
<td>1.25</td>
</tr>
<tr class="odd">
<td>6</td>
<td>1</td>
</tr>
<tr class="even">
<td>7</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.5</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.4</td>
</tr>
</tbody>
</table>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2_1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="14_files/figure-html/fig-2_1-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption class="figure-caption">Figure&nbsp;14.2: Scatterplot of the data in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a></figcaption>
</figure>
</div>
</div>
</div>
<p>We hypothesize that a straight-line model relates <em>y</em> to <em>x</em>, as follows:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 x + \varepsilon
\]</span></p>
<p>How can we use the data from the eight observations in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a> to estimate the unknown y-intercept (<span class="math inline">\(\beta_0\)</span>) and slope (<span class="math inline">\(\beta_1\)</span>)?</p>
<p>We can start by trying some lines and see how well they fit the data. But how do we measure how well a line <em>fits</em> the data?</p>
<p>A quantitative method to evaluate how well a straight line fits a set of data is by measuring the deviations of the data points from the line.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Review: Deviations of Response Variable
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(y\)</span> is the variable of interest, so we are focused on the differences between observed <span class="math inline">\(y\)</span> and the predicted value of <span class="math inline">\(y\)</span></p>
</div>
</div>
<p>We calculate the magnitude of the <em>deviations</em> (the differences between observed and predicted values of <span class="math inline">\(y\)</span>).</p>
<p>These deviations, or prediction errors, represent the <em>vertical</em> distances between observed and predicted values of <span class="math inline">\(y\)</span>.</p>
<p>Suppose we try to fit the line <span id="eq-02_01"><span class="math display">\[
    \hat{y} =2-.2x
\tag{14.1}\]</span></span></p>
<p>This line can be seen in <a href="#fig-2_2">Figure&nbsp;<span>14.3</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2_2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="14_files/figure-html/fig-2_2-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption class="figure-caption">Figure&nbsp;14.3: Scatterplot of data in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a> with the red line representing the line in <a href="#eq-02_01">Equation&nbsp;<span>14.1</span></a></figcaption>
</figure>
</div>
</div>
</div>
<p>The observed and predicted values of <span class="math inline">\(y\)</span>, their differences, and their squared differences are shown in the table below.</p>
<div id="tbl-table2_2" class="anchored">
<table class="table">
<caption>Table&nbsp;14.2: Deviations and squared deviations of the line in <a href="#eq-02_01">Equation&nbsp;<span>14.1</span></a> and the data in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a>.</caption>
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(y\)</span></th>
<th><span class="math inline">\(\hat{y}\)</span></th>
<th><span class="math inline">\((y - \hat{y})\)</span></th>
<th><span class="math inline">\((y - \hat{y})^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>1.8</td>
<td>0.2</td>
<td>0.004</td>
</tr>
<tr class="even">
<td>2</td>
<td>1.4</td>
<td>1.6</td>
<td>-0.2</td>
<td>0.004</td>
</tr>
<tr class="odd">
<td>2.75</td>
<td>1.6</td>
<td>1.45</td>
<td>0.15</td>
<td>0.0225</td>
</tr>
<tr class="even">
<td>4</td>
<td>1.25</td>
<td>1.2</td>
<td>0.05</td>
<td>0.0025</td>
</tr>
<tr class="odd">
<td>6</td>
<td>1</td>
<td>0.8</td>
<td>0.2</td>
<td>0.04</td>
</tr>
<tr class="even">
<td>7</td>
<td>0.5</td>
<td>0.6</td>
<td>-0.1</td>
<td>0.01</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.5</td>
<td>0.4</td>
<td>0.1</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.4</td>
<td>0</td>
<td>0.4</td>
<td>0.16</td>
</tr>
</tbody>
</table>
</div>
<p>Note that the sum of the errors (SE) is 0.8, and the <em>sum</em> of <em>squares</em> of the <em>errors</em> (SSE), which emphasizes larger deviations from the line, is 0.325.</p>
<p>We can try another line to see if we do better at predicting <span class="math inline">\(y\)</span> (that is, have smaller SSE).</p>
<p>Let’s try the line <span id="eq-02_02"><span class="math display">\[
    \hat{y} =1.8-.15x
\tag{14.2}\]</span></span></p>
<p>This line can be seen in <a href="#fig-2_3">Figure&nbsp;<span>14.4</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-2_3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="14_files/figure-html/fig-2_3-1.png" class="img-fluid figure-img" width="576"></p>
<figcaption class="figure-caption">Figure&nbsp;14.4: Scatterplot of data in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a> with the red line representing the line in <a href="#eq-02_02">Equation&nbsp;<span>14.2</span></a></figcaption>
</figure>
</div>
</div>
</div>
<p>The fit results are shown in <a href="#tbl-table2_3">Table&nbsp;<span>14.3</span></a>.</p>
<div id="tbl-table2_3" class="anchored">
<table class="table">
<caption>Table&nbsp;14.3: Deviations and squared deviations of the line in <a href="#eq-02_02">Equation&nbsp;<span>14.2</span></a> and the data in <a href="#tbl-table2_1">Table&nbsp;<span>14.1</span></a>.</caption>
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(y\)</span></th>
<th><span class="math inline">\(\hat{y}\)</span></th>
<th><span class="math inline">\(y - \hat{y}\)</span></th>
<th><span class="math inline">\((y - \hat{y})^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>1.65</td>
<td>0.35</td>
<td>0.1225</td>
</tr>
<tr class="even">
<td>2</td>
<td>1.4</td>
<td>1.5</td>
<td>-0.1</td>
<td>0.01</td>
</tr>
<tr class="odd">
<td>2.75</td>
<td>1.6</td>
<td>1.3875</td>
<td>0.2125</td>
<td>0.04515625</td>
</tr>
<tr class="even">
<td>4</td>
<td>1.25</td>
<td>1.2</td>
<td>0.05</td>
<td>0.0025</td>
</tr>
<tr class="odd">
<td>6</td>
<td>1</td>
<td>0.9</td>
<td>0.1</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>7</td>
<td>0.5</td>
<td>0.75</td>
<td>-0.25</td>
<td>0.0625</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.5</td>
<td>0.6</td>
<td>-0.1</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.4</td>
<td>0.3</td>
<td>0.1</td>
<td>0.01</td>
</tr>
</tbody>
</table>
</div>
<p>The SSE for this line is 0.2727, which is lower than the SSE for the previous line, indicating a better fit.</p>
<p>While we could try additional lines to achieve a lower SSE, there are infinitely many possibilities since <em><span class="math inline">\(\beta_0\)</span></em> and <em><span class="math inline">\(\beta_1\)</span></em> can take any real value.</p>
<p>Using Calculus, we can attempt to minimize the SSE for the generic line <span class="math display">\[\begin{align*}
    \hat{y} = b_0 +b_1 x
\end{align*}\]</span></p>
<p>We will denote the sum of the squared distances with <span class="math inline">\(Q\)</span>: <span id="eq-w1_2"><span class="math display">\[
Q=\sum \left(y_i-\hat{y}_i\right)^2
\tag{14.3}\]</span></span></p>
<p>We determine the “best” line as the one that minimizes <span class="math inline">\(Q\)</span>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
For those who want to see the math:
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To minimize <span class="math inline">\(Q\)</span>, we differentiate it with respect to <span class="math inline">\(b_{0}\)</span> and <span class="math inline">\(b_{1}\)</span>: <span class="math display">\[\begin{align*}
\frac{\partial Q}{\partial b_{0}} &amp; =-2\sum \left(y_{i}-\left(b_{0}+b_{1}x_{i}\right)\right)\\
\frac{\partial Q}{\partial b_{1}} &amp; =-2\sum x_{i}\left(y_{i}-\left(b_{0}+b_{1}x_{i}\right)\right)
\end{align*}\]</span></p>
<p>Setting these partial derivatives equal to 0, we have <span class="math display">\[\begin{align*}
-2\sum \left(y_{i}-\left(b_{0}+b_{1}x_{i}\right)\right) &amp; =0\\
-2\sum x_{i}\left(y_{i}-\left(b_{0}+b_{1}x_{i}\right)\right) &amp; =0
\end{align*}\]</span> Looking at the first equation, we can simplify as <span class="math display">\[\begin{align*}
-2\sum \left(y_{i}-\left(b_{0}+b_{1}x_{i}\right)\right)=0 &amp; \Longrightarrow\sum \left(y_{i}-\left(b_{0}+b_{1}x_{i}\right)\right)=0\\
&amp; \Longrightarrow\sum y_{i}-\sum b_{0}-b_{1}\sum x_{i}=0\\
&amp; \Longrightarrow\sum y_{i}-nb_{0}-b_{1}\sum x_{i}=0\\
&amp; \Longrightarrow\sum y_{i}=nb_{0}+b_{1}\sum x_{i}
\end{align*}\]</span></p>
<p>Simplifying the second equation gives us <span class="math display">\[\begin{align*}
-2\sum x_{i}\left(y_{i}-\left(b_0+b_1x_{i}\right)\right)=0 &amp; \Longrightarrow\sum x_{i}\left(y_{i}-\left(b_0+b_1x_{i}\right)\right)=0\\
&amp; \Longrightarrow\sum x_{i}y_{i}-b_0\sum x_{i}-b_1\sum x_{i}^{2}=0\\
&amp; \Longrightarrow\sum x_{i}y_{i}=b_0\sum x_{i}+b_1\sum x_{i}^{2}
\end{align*}\]</span></p>
<p>The two equations <span id="eq-w1_3"><span class="math display">\[
\begin{align}
\sum y_{i} &amp; =nb_0+b_1\sum x_{i}\nonumber\\
\sum x_{i}y_{i} &amp; =b_0\sum x_{i}+b_1\sum x_{i}^{2}
\end{align}
\tag{14.4}\]</span></span></p>
<p>are called the <em>normal</em> <em>equations</em>.</p>
<p>We now have two equations and two unknowns (<span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>). We can solve the equations simultaneously. We solve the first equation for <span class="math inline">\(b_0\)</span> which gives us <span class="math display">\[\begin{align*}
b_0 &amp; =\frac{1}{n}\left(\sum y_{i}-b_1\sum x_{i}\right)\\
&amp; =\bar{y}-b_1\bar{x}.
\end{align*}\]</span></p>
<p>We now substitute this into the second equation in <a href="#eq-w1_3">Equation&nbsp;<span>14.4</span></a>. Solving this for <span class="math inline">\(b_1\)</span> gives us <span class="math display">\[\begin{align*}
&amp; \sum x_{i}y_{i}=b_0\sum x_{i}+b_1\sum x_{i}^{2}\\
&amp; \quad\Longrightarrow\sum x_{i}y_{i}=\left(\bar{y}-b_1\bar{x}\right)\sum x_{i}+b_1\sum x_{i}^{2}\\
&amp;\quad\Longrightarrow b_1=\frac{\sum \left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\sum \left(x_{i}-\bar{x}\right)^{2}}.
\end{align*}\]</span></p>
<p>To show these estimators are the minimum, we take the second partial derivatives of <span class="math inline">\(Q\)</span>: <span class="math display">\[\begin{align*}
\frac{\partial^{2}Q}{\partial\left(b_{0}\right)^{2}} &amp; =2n\\
\frac{\partial^{2}Q}{\partial\left(b_{1}\right)^{2}} &amp; =2\sum x_{i}^{2}
\end{align*}\]</span> Since these second partial derivatives are both positives, then we know the least squares estimators are the minimum.</p>
</div>
</div>
</div>
<p>The line that best fits the data (that is minimizes <span class="math inline">\(Q\)</span> above) has the following y-intercept and slope: <span id="eq-w1_4"><span class="math display">\[
\begin{align}
b_0 &amp; =\bar{y}-b_1\bar{x}\\
b_1 &amp; =\frac{\sum \left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\sum \left(x_{i}-\bar{x}\right)^{2}}
\end{align}
\tag{14.5}\]</span></span></p>
<p>These equations are called the <blank>least squares</blank> estimators.</p>
<p>The least squares estimators in <a href="#eq-w1_4">Equation&nbsp;<span>14.5</span></a> can be expressed in simpler terms if we let <span class="math display">\[\begin{align*}
SS_{xx} &amp;= \sum \left(x_i-\bar x\right)^2 \\
SS_{xy} &amp;= \sum \left(x_i-\bar x\right)\left(y_i - \bar y\right)
\end{align*}\]</span></p>
<p>The least squares estimates become <span class="math display">\[\begin{align}
{b_1=\frac{SS_{xy}}{SS_{xx}}}\\
{b_0=\bar{y}-b_1\bar{x}}
\end{align}\]</span></p>
<p>To recap: The straight line model for the response <span class="math inline">\(y\)</span> in terms of <span class="math inline">\(x\)</span> is <span class="math display">\[\begin{align*}
{y = \beta_0 + \beta_1 x + \varepsilon}
\end{align*}\]</span></p>
<p>The fitted line (also called the <em>least squares line</em>) is <span class="math display">\[\begin{align*}
{\hat{y} = b_0 + b_1 x }
\end{align*}\]</span></p>
<p>For a given data point, <span class="math inline">\((x_i, y_i)\)</span>, the observed value of <span class="math inline">\(y\)</span> is denoted as <span class="math inline">\(y_i\)</span> and the predicted value of <span class="math inline">\(y\)</span> is obtained by substituting <span class="math inline">\(x_i\)</span> into the prediction equation: <span class="math display">\[\begin{align*}
{\hat{y}_i = b_0 + b_1 x_i }
\end{align*}\]</span></p>
<p>The deviation of the <span class="math inline">\(i\)</span>th value of <span class="math inline">\(y\)</span> from its predicted value, called the <span class="math inline">\(i\)</span>th <em>residual</em>, is <span class="math display">\[
\begin{align*}
{e_i= \left(y_i-\hat{y}_i\right) }
\end{align*}
\]</span> Thus, SSE is just the sum of the squared residuals: <span class="math display">\[
SSE = \sum_{i=1}^n \left(y_i-\hat{y}_i\right)^2
\]</span></p>
<p>In practice we seldom calculate these estimates by hand; software computes them for us.</p>
</section>
<section id="example-advertising-and-sales-business" class="level3">
<h3 class="anchored" data-anchor-id="example-advertising-and-sales-business">Example: Advertising and sales (business)</h3>
<p>Consider the business example introduced earlier. The advertising budget (in thousands of dollars) serves as <span class="math inline">\(x\)</span>, and weekly sales (in thousands of dollars) serve as <span class="math inline">\(y\)</span>. A scatterplot suggests a strong positive association. Fitting a regression line by least squares yields an equation of the form</p>
<p><span class="math display">\[
\widehat{y} = 12.47 + 1.74 x,
\]</span></p>
<p>meaning that each additional thousand dollars spent on advertising is associated with an estimated increase of about 1.74 thousand dollars in weekly sales. The intercept (12.47) is the predicted sales when advertising spend is zero. Depending on context, the intercept may or may not have a meaningful interpretation; often it represents an extrapolation outside the observed data range.</p>
<p>Below is the scatterplot with the fitted regression line.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>The slope 1.74 tells us that for each thousand‑dollar increase in advertising, sales increase by about 1.71 thousand dollars. The intercept 12.47 suggests that if a store spent nothing on advertising, the model predicts $12,470 in weekly sales. In reality, such an extrapolation may not be reasonable; always interpret the intercept within the range of your data.</p>
</section>
<section id="performing-regression-in-jmp-18" class="level3">
<h3 class="anchored" data-anchor-id="performing-regression-in-jmp-18">Performing regression in JMP 18</h3>
<p>To fit a simple linear regression in JMP:</p>
<ol type="1">
<li><strong>Load your data.</strong> Import or enter the variables into a JMP table.</li>
<li><strong>Fit the line.</strong> Choose <strong>Analyze → Fit Y by X</strong>. Assign the response variable to <strong>Y, Response</strong> and the explanatory variable to <strong>X, Factor</strong>, then click <strong>OK</strong>. A scatterplot appears with red triangles above it. Click the red triangle ► and select <strong>Fit Line</strong>. JMP displays the regression line, the estimated coefficients (<span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>), and the analysis of variance table.</li>
</ol>
</section>
<section id="recap-1" class="level3">
<h3 class="anchored" data-anchor-id="recap-1">Recap</h3>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Keyword/Concept</strong></th>
<th><strong>Explanation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>simple linear regression</strong></td>
<td>A model relating a quantitative response <span class="math inline">\(y\)</span> to a single quantitative predictor <span class="math inline">\(x\)</span> via a straight line.</td>
</tr>
<tr class="even">
<td><strong>least squares</strong></td>
<td>A method that determines the intercept and slope by minimizing the sum of squared residuals.</td>
</tr>
<tr class="odd">
<td><strong>slope (<span class="math inline">\(b_1\)</span>)</strong></td>
<td>The change in the predicted response for a one‑unit increase in the explanatory variable; its sign indicates the direction of the relationship. The population slope is denoted <span class="math inline">\(\beta_1\)</span></td>
</tr>
<tr class="even">
<td><strong>intercept (<span class="math inline">\(b_0\)</span>)</strong></td>
<td>The predicted response when the explanatory variable equals zero; may or may not have a meaningful interpretation depending on context. The population intercept is denoted <span class="math inline">\(\beta_1\)</span>.</td>
</tr>
<tr class="odd">
<td><strong>residual</strong></td>
<td>The difference between an observed <span class="math inline">\(y\)</span> value and its predicted value <span class="math inline">\(e_i = y_i - \widehat{y}_i\)</span>.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-1" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-1">Check your understanding</h3>
<ol type="1">
<li>Suppose you fit a regression model <span class="math inline">\(\widehat{y}=2.5 + 0.8x\)</span> relating hours of study (x) to exam score (y). Interpret the slope and the intercept.</li>
<li>Explain why the least squares method squares the residuals instead of simply summing them.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>The slope 0.8 means that for each additional hour of study, the predicted exam score increases by 0.8 points. The intercept 2.5 is the predicted exam score for a student who studies zero hours; it may not be meaningful if the data do not include students who studied so little.</li>
<li>Residuals can be positive or negative. If we simply added them, positive and negative errors would cancel out, giving a misleading impression of model fit. Squaring the residuals makes them all positive and penalizes larger discrepancies more heavily, ensuring that the line minimizes overall error.</li>
</ol>
</div>
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="sec-14_03" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="sec-14_03"><span class="header-section-number">14.3</span> Interpreting the Slope and Intercept</h2>
<blockquote class="blockquote">
<p>“Essentially, all models are wrong, but some are useful.” - George Box</p>
</blockquote>
<blockquote class="blockquote">
<p><em>Guiding question:</em> <em>What do the coefficients of a regression line tell us in context?</em></p>
</blockquote>
<p>While the previous section introduced the regression line, here we dig deeper into interpreting its coefficients. The <em>slope</em> <span class="math inline">\(b_1\)</span> tells us how the predicted response changes when the predictor increases by one unit. If <span class="math inline">\(b_1\)</span> is positive, the regression line rises from left to right; if negative, it falls. The magnitude of <span class="math inline">\(b_1\)</span> indicates how steep the line is.</p>
<p>The <em>intercept</em> <span class="math inline">\(b_0\)</span> is the predicted value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x=0\)</span>. In some situations it has a natural interpretation. For instance, in the business example above, <span class="math inline">\(b_0\approx 12.47\)</span> means that a store with zero advertising dollars is predicted to sell about $12,470 per week (perhaps due to walk‑in customers). In other contexts the intercept may be outside the range of observed <span class="math inline">\(x\)</span> values. In an example of height–weight, an intercept of any value would not be meaningful because nobody has a height of zero inches. In such cases the slope is often the focus and the intercept is treated as a mathematical artifact.</p>
<section id="examples-across-fields" class="level3">
<h3 class="anchored" data-anchor-id="examples-across-fields">Examples across fields</h3>
<ul>
<li><strong>Medicine:</strong> In pharmacokinetics, the relationship between drug dose (<span class="math inline">\(x\)</span>) and concentration in blood (<span class="math inline">\(y\)</span>) is often modeled linearly over a therapeutic range. A slope of 0.2 means that each additional milligram of drug increases the mean concentration by 0.2 units. The intercept might represent baseline concentration (e.g., residual drug from a previous dose).</li>
<li><strong>Biology:</strong> When studying growth, you might relate nutrient concentration to plant height. A slope of 1.5 cm per nutrient unit indicates that increasing fertilizer by one unit yields plants 1.5 cm taller on average. If the intercept is negative, it signals that the linear model is extrapolated below the smallest nutrient level and should not be taken literally.</li>
<li><strong>Business:</strong> In cost analysis, the total cost <span class="math inline">\(y\)</span> can often be written as a fixed cost (<span class="math inline">\(b_0\)</span>) plus a variable cost per unit (<span class="math inline">\(b_1\)</span>). If a company has a fixed cost of $10,000 and spends $5 per unit produced, the regression equation would be <span class="math inline">\(\widehat{y} = 10{,}000 + 5x\)</span>. Here both slope and intercept have clear interpretations.</li>
</ul>
</section>
<section id="inference-for-the-regression-slope" class="level3">
<h3 class="anchored" data-anchor-id="inference-for-the-regression-slope">Inference for the Regression Slope</h3>
<blockquote class="blockquote">
<p><em>Guiding question:</em> <em>How can we quantify uncertainty in our estimate of the slope and test whether the relationship is statistically significant?</em></p>
</blockquote>
<p>Estimating the slope from a sample gives us a point estimate, but due to sampling variability we need to quantify its uncertainty. Under the usual regression assumptions (discussed in a later section) the estimated slope <span class="math inline">\(b_1\)</span> follows a t‑distribution centered at the true population slope <span class="math inline">\(\beta_1\)</span>. The spread of this distribution is governed by the <blank>standard error of the slope</blank>, denoted <span class="math inline">\(\mathrm{SE}_{b_1}\)</span>. Software computes this value for us, but it can be expressed in terms of the residuals and the variability of the predictor:</p>
<p><span class="math display">\[
\mathrm{SE}_{b_1} = \sqrt{\frac{SSE}{\sum (x_i - \overline{x})^2}}.
\]</span></p>
<p>The denominator is the spread of the <span class="math inline">\(x\)</span>-values about their mean, and the numerator is the root mean squared error of the regression (the residual standard deviation).</p>
<section id="hypothesis-testing-for-the-slope" class="level4">
<h4 class="anchored" data-anchor-id="hypothesis-testing-for-the-slope">Hypothesis testing for the slope</h4>
<p>To test whether there is a linear relationship in the population, we set up the hypotheses</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \beta_1 = 0 \quad \text{(no linear association)},\\
H_a &amp;: \beta_1 \ne 0 \quad \text{(some linear association)}.
\end{aligned}
\]</span></p>
<p>The test statistic is the ratio of the estimated slope to its standard error:</p>
<p><span class="math display">\[
t = \frac{b_1}{\mathrm{SE}_{b_1}},
\]</span></p>
<p>which follows a t‑distribution with <span class="math inline">\(n-2\)</span> degrees of freedom under the null hypothesis. A large positive or negative <span class="math inline">\(t\)</span>-value provides evidence against <span class="math inline">\(H_0\)</span>. The P‑value is the probability of observing a <span class="math inline">\(t\)</span>-value as extreme as the computed value if <span class="math inline">\(H_0\)</span> were true. A small P‑value (e.g., less than 0.05) leads us to reject <span class="math inline">\(H_0\)</span>, concluding that the slope is significantly different from zero.</p>
</section>
<section id="confidence-interval-for-the-slope" class="level4">
<h4 class="anchored" data-anchor-id="confidence-interval-for-the-slope">Confidence interval for the slope</h4>
<p>A <em>confidence interval</em> for <span class="math inline">\(\beta_1\)</span> provides a range of plausible values. A <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval is given by</p>
<p><span class="math display">\[
b_1 \,\pm\, t_{(\alpha/2,\,n-2)} \times \mathrm{SE}_{b_1},
\]</span></p>
<p>where <span class="math inline">\(t_{(\alpha/2,n-2)}\)</span> is the critical value from the t‑distribution with <span class="math inline">\(n-2\)</span> degrees of freedom. If the interval does not include zero, the sample provides evidence of a non‑zero slope.</p>
</section>
<section id="example-age-and-systolic-blood-pressure-1" class="level4">
<h4 class="anchored" data-anchor-id="example-age-and-systolic-blood-pressure-1">Example: Age and systolic blood pressure</h4>
<p>Consider again the dataset relating age to systolic blood pressure for 20 adults. Fitting a regression line yields an estimated slope of roughly 0.95 mmHg per year and a standard error of about 0.09. The test statistic <span class="math inline">\(t = 0.95/0.09 \approx 10.8\)</span> is large in magnitude, and the P‑value is less than 0.0001, indicating strong evidence that systolic blood pressure increases with age. A 95% confidence interval for the slope is approximately <span class="math inline">\((0.77,\,1.14)\)</span>, meaning that we are 95% confident that each additional year of age increases mean systolic blood pressure by between 0.77 and 1.14 mmHg.</p>
<p>In JMP, after selecting <strong>Fit Y by X</strong> and choosing <strong>Fit Line</strong>, the <strong>Parameter Estimates</strong> table lists the slope estimate, its standard error, the <span class="math inline">\(t\)</span>-ratio, the P‑value, and a 95% confidence interval. To perform a slope test, check whether the P‑value for the predictor is below your significance threshold. To report a confidence interval, use the “Lower 95%” and “Upper 95%” entries for the slope.</p>
</section>
<section id="example-enzyme-concentration-and-reaction-rate" class="level4">
<h4 class="anchored" data-anchor-id="example-enzyme-concentration-and-reaction-rate">Example: Enzyme concentration and reaction rate</h4>
<p>Biologists fit a simple linear regression model relating reaction rate to enzyme concentration. In our earlier sample of 15 observations, the estimated slope was about 0.42 with a standard error of 0.05. The resulting test statistic <span class="math inline">\((0.42/0.05\approx 7.7)\)</span> yields a tiny P‑value (&lt;0.001), indicating a significant positive association. The 95% confidence interval for the slope is roughly <span class="math inline">\((0.30,\,0.53)\)</span>. We therefore estimate that increasing the enzyme concentration by one unit raises the reaction rate by between 0.30 and 0.53 units on average.</p>
</section>
<section id="performing-inference-in-jmp-18" class="level4">
<h4 class="anchored" data-anchor-id="performing-inference-in-jmp-18">Performing inference in JMP 18</h4>
<p>To obtain confidence intervals and hypothesis tests for the slope in JMP:</p>
<ol type="1">
<li><strong>Fit the regression.</strong> Use <strong>Analyze → Fit Y by X</strong>, assign the response variable to <strong>Y</strong> and the predictor to <strong>X</strong>, and click <strong>Fit Line</strong>.</li>
<li><strong>Examine the Parameter Estimates table.</strong> This table displays the estimate (<span class="math inline">\(b_1\)</span>), its standard error, the <span class="math inline">\(t\)</span>-ratio and P‑value, and 95% confidence limits for each coefficient. A small P‑value for the predictor indicates a significant slope.</li>
<li><strong>Report the confidence interval.</strong> Use the lower and upper 95% bounds provided for the slope. For different confidence levels, click the red triangle beside <strong>Parameter Estimates</strong>, choose <strong>Confidence Intervals</strong>, and specify the desired level.</li>
</ol>
</section>
</section>
<section id="recap-2" class="level3">
<h3 class="anchored" data-anchor-id="recap-2">Recap</h3>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Concept/Statistic</strong></th>
<th><strong>Interpretation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Sample Slope (<span class="math inline">\(b_1\)</span>)</strong></td>
<td>Change in the predicted response for a one‑unit increase in the predictor; sign indicates direction and magnitude indicates steepness.</td>
</tr>
<tr class="even">
<td><strong>Sample Intercept (<span class="math inline">\(b_0\)</span>)</strong></td>
<td>Predicted response when the predictor is zero; meaningful only if zero is within or near the observed range.</td>
</tr>
<tr class="odd">
<td><strong><span class="math inline">\(t\)</span>-test for slope</strong></td>
<td>Test statistic <span class="math inline">\(t=b_1/\mathrm{SE}_{b_1}\)</span> follows a t‑distribution with <span class="math inline">\(n-2\)</span> degrees of freedom under <span class="math inline">\(H_0:\beta_1=0\)</span>; a small P‑value indicates a non‑zero slope.</td>
</tr>
<tr class="even">
<td><strong>Confidence interval for slope</strong></td>
<td>Interval of the form <span class="math inline">\(b_1 \pm t \times \mathrm{SE}_{b_1}\)</span>; provides a range of plausible values for the population slope. If the interval excludes zero, it suggests a significant linear association.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-2" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-2">Check your understanding</h3>
<ol type="1">
<li>In a study of lung function, researchers regress forced expiratory volume (FEV) on patient age using a sample of 25 participants. The estimated slope is 0.12 L/year with a standard error of 0.03. Test <span class="math inline">\(H_0:\beta_1=0\)</span> versus <span class="math inline">\(H_a:\beta_1\ne 0\)</span> at the 0.05 significance level. Construct a 95% confidence interval for the slope and interpret it.</li>
<li>A nutritionist models the relationship between daily vitamin D intake (mg) and bone density. The estimated slope is −0.05 with a standard error of 0.07 (<span class="math inline">\(n=30\)</span>). What can you conclude about the effect of vitamin D on bone density? Explain.</li>
<li>For the advertising data, the slope estimate is 1.45 and the 95% confidence interval is approximately <span class="math inline">\((1.28,1.61)\)</span>. How would you interpret this interval in the business context? Would you conclude that advertising has no effect? Why or why not?</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>The test statistic is <span class="math inline">\(t=0.12/0.03=4\)</span> with <span class="math inline">\(df=25-2=23\)</span>. A <span class="math inline">\(t\)</span>-ratio of 4 yields a P‑value much less than 0.05, so we reject <span class="math inline">\(H_0\)</span> and conclude that age is positively associated with FEV. A 95% confidence interval is <span class="math inline">\(0.12 \pm t_{0.025,\,23}\times 0.03 \approx 0.12 \pm 2.07 \times 0.03\)</span>, or <span class="math inline">\((0.06,\,0.18)\)</span>. We are 95% confident that each additional year of age increases FEV by between 0.06 and 0.18 liters, on average.</li>
<li>Compute <span class="math inline">\(t = -0.05/0.07 \approx -0.71\)</span> with <span class="math inline">\(df = 30-2=28\)</span>. This value is small in magnitude, and the corresponding P‑value is greater than 0.05. We fail to reject <span class="math inline">\(H_0\)</span>; there is no evidence of a linear relationship between vitamin D intake and bone density in this sample. The 95% confidence interval (not requested) would include zero, reinforcing this conclusion.</li>
<li>The interval <span class="math inline">\((1.28,1.61)\)</span> means that for every additional $1{,}000 spent on advertising, weekly sales are estimated to increase by between about $1.28k and $1.61k. Because the interval is entirely above zero, we conclude that advertising has a positive effect on sales. There is strong evidence against the null hypothesis of no effect, so it would be incorrect to claim that advertising has no impact.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-14_04" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="sec-14_04"><span class="header-section-number">14.4</span> Assessing the Fit</h2>
<blockquote class="blockquote">
<p>“If we did all the things we are capable of, we would literally astound ourselves.” - Thomas Edison</p>
</blockquote>
<blockquote class="blockquote">
<p><em>Guiding question:</em> <em>How much of the variability in the response is explained by our regression model?</em></p>
</blockquote>
<p>We have already discussed a measure of how well a linear model explains the association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>.</p>
<p>A second measure of how well the model fits the data involves measuring the amount of <em>variability</em> in <span class="math inline">\(y\)</span> that is explained by the model using <span class="math inline">\(x\)</span>.</p>
<p>We start by examining the variability of the variable we want to learn about. We want to learn about the response variable <span class="math inline">\(y\)</span>. One way to measure the variability of <span class="math inline">\(y\)</span> is with <span class="math display">\[
SS_{yy} = \sum\left(y_i-\bar{y}\right)^2
\]</span></p>
<p>Note that <span class="math inline">\(SS_{yy}\)</span> does not include the model or <span class="math inline">\(x\)</span>. It is just a measure of how <span class="math inline">\(y\)</span> deviates from its mean <span class="math inline">\(\bar{y}\)</span>.</p>
<p>We also have the variability of the points about the <blank>line</blank>. We can measure this with the sum of squares error <span class="math display">\[
SSE = \sum \left(y_i - \hat{y}_i\right)^2
\]</span></p>
<p>Note that SSE does include <span class="math inline">\(x\)</span>. This is because the fitted line <span class="math inline">\(\hat{y}\)</span> is a function of <span class="math inline">\(x\)</span>.</p>
<p>Here are a couple of key points regarding sums of squares:</p>
<ul>
<li>If <span class="math inline">\(x\)</span> provides little to no useful information for predicting <span class="math inline">\(y\)</span>, then <span class="math inline">\(SS_{yy}\)</span> and <span class="math inline">\(SSE\)</span> will be nearly <blank>equal</blank>.</li>
<li>If <span class="math inline">\(x\)</span> does provide valuable information for predicting <span class="math inline">\(y\)</span>, then <span class="math inline">\(SSE\)</span> will be <blank>smaller</blank> than <span class="math inline">\(SS_{yy}\)</span>.</li>
<li>In the extreme case where all points lie exactly on the least squares line, <span class="math inline">\(SSE = 0\)</span>.</li>
</ul>
<p>Here’s an example to illustrate:</p>
<p>Suppose we have data for two variables, hours studied (x) and test scores (y). If studying time doesn’t help predict the test score, the variation in test scores (measured by <span class="math inline">\(SS_{yy}\)</span>) will be similar to the error in the prediction (measured by <span class="math inline">\(SSE\)</span>). However, if studying time is a good predictor, the prediction errors will be much smaller, making <span class="math inline">\(SSE\)</span> significantly smaller than <span class="math inline">\(SS_{yy}\)</span>. If the relationship between study time and test scores is perfect, then the error would be zero, resulting in <span class="math inline">\(SSE = 0\)</span>.</p>
<section id="proportion-of-variation-explained" class="level3">
<h3 class="anchored" data-anchor-id="proportion-of-variation-explained">Proportion of Variation Explained</h3>
<p>We want to explain as much of the variation of <span class="math inline">\(y\)</span> as possible. So we want to know just how much of that variation is explained by using linear regression model with <span class="math inline">\(x\)</span>. We can quantify this variation explained by taking the difference <span id="eq-w2_17"><span class="math display">\[
\begin{align}
    SSR = SS_{yy}-SSE
\end{align}
\tag{14.6}\]</span></span></p>
<p>SSR is called the sum of squares <blank>regression</blank>.</p>
<p>We calculate the <em>proportion</em> of the variation of <span class="math inline">\(y\)</span> explained by the regression model using <span class="math inline">\(x\)</span> by calculating<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span id="eq-w2_18"><span class="math display">\[
\begin{align}
    r^2 = \frac{SSR}{SS_{yy}}
\end{align}
\tag{14.7}\]</span></span></p>
<p><span class="math inline">\(r^2\)</span> is called the coefficient of <em>determination</em><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</section>
<section id="interpreting-r2" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-r2">Interpreting <span class="math inline">\(R^2\)</span></h3>
<p>Suppose <span class="math inline">\(r=0.93\)</span> in our blood‑pressure example. Then <span class="math inline">\(R^2 = 0.93^2 \approx 0.86\)</span>. This means that about 86% of the variability in systolic blood pressure is explained by age through a linear relationship. The remaining 14% represents variability due to other factors and random noise.</p>
<p>In the advertising example with <span class="math inline">\(r=0.98\)</span>, <span class="math inline">\(R^2\approx 0.96\)</span>, suggesting that advertising spending explains 96% of the variation in sales. High values of <span class="math inline">\(R^2\)</span> do not prove causation, and an excessively large <span class="math inline">\(R^2\)</span> can sometimes signal overfitting or the influence of an outlier. Always inspect the scatterplot and residuals.</p>
</section>
<section id="getting-r2-in-jmp" class="level3">
<h3 class="anchored" data-anchor-id="getting-r2-in-jmp">Getting <span class="math inline">\(R^2\)</span> in JMP</h3>
<p>After fitting a regression line in JMP (via <strong>Fit Y by X</strong> and <strong>Fit Line</strong>), the <strong>Summary of Fit</strong> table shows several statistics. The row labeled <strong>R Square</strong> gives <span class="math inline">\(R^2\)</span>. The <strong>Root Mean Square Error</strong> (RMSE) is the square root of the mean squared residuals and provides a measure of typical prediction error in the units of the response.</p>
</section>
<section id="recap-3" class="level3">
<h3 class="anchored" data-anchor-id="recap-3">Recap</h3>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Statistic</strong></th>
<th><strong>Meaning</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Coefficient of determination (<span class="math inline">\(R^2\)</span>)</strong></td>
<td>The fraction of the variation in the response that can be explained by its linear relationship with the predictor.</td>
</tr>
<tr class="even">
<td><strong>Root mean square error (RMSE)</strong></td>
<td>The square root of the average squared residuals; provides a typical size of prediction error in the response variable’s units.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-3" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-3">Check your understanding</h3>
<ol type="1">
<li>If <span class="math inline">\(r=0.50\)</span> for a pair of variables, what is <span class="math inline">\(R^2\)</span>? Interpret this value in context.</li>
<li>In the enzyme concentration example, the correlation was roughly 0.94. What proportion of the variability in reaction rate does the linear model explain? What percentage remains unexplained?</li>
<li>Can an <span class="math inline">\(R^2\)</span> value ever be negative? Explain why or why not.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Since <span class="math inline">\(R^2 = r^2\)</span>, with <span class="math inline">\(r=0.50\)</span> we get <span class="math inline">\(R^2 = 0.25\)</span>. This means that about 25% of the variation in the response is explained by its linear relationship with the predictor. The remaining 75% is due to other factors or random variation.</li>
<li><span class="math inline">\(R^2 = 0.94^2 \approx 0.88\)</span>, so about 88% of the variability in reaction rate is explained by enzyme concentration. Roughly 12% remains unexplained by this simple linear model.</li>
<li>No.&nbsp;<span class="math inline">\(R^2\)</span> is defined as the square of the correlation coefficient (or equivalently, as 1 minus the ratio of the residual sum of squares to the total sum of squares) and therefore must lie between 0 and 1. A negative value would have no interpretation in this context.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-14_05" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="sec-14_05"><span class="header-section-number">14.5</span> Residual Analysis</h2>
<blockquote class="blockquote">
<p>“`…the statistician knows…that in nature there never was a normal distribution, there never was a straight line, yet with normal and linear assumptions, known to be false, he can often derive results which match, to a useful approximation, those found in the real world.” - George Box</p>
</blockquote>
<blockquote class="blockquote">
<p><em>Guiding question:</em> <em>How do we check whether our regression model is appropriate?</em></p>
</blockquote>
<p>A regression line is a simplification of reality. <strong>Residuals</strong>—the differences between observed and predicted values—tell us how well the model fits each observation. By plotting and analyzing residuals we can assess the validity of our linear model and its underlying assumptions.</p>
<section id="residual-plots" class="level3">
<h3 class="anchored" data-anchor-id="residual-plots">Residual plots</h3>
<p>The four main assumptions of simple linear regression are:</p>
<ol type="1">
<li><strong>Linearity:</strong> The relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is linear. We assess this by examining the scatterplot and the residuals; a residual plot (residuals vs.&nbsp;fitted values) should show no systematic pattern.</li>
<li><strong>Independence of errors:</strong> Residuals are independent of each other. This is mainly a study‑design issue, but a residual plot with no obvious patterns supports independence.</li>
<li><strong>Normality of errors:</strong> Residuals are approximately normally distributed. Check this assumption with a normal probability plot or a histogram of the residuals.</li>
<li><strong>Equal variances (homoscedasticity):</strong> The spread of residuals is roughly constant across all fitted values. On a residual plot, the vertical spread should be similar across the range of <span class="math inline">\(x\)</span>; funnels or megaphone shapes indicate heteroscedasticity.</li>
</ol>
<p>Violations of these assumptions can invalidate inference. For example, a curved pattern in the residual plot suggests that the relationship is nonlinear, calling for a transformation or a different model. Non‑constant variance may require weighted regression or a transformation of the response.</p>
<p>If the linear model is appropriate, the residuals should be randomly scattered around zero with constant variance. You can also create a normal probability plot of the residuals. In JMP, select <strong>Save Residuals</strong> in the regression output and then use <strong>Graph → Distribution</strong> or <strong>Analyze → Fit Y by X</strong> to examine the residuals.</p>
</section>
<section id="conducting-residual-analysis-in-jmp" class="level3">
<h3 class="anchored" data-anchor-id="conducting-residual-analysis-in-jmp">Conducting residual analysis in JMP</h3>
<ol type="1">
<li><strong>Save residuals.</strong> In the <strong>Fit Y by X</strong> output window, click the red triangle ► and choose <strong>Save Residuals</strong>. A new column of residuals appears in your data table.</li>
<li><strong>Plot residuals vs.&nbsp;fitted values.</strong> Choose <strong>Graph → Graph Builder</strong>, drag the fitted values (predicted <span class="math inline">\(y\)</span>) to the X‑axis and residuals to the Y‑axis, and select the <em>Scatter Plot</em> element. The plot should show no obvious pattern if the linearity and equal‑variance assumptions are satisfied.</li>
<li><strong>Check normality.</strong> Use <strong>Analyze → Distribution</strong> on the residuals column. Inspect the histogram and normal quantile plot. If the residuals deviate greatly from normality, consider transformations or nonparametric methods.</li>
</ol>
</section>
<section id="recap-4" class="level3">
<h3 class="anchored" data-anchor-id="recap-4">Recap</h3>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Concept</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Residual (error)</strong></td>
<td>The difference between an observed response and the value predicted by the regression line.</td>
</tr>
<tr class="even">
<td><strong>Residual plot</strong></td>
<td>Scatterplot of residuals vs.&nbsp;fitted values; used to check linearity and constant variance assumptions.</td>
</tr>
<tr class="odd">
<td><strong>Equal variance (homoscedasticity)</strong></td>
<td>Assumption that residuals have constant variance across levels of the predictor; checked by looking for uniform spread in residual plots.</td>
</tr>
</tbody>
</table>
</section>
<section id="check-your-understanding-4" class="level3">
<h3 class="anchored" data-anchor-id="check-your-understanding-4">Check your understanding</h3>
<ol type="1">
<li>Describe what you would look for in a residual vs.&nbsp;fitted plot to decide whether the linearity assumption is satisfied.</li>
<li>Why is it important that residuals have constant variance? What problems arise if this assumption is violated?</li>
<li>Explain how you would check the normality of residuals in JMP.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled" title="Solutions">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solutions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>A residual vs.&nbsp;fitted plot should show residuals randomly scattered around zero with no systematic pattern. If you see a curve, clusters or a funnel shape, the linearity assumption may be violated.</li>
<li>Constant variance ensures that the model’s prediction errors are equally reliable across all values of the predictor. If the variance increases or decreases with the fitted values (heteroscedasticity), the standard errors of the coefficients may be biased, leading to misleading inference. In such cases you might transform the response or use weighted least squares.</li>
<li>After saving residuals in JMP, use <strong>Analyze → Distribution</strong> to generate a histogram and normal quantile plot. If the histogram is roughly bell‑shaped and the points in the quantile plot lie close to the reference line, the normality assumption is reasonable. Significant departures (skewness or heavy tails) suggest that a transformation or a different model may be needed.</li>
</ol>
</div>
</div>
</div>
</section>
</section>
<section id="sec-14_06" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="sec-14_06"><span class="header-section-number">14.6</span> Prediction Intervals and Confidence Intervals</h2>
<blockquote class="blockquote">
<p>“Our greatest fear should not be of failure, but of succeeding at something that doesn’t really matter.” - D.L. Moody</p>
</blockquote>
<section id="the-residual-standard-deviation" class="level3">
<h3 class="anchored" data-anchor-id="the-residual-standard-deviation">The Residual Standard Deviation</h3>
<p>Recall that the sample prediction equation <span class="math display">\[
\begin{align*}
    { \hat y = b_0 + b_1 x }
\end{align*}
\]</span> estimates a population regression equation, <span class="math display">\[
\begin{align*}
{ y = \beta_0 + \beta_1 x +\varepsilon}
\end{align*}
\]</span></p>
<p>For statistical inference, the regression model also assumes that the conditional distribution of <span class="math inline">\(y\)</span> at a fixed value of <span class="math inline">\(x\)</span> is normal, with the same standard deviation at each <span class="math inline">\(x\)</span> (the homoscedasticity assumption discussed in the previous section).</p>
<p>This standard deviation, denoted by <span class="math inline">\(\sigma\)</span>, refers to the variability of <span class="math inline">\(y\)</span> values for all subjects with the same value of <span class="math inline">\(x\)</span>.</p>
<p>This is a parameter that can be estimated from the data.</p>
<p>The estimate of <span class="math inline">\(\sigma\)</span> uses <span class="math display">\[
\begin{align*}
    { \sum \left(y-\hat y\right)^2}
\end{align*}
\]</span> the residual sum of squares, which summarizes sample variability about the regression line.</p>
<p>The estimate, called the residual standard deviation, is <span class="math display">\[
\begin{align*}
    {s = \sqrt{\frac{\sum \left(y-\hat y\right)^2}{n-2}} }
\end{align*}
\]</span></p>
<p>It describes the typical size of the residuals. The <span class="math inline">\(n - 2\)</span> term in the denominator is the df value of the <span class="math inline">\(t\)</span> distribution used for inference about <span class="math inline">\(\beta_1\)</span> in the previous section.</p>
</section>
<section id="confidence-and-prediction-intervals" class="level3">
<h3 class="anchored" data-anchor-id="confidence-and-prediction-intervals">Confidence and Prediction Intervals</h3>
<p>If we are satisfied that a useful model has been found, we are ready to use the model for estimation and prediction.</p>
<p>We have already seen how to estimate the mean value of <span class="math inline">\(y\)</span> given some value of <span class="math inline">\(x\)</span>. For example, if <span class="math inline">\(\hat{y}=-9.2+0.4x\)</span>, then an estimate for the mean value of <span class="math inline">\(y\)</span> at <span class="math inline">\(x=65\)</span> is <span class="math display">\[
\begin{align*}
    { \hat{y}=-9.2+0.4(65) = 16.8  }
\end{align*}
\]</span></p>
<p>If we want to predict a new value of <span class="math inline">\(y\)</span> for some value of <span class="math inline">\(x\)</span>, then again we can use the regression line. For the same example: <span class="math display">\[
\begin{align*}
    { \hat{y}=-9.2+0.4(65) = 16.8  }
\end{align*}
\]</span></p>
<p>So we estimate the mean and predict for an individual value in the same way. What is different in the two uses of regression involves the variability.</p>
<p>What has greater variability, the mean of <span class="math inline">\(y\)</span> or a single value of <span class="math inline">\(y\)</span>?</p>
<p>The mean will have <blank>less</blank> variability than an individual value.</p>
</section>
<section id="sampling-errors-for-the-estimator-of-the-mean-of-y-and-the-predictor-of-an-individual-new-value-of-y" class="level3">
<h3 class="anchored" data-anchor-id="sampling-errors-for-the-estimator-of-the-mean-of-y-and-the-predictor-of-an-individual-new-value-of-y">Sampling Errors for the Estimator of the Mean of <span class="math inline">\(y\)</span> and the Predictor of an Individual New Value of <span class="math inline">\(y\)</span></h3>
<p>The standard deviation of the sampling distribution of the estimator <span class="math inline">\(\hat y\)</span> of the mean value of <span class="math inline">\(y\)</span> at a specific value of <span class="math inline">\(x\)</span> , say <span class="math inline">\(x_p\)</span>, is <span class="math display">\[
\begin{align*}
\sigma_{\hat{y}} &amp; =\sigma\sqrt{\frac{1}{n}+\frac{\left(x_{p}-\bar{x}\right)^{2}}{SS_{xx}}}
\end{align*}
\]</span></p>
<p>We refer to <span class="math inline">\(\sigma_{\hat y}\)</span> as the standard deviation of <span class="math inline">\(\hat y\)</span>.</p>
<p>The standard deviation of the prediction error for the predictor <span class="math inline">\(\hat y\)</span> of an individual new <span class="math inline">\(y\)</span> value at a specific value of <span class="math inline">\(x\)</span> is <span class="math display">\[
\begin{align*}
\sigma_{\left(y-\hat{y}\right)} &amp; =\sigma\sqrt{1+\frac{1}{n}+\frac{\left(x_{p}-\bar{x}\right)^{2}}{SS_{xx}}}
\end{align*}
\]</span></p>
<p>We refer to <span class="math inline">\(\sigma_{(y-\hat y)}\)</span> as the standard deviation of prediction.</p>
<p>The true value of <span class="math inline">\(\sigma\)</span> is rarely known, so we estimate <span class="math inline">\(\sigma\)</span> by <span class="math inline">\(s\)</span>.</p>
<p>We can then construct the <blank>confidence interval</blank> for the <blank>mean</blank> value of <span class="math inline">\(y\)</span> at <span class="math inline">\(x=x_p\)</span> as <span class="math display">\[
\begin{align*}
\hat{y} &amp; \pm t_{\alpha/2}s\sqrt{\frac{1}{n}+\frac{\left(x_{p}-\bar{x}\right)^{2}}{SS_{xx}}}
\end{align*}
\]</span></p>
<p>The <blank>prediction interval</blank> for an <blank>individual</blank> new value of <span class="math inline">\(y\)</span> at <span class="math inline">\(x=x_p\)</span> is <span class="math display">\[
\begin{align*}
\hat{y} &amp; \pm t_{\alpha/2}s\sqrt{1+\frac{1}{n}+\frac{\left(x_{p}-\bar{x}\right)^{2}}{SS_{xx}}}
\end{align*}
\]</span></p>
<p>Note that the prediction interval for an individual new value of <span class="math inline">\(y\)</span> is always <blank>wider</blank> than the corresponding confidence interval for the mean value of <span class="math inline">\(y\)</span>.</p>
<p>The data for female athlete on the bench press can be found in the file .</p>
<p>The response variable is the maximum bench press and the explanatory variable is the number of bench press reps of 60 lbs.</p>
<p>JMP output:</p>
<p><img src="images/12_07_female_benchpress_regression.png" class="img-fluid"></p>
<p>Suppose we want to make a confidence interval for the mean bench press for all those who can do 11 reps at 60 lbs. Also, suppose we want a prediction interval for one athlete who can do 11 reps at 60 lbs.</p>
<p><img src="images/12_08_female_benchpress_intervals.png" class="img-fluid"></p>
<p>Caution: We do not want to <blank>extrapolate</blank> when conducting a regression analysis. That is, we do not want to construct confidence intervals or prediction intervals for values of <span class="math inline">\(x\)</span> that are outside the range of the <span class="math inline">\(x\)</span> values we had in our sample.</p>
<p>For example, below is the scatterplot for the benchpress data.</p>
<p><img src="images/12_04_female_bench_fit.png" class="img-fluid"></p>
<p>Note that we do not have any athlete who can do 40 reps or more at 60 lbs. So to use our estimated model to predict at say 50 reps would be extrapolation. We should not do this in regression analysis.</p>
<hr>
<p><img src="images/correlation.png" class="img-fluid"></p>


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>In simple linear regression, it can be shown that this quantity is equal to the square of the simple linear coefficient of correlation <span class="math inline">\(r\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that some software will denote the coefficient of determination as <span class="math inline">\(R^2\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>